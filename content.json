{"meta":{"title":"Yuanyang-Lee's Blog","subtitle":"","description":"","author":"Captain_Lee","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2023-02-08T17:20:04.000Z","updated":"2023-02-08T17:21:01.238Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标题","date":"2023-02-08T16:22:53.592Z","updated":"2023-02-08T16:22:53.588Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-02-08T17:23:44.000Z","updated":"2023-02-08T17:24:02.300Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"脉冲神经网络 SNN","slug":"脉冲神经网络-SNN","date":"2024-01-26T09:00:42.000Z","updated":"2024-01-29T16:53:38.254Z","comments":true,"path":"2024/01/26/脉冲神经网络-SNN/","link":"","permalink":"http://example.com/2024/01/26/%E8%84%89%E5%86%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-SNN/","excerpt":"","text":"第三代神经网络 SNN 尖峰神经网络（SNN，Spike Neural Network）是一种神经网络模型，它在模拟人脑处理信息方式方面比传统的人工神经网络更为接近。 SNN 的独特之处在于其神经元之间的交流是通过“尖峰”（Spike），即短暂的电信号脉冲来实现的，类似于生物神经元的通信方式。这种方式允许 SNN 以一种高效的时间编码方式处理信息，使得网络能够响应快速变化的输入信号并在更低的功耗下运行。 如下图，这项由 J. Krüger 和 F. Aiple 在 1988 年进行的研究集中在猴子的视皮层下层的神经元之间的相互作用。研究通过使用多个紧密排列的微电极记录尖峰并分析交叉相关图，旨在理解这些皮层层次中神经元的交互作用及其相关结构。其中两条竖线标记了 100ms 的间隔。 SNN 通常被视为第三代神经网络模型，它在模拟神经元动态行为、处理时间序列数据以及学习时空模式方面表现出独特优势。由于其生物学上的真实性和能效高的特点，SNN 在神经形态计算领域尤为受到关注。神经形态计算旨在模仿人脑的处理方式，开发出更高效的计算模型和硬件架构。 神经元 相比第二代神经网络，也就是基于传统的线性变换和非线性激活函数的 ANN 而言，SNN 将激活函数替换成了一种动态的时序敏感的神经元（Neuron）。 基本特性 脉冲机制：SNN 神经元通过尖峰进行通信。这些脉冲是离散的事件，通常在模拟神经元的电压达到某个阈值时发生。 时间动力学：SNN 神经元具有显著的时间动力学特性。它们的状态不仅取决于当前的输入，还取决于历史输入的积累效应，这是通过内部状态变量（例如膜电位）来实现的。 生物学上的仿真性：SNN 更贴近于模拟真实生物神经系统的方式。它们试图通过模拟生物神经元的动态特性（如脉冲编码和神经元的时变动态）来处理信息。 接下来我们以两种神经元为例，讲解其工作原理。 IF 神经元 IF 神经元（Integrate-and-Fire Neuron）是脉冲神经网络（SNNs）中最基本的神经元模型之一。它的设计模拟了生物神经元的基本行为，特别是如何积累输入信号，并在达到特定阈值时产生脉冲。 积分（Integrate）：IF 神经元首先会积累其输入信号。这些输入可能来自网络中的其他神经元，或者是外部的刺激。积分过程实际上是对输入信号（通常是电流）随时间的累加，这在生物学上对应于神经元膜电位的变化。 \\[ U_i^{(l)}(t) = U_i^{(l)}(t - 1) + RI_{i}^{(l)}(t) \\] 这里 \\(U_i^{(l)}(t)\\) 表示 \\(t\\) 时刻神经元的膜电位，\\(RI_i^{(l)}(t)\\) 表示 \\(t\\) 时刻该神经元接收的输入信号的大小，其中 \\(I_i^{(l)}(t)\\) 表示输入电流，由 \\(t\\) 时刻神经元接收到的尖峰累加而成，\\(R\\) 在这里表示膜电阻。 触发（Fire）：当积累的信号（即膜电位）达到特定的阈值时，神经元会发射一个脉冲，并且将这个信号传递给其它神经元。发射脉冲后，神经元的膜电位通常会被重置到一个较低的初始值，准备接受下一轮的信号积累。 \\[ S_i^{(l)}(t) = \\Theta(U_i^{(l)}(t) - U_{\\text{threshold}}) \\] \\[ U_i^{(l)}(t) := U_{\\text{rest}}\\ \\ \\text{if}\\ \\ U_i^{(l)}(t) \\geq U_{\\text{threshold}} \\] 这里 \\(\\Theta(\\cdot)\\) 表示阶跃函数，\\(U_{\\text{threshold}}\\) 表示阈值电压，\\(U_{\\text{rest}}\\) 表示静息电压。 可视化 如下图，假设 IF 神经元 15 个时刻的输入信号大小为：[0.2, 0, 0, 0, 0, 0.79, 0.02, 0, 0, 0, 0.9, 0, 0, 0, 0.09, 0.01] ： 膜电位在 t = 6 和 t = 15 时达到阈值并迅速恢复到静息电位，同时神经元的后端突出释放尖峰。 LIF 神经元 LIF（Leaky Integrate-and-Fire）神经元是脉冲神经网络（SNNs）中的一个重要和常见的神经元模型。与最简单的 IF（Integrate-and-Fire）神经元模型不同，LIF 模型增加了对生物神经元电位衰减特性的模拟，使之更贴近真实的生物神经元行为。 其微分方程形式表示如下： \\[ \\tau_{\\text{mem}} \\frac{dU_{i}^{(l)}}{dt} = -(U_i^{(l)} - U_{\\text{rest}}) + RI_{i}^{(l)} \\] 其中 \\(\\tau_{\\text{mem}}\\) 是膜时间常数，它决定了膜电位因泄漏而衰减的速率。 可视化 如下图，假设 LIF 神经元 20 个时刻的输入信号大小为：[0.9, 0, 0, 0, 0.9, 0, 0, 0, 0.9, 0, 0.9, 0, 1.5, 0, 0, 0, 0, 0, 0, 1.5, 1.5] 该 LIF 神经元在 t = 20 时被触发。 前向传播 许多时序神经元在一起就组成了一个完整的 SNN 网络模型，以尖峰组成的时序编码信息在不同神经元之间的突触（Synapse）上进行传播。如下图所示： 对于一个全连接网络而言，第 \\(l + 1\\) 层第 \\(i\\) 个神经元而言，其 \\(t\\) 时刻的输入电流大小满足： \\[ I_i^{(l + 1)}(t) = \\sum_j w_{ji} S_{j}^{(l)}(t) = \\sum_{j \\in E^{(l)}(t)} w_{ji} \\] 其中 \\(w_{ji}\\) 表示该神经元每个后突触的权重，\\(E^{(l)}(t)\\) 表示 \\(t\\) 时刻第 \\(l\\) 层触发的神经元的集合。 梯度替代 在 SNN 中，由于脉冲的二进制特性（神经元要么发射脉冲，要么不发射），这导致了神经元激活函数的不连续性，使得传统的梯度反向传播方法不适用。 为了解决这个问题，研究者们提出了“梯度替代”（Surrogate Gradient）方法。这个方法的核心思想是用一个连续可微的函数来近似原本不连续的激活函数的导数。这个近似的函数被称为“替代梯度”或“伪梯度”。梯度替代的步骤通常包括： 前向传播：在网络的前向传播过程中，使用真实的脉冲激活函数。 反向传播：在计算梯度并进行反向传播时，将不可微的激活函数替换为可微的替代梯度函数。 参数更新：使用这些近似梯度来更新网络的参数。 这种方法的一个常见例子是在 SNN 中使用 Heaviside 阶跃函数作为激活函数，该函数在脉冲发射时是不可微的。为了进行梯度反向传播，研究者们可能会使用 Sigmoid 函数或是带有平滑过渡的阶跃函数来近似 Heaviside 函数的导数。 简单案例 接下来我们将使用 SpikingJelly 框架 实现一个 SNN 全连接识别 MNIST 手写数字的简单案例： 导包 12345678import torchfrom torch import nn, optimfrom torch.nn import functional as Ffrom torch.utils.data import DataLoaderfrom torchvision import datasets, transformsfrom spikingjelly.activation_based import neuron, encoding, surrogate, functionalfrom tqdm import tqdmimport matplotlib.pyplot as plt 模型定义 12345model = nn.Sequential( nn.Flatten(), nn.Linear(28 * 28, 10, bias=False), neuron.LIFNode(tau=2.0, surrogate_function=surrogate.ATan())) 由于 SNN 接收的信号是尖峰组成的时序编码，所以我们还需要一个编码器将静态的图片（\\(C \\times H \\times W\\)）转化为时序尖峰信号（\\(T \\times C \\times H \\times W\\)），这里我们使用泊松编码器（Poisson Encoder）。泊松编码器认为图像每个像素的尖峰发射事件服从泊松分布，其强度 \\(\\lambda\\) 与像素强度相关。 1encoder = encoding.PoissonEncoder() 加载数据集 123456789transform = transforms.Compose([transforms.ToTensor()])train_set = datasets.MNIST(root=&#x27;./data&#x27;, train=True, download=True, transform=transform)val_set = datasets.MNIST(root=&#x27;./data&#x27;, train=False, download=True, transform=transform)batch_size = 64train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False) 训练 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768num_epochs = 16T = 32device = &#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;model.to(device=device)optimizer = optim.Adam(model.parameters(), lr=1e-3)criterion = nn.MSELoss()train_loss_rec = []train_acc_rec = []val_loss_rec = []val_acc_rec = []for epoch in range(1, num_epochs + 1): avg_loss = 0 avg_acc = 0 model.train() for img, label in tqdm(train_loader, desc=f&#x27;Training Epoch [&#123;epoch&#125;/&#123;num_epochs&#125;]&#x27;, unit=&#x27;batch&#x27;): optimizer.zero_grad() img = img.to(device=device) label = label.to(device=device) fr_out = 0.0 for t in range(T): encoded_img = encoder(img) fr_out += model(encoded_img) fr_out /= T loss = criterion(fr_out, F.one_hot(label, 10).float()) loss.backward() optimizer.step() functional.reset_net(model) avg_loss += loss.data.item() acc = (torch.argmax(fr_out, dim=1) == label).sum() / label.size(0) avg_acc += acc.data.item() avg_loss /= len(train_loader) avg_acc /= len(train_loader) train_loss_rec.append(avg_loss) train_acc_rec.append(avg_acc) print(f&#x27;Training Loss: &#123;avg_loss :.4&#125;&#x27;) print(f&#x27;Training Accuracy: &#123;avg_acc :.4&#125;&#x27;) avg_loss = 0 avg_acc = 0 model.eval() with torch.no_grad(): for img, label in val_loader: img = img.to(device=device) label = label.to(device=device) fr_out = 0.0 for t in range(T): encoded_img = encoder(img) fr_out += model(encoded_img) fr_out /= T functional.reset_net(model) loss = criterion(fr_out, F.one_hot(label, 10)) avg_loss += loss.data.item() acc = (torch.argmax(fr_out, dim=1) == label).sum() / label.size(0) avg_acc += acc.data.item() avg_loss /= len(val_loader) avg_acc /= len(val_loader) val_loss_rec.append(avg_loss) val_acc_rec.append(avg_acc) print(f&#x27;Validation Loss: &#123;avg_loss :.4&#125;&#x27;) print(f&#x27;Validation Accuracy: &#123;avg_acc :.4&#125;&#x27;) 训练结果可视化 12345678910111213141516171819202122232425epoch_t = range(1, num_epochs + 1)plt.figure(figsize=(10, 5))plt.subplot(1, 2, 1)plt.title(&#x27;Loss-Epoch&#x27;)plt.xlabel(&#x27;Epoch&#x27;)plt.ylabel(&#x27;Loss(MSE)&#x27;)plt.plot(epoch_t, train_loss_rec, label=&#x27;Training&#x27;)plt.plot(epoch_t, val_loss_rec, label=&#x27;Validation&#x27;)best_idx = torch.argmin(torch.tensor(val_loss_rec)).item()plt.scatter(best_idx + 1, val_loss_rec[best_idx], color=&#x27;red&#x27;, marker=&#x27;*&#x27;)plt.text(best_idx + 1, val_loss_rec[best_idx], f&#x27;epoch-&#123;best_idx + 1&#125;&#x27;)plt.legend()plt.subplot(1, 2, 2)plt.title(&#x27;Accuracy-Epoch&#x27;)plt.xlabel(&#x27;Epoch&#x27;)plt.ylabel(&#x27;Accuracy&#x27;)plt.plot(epoch_t, train_acc_rec, label=&#x27;Training&#x27;)plt.plot(epoch_t, val_acc_rec, label=&#x27;Validation&#x27;)best_idx = torch.argmax(torch.tensor(val_acc_rec)).item()plt.scatter(best_idx + 1, val_acc_rec[best_idx], color=&#x27;red&#x27;, marker=&#x27;*&#x27;)plt.text(best_idx + 1, val_acc_rec[best_idx], f&#x27;epoch-&#123;best_idx + 1&#125;&#x27;)plt.legend()plt.show()","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"SNN","slug":"SNN","permalink":"http://example.com/tags/SNN/"}]},{"title":"数据链路层——MAC 子层","slug":"数据链路层——MAC-子层","date":"2023-12-11T01:42:37.000Z","updated":"2023-12-19T00:46:54.095Z","comments":true,"path":"2023/12/11/数据链路层——MAC-子层/","link":"","permalink":"http://example.com/2023/12/11/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E2%80%94%E2%80%94MAC-%E5%AD%90%E5%B1%82/","excerpt":"","text":"MAC 子层 什么是 MAC 子层？ MAC（Medium Access Control）子层，是数据链路层的一部分，主要负责在物理介质上传输数据包。 在 OSI 模型中，数据链路层被分为逻辑链路控制（LLC）子层和媒体访问控制（MAC）子层，其中： LLC 子层负责管理服务质量，例如流量控制和错误检测（不同于MAC层的错误检测）。这包括重发机制，以确保信息的正确传输等；而 MAC 子层处理物理地址（MAC 地址），用于在同一网络内识别设备，它负责封装数据，在数据包周围添加帧头和帧尾，包括源和目的地的物理地址。 总结来说，LLC 子层主要负责管理链路层与网络层之间的接口和服务质量，而 MAC 子层则集中于物理地址的处理、数据帧的封装和媒体访问控制。这种分层使得数据链路层可以灵活地支持多种不同类型的物理网络技术，同时为上层网络提供统一的接口和服务。 媒体访问技术 两类常见的媒体访问技术： 预约协议（Reservation Based Protocol） 需要知道网络的拓扑结构 无冲突（Collision Free） Eg：令牌环、TDMA 争抢协议（Contension Based Protocol） 不需要知道网络的拓扑结构 各个节点会竞争资源，可能产生冲突 Eg：ALOHA、CSMA 令牌环 一种古老的技术，定义了一种短帧，称为令牌（Token）。令牌环网络的拓扑结构呈环状，所有计算机连接成一个闭合的环路。每台计算机都直接连接到环上，并通过物理介质（通常是双绞线或光纤）相互连接。在令牌环中令牌以固定速率在网络中沿着环路传递。只有拥有令牌的计算机才能发送数据，其他计算机必须等待令牌传递到它们之前才能发送。 优点：不会产生冲突 缺点：一个节点失效会影响到整个信道 TDMA TDMA（Time Division Multiple Access）技术将传输过程分成不同的时槽（Time Slot），每个时槽只允许一个用户传输信息。TDMA 在大多数 2G 系统中使用。 优点：和令牌环一样，TDMA 也能避免冲突 缺点：某个节点如果长期没有请求，则可能造成信道浪费 ALOHA 不同于令牌环和 TDMA，ALOHA 属于冲突协议，即每个节点会竞争资源。 纯 ALOHA 纯 ALOHA 协议相当简单，它是一种无协商（Without coordination）的协议，每个节点可以在任意时刻传输信息，如果在规定时间没有收到 ACK，则重传该帧。 想象一根总线拓扑结构，所有节点可以在任何时刻传输信息，则无可避免会产生冲突： 当两个不同的节点在同一时刻传输信息就会发生冲突，脆弱时间（Vulnerable Time）等于 \\(2 \\times T_{fr}\\)，这里的 \\(T_{fr}\\) 指帧传递时间（Frame transmission time）。 Slotted ALOHA 时槽 ALOHA（Slotted ALOHA）就是在纯 ALOHA 协议的基础上，把时间段分为许多等长的时槽，每一帧只允许在时槽的起始点开始传输，这么设计之后，所有的帧要么错开（Miss），要么重合（Overlap）。 脆弱时间：\\(T_0\\)，这里的 \\(T_0\\) 指时槽的长度。 CSMA CSMA，全称 Carrier Sense Multiple Access，这里的 Carrir Sense 指的就是监听信道，其基于一个假设，就是节点可以监听信道是否空闲。 传统 CSMA 如果信道是空闲的（Idle），节点会传输信息 如果信道是繁忙的（Busy），节点则会一直等待直到信道空闲 这是否意味着 CSMA 就不会产生冲突呢？答案是否定的，如果两个节点恰巧在同一时刻传输帧，则会发生冲突： 和 ALOHA 一样，CSMA 通过 ACK 确定是否发送冲突，如果节点在发送帧后未在指定时间内收到 ACK，则确定为帧可能发生冲突或出错，则重传帧。 脆弱时间：\\(\\tau\\)，\\(\\tau\\) 在这里指传输时延。 CSMA 还可以分为两种类型： 非坚持 CSMA（Nonpersistant CSMA） 在非坚持 CSMA 中，如果节点检测到信道是繁忙的，则会随机等待一定的时间，然后重新监听信道。 坚持 CSMA（Persistant CSMA） 在坚持 CSMA 中，如果节点检测到信道是繁忙的，则会一直监听信道直到信道变得空闲然后传输帧。 在坚持 CSMA 中，还可以细分两类： 1-坚持 CSMA（1-persistent CSMA） 检测到信道空闲，则立马发送帧 在低负载的情况下可以实现高吞吐量（High throughput）和低时延（Low delay），而在高负载的情况下可能会造成低吞吐量，因为所有节点在信道空闲的时候都会争抢着发送帧，跟有可能造成冲突。 p-坚持 CSMA（p-persistant CSMA） 检测到信道空闲，以概率 p（0 &lt; p &lt; 1）发送帧 在高负载的情况下可以实现高吞吐量。但其在低时延的情况下可能会增大时延。 CSMA/CD CSMA/CD（Carrier Sense Multiple Access with Collision Detection），在 CSMA 的基础上添加了冲突检测（Collision Detection）。 这是什么意思呢，就是说在 CSMA 的基础上给了节点能够在传输过程中检测到冲突的能力，一旦检测到冲突，改节点会立刻舍弃此次传输。具体来说步骤如下： 如果冲突被检测，则取消传输（Cease transmission）并且传输一个强化信号（Jam signal）而不是传递完整个帧。 在发送强化信号之后，节点随机等待一段时间然后重新开始，这一步我们称为退避（Back-off）。 使用这个机制，可以节约时间和带宽。 CSMA/CD 最差情况下每个节点要多长时间检测到冲突：答案是 \\(2 \\times \\tau\\)。 假设节点 A 和节点 B 是分布在总线上两端的两个节点，A 在检测到信道空闲后发送帧，在即将到 B 时 B 也发送了一帧，此刻发送冲突，A 需要两倍传输时延才能检测到冲突。 指数退避（Exponential Back-off） 在检测到冲突后，节点会退避并且重新等待一段随机时间。这里的随机时间是如何定义的呢？ 我们定义 \\(K = min\\{10, \\text{number of attempt}\\}\\)，每次退避时从区间 \\([0, 2 ^ k)\\) 中随机选取一个整数作为退避系数 \\(r\\)，退避时间 = \\(r \\hat t\\)，这里的 \\(\\hat t\\) 表示基本重传时间（Basic retransmission time），一般是 51.2 \\(\\mu s\\)。 在 16 次冲突后，改请求就会取消，这一帧会被舍弃。 完整流程： 参考协议：IEEE 802 IEEE 802 是一种包括了物理层和数据链路层的网络协议。不同的 IEEE 802 子标准针对不同的局域网和城域网技术，如以太网、无线局域网（Wi-Fi）、WiMAX 等，都基于这一模型进行规范和实现。 以太网 以太网（Ethernet）是一种常见的局域网（LAN）技术，用于在计算机和网络设备之间进行数据通信。以太网起源于 20 世纪 70 年代，是由 Xerox、Intel 和 Digital Equipment Corporation（DEC）共同开发的，后来被广泛采用，并成为最常见的局域网技术之一。 以太网支持多种数据传输速度，包括10 Mbps（常称为10BASE-T）、100 Mbps（100BASE-TX）、1 Gbps（1000BASE-T）和更高速度。IEEE 802.3系列标准定义了以太网的规范，不同速度的以太网遵循不同的 IEEE 802.3 子标准。 NIC 网卡（Network Interface Card，NIC），是一种用于建立和管理计算机连接到设备，其包含了物理层和数据链路层（LLC 与 MAC）的功能，每张网卡都有一个唯一的物理地址，称为 MAC 地址。 MAC 地址 每个 MAC 地址由 6 个字节组成，前 3 个字节表示供应商的标识符，后 3 个字节表示供应商提供的序列号。 Eg：1c:57:dc:68:23:0d 传统以太网 拓扑结构：逻辑上都是总线型的。 传统以太网比如 10Base-T 通过一个集线器（Hub）连接所有主机： 从上述结构可知，每一台主机发送的帧所有其他主机都可以接收，看上去拓扑结构是星型的，实际上还是总线型的。 使用的媒体访问技术：CSMA/CD 传统以太网使用 CSMA/CD 作为媒体访问技术，更具体来说，使用的是 1-persistent CSMA/CD 技术，这个前文已经说过，再次就不赘述了。 以太网的数据帧 Preamble：前导码，用于时钟同步（Clock synchronization），SFD 用于标记帧的开始。 Address：包括目的地和出发地的 6 字节 MAC 地址，由于以太网是广播链路传播，因此地址是必须的。 如果 Destination address 的值为 FF:FF:FF:FF:FF:FF，那就说明该帧是发送给全部节点的，所有计算机都会接收。 Type：指定帧的类型，IPv4 或 IPv6。 Data and padding：数据和填充，这部分的大小在 46 字节到 1500 字节。 这部分至少 46 字节就是为了保证整个帧大小不小于 64B，这么设计的目的就是让帧的传输时间不少于传输时延。否则 CSMA/CD 有时候将无法检测到冲突。 CRC：校错码。 交换以太网 交换以太网在传统以太网的基础上将集线器改成了交换机（Switch）。 与传统的以太网集线器（Hub）不同，交换机能够根据数据帧中的目标 MAC 地址，将数据帧有针对性地发送到正确的端口，而不是广播给所有连接设备。为了实现有针对性的数据帧交换，交换机维护一个 MAC 地址表，记录了各个设备的 MAC 地址与相应端口之间的映射关系。当数据帧到达交换机时，它会查找 MAC 地址表以确定如何转发数据帧。 集线器（Hub）属于半双工通信，这是因为它在数据传输方面有一些限制和局限性。半双工通信意味着在同一时间内，设备只能进行单向的数据传输，要么发送数据，要么接收数据，而不能同时进行发送和接收。 相比之下，交换机（Switch）是一种支持全双工通信的设备，因为它具有智能的数据帧处理功能，可以在不同的端口之间建立虚拟电路，允许同时进行双向通信。交换机更高效、可靠，并且不容易发生碰撞，因此在现代网络中广泛使用，取代了集线器。集线器通常仅用于旧的网络中或特定的测试和诊断场景中。由于在交换机中不存在资源的争抢，也就不需要像 CSMA/CD 这样的介质访问技术。 快速以太网 快速以太网（Fast Ethernet）是对传统以太网的升级，旨在提供更高的数据传输速度。 快速以太网支持 100 Mbps（兆位每秒）的数据传输速度，相对于传统以太网的 10 Mbps 来说，它提供了更快的网络连接速度。因此，它通常被称为 100BASE-T。 Gigabit 以太网 Gigabit 以太网是一种高速的以太网技术，提供了 1 Gbps 的传输速度，用于满足高带宽需求的各种应用，如企业网络、数据中心和多媒体传输。它是现代网络基础设施的关键组成部分，为快速和可靠的数据传输提供了支持。 无线局域网 为什么 CSMA/CD 不适用于无线通信？ CSMA/CD 不适用于无线通信是因为其可能产生两个问题： 隐藏基站问题（Hidden station problem） 如上图所示，假设 A 要传输帧给 B，于此同时 C 也要传输帧给 B，由于无线信号的范围覆盖问题，A 和 C 均不能接收到彼此的信号，因此 A 和 C 都无法检测到 B 处发生了冲突。 暴露基站问题（Exposed station problem） 如上图所示，B 要传输帧给 A，C 要传输帧给 D，C 在发送帧时检测到与 B 传输的帧发送冲突，于是便会立刻停止帧的传输。而事实上 C 传输帧给 D 不收到 B 的影响，因为 B 的帧无法传输到 D，实际上不存在冲突问题。 以上两种情况可以总结为在无线通信中检测不到冲突和错误判断了冲突。 MACA 为了解决隐藏站的问题，人们提出了 MACA（Multiple Access Collision Avoidance），不同于冲突检测，该技术强调冲突避免。 MACA 的具体是通过基站之间的握手机制实现的，步骤如下： 若 S 要传递帧给 R，那么首先 S 会传输一个称为 RTS 的帧 终点 R 收到 RTS 后，会传输一个 CTS S 接收到 CTS 后传输帧给 R R 成功接受帧后返回 ACK 给 S 具体流程 A 与 B 建立通信，发送 RTS，C 和 E 收到 RTS 帧，接下来将保持沉默； B 收到 A 传输的 RTS，返回一个 CTS，D 和 E 收到 CTS 帧，接下来将保持沉默。 MACA 为什么可以解决隐藏站的问题？ 节点只收到 CTS，未收到 RTS：节点在接收节点 R 的范围内，不在发送节点 S 的范围内，所以该节点是一个隐藏站，也就是说该节点在 S 到 R 的传输过程将无法传输信息。如上图，D 是一个隐藏站，在 A 与 B 通信的过程中会被沉默。 注意：MACA 无法解决暴露站的问题，如上图，C 是一个暴露站，其通信是不受到影响的，但其错误判断可能会产生冲突从而造成信道浪费。 LAN 架构 LAN 架构主要可以分为以下两个部分： 接入点（Access Point，AP）： AP 是一种网络设备，通常是一个无线路由器或无线接入设备，用于创建一个无线局域网，比如基站。它允许无线设备（如笔记本电脑、智能手机、平板电脑）连接到有线局域网或互联网。AP 负责将有线网络信号转换成无线信号，并为连接到它的无线设备提供网络连接。它通常有一个或多个无线接口（通常是 Wi-Fi），以允许多个设备连接。 基本服务集（Basic Service Set，BSS）： BSS 是一个概念，用于描述一个无线局域网中的基本单元。每个 BSS 由一个 AP（或无线路由器）和与之连接的无线设备组成。BSS 通常包括一个无线网络的一个小覆盖区域，所有连接到同一个 AP 的设备属于同一个 BSS。在同一个 BSS 内，设备可以相互通信。BSS 还有一个唯一的标识符，称为 BSSID，通常是 AP 的 MAC 地址，用于在网络中唯一标识一个 BSS。 Ad hoc Ad hoc，也就是自组织网络，是一种无线 LAN 模式，其不依赖基站，这种网络只能通过节点的连接覆盖来将数据传输给其他节点，所有节点将自己组织成网络。 寻找可用节点的两种方法 被动扫描（Passive Scanning） 被动扫描是一种相对较简单的方法，其中无线设备只是监听周围的 Wi-Fi 信号，而不主动发送请求。它通常用于发现并显示附近可用的 Wi-Fi 网络列表，以供用户选择连接。无线设备在特定时间间隔内监听 Wi-Fi 信道上的信号帧，以检测是否有 AP 广播它们的信标帧（Beacon Frames）。这些信标帧包含有关 AP 的信息，如 SSID（网络名称）、BSSID（AP的MAC地址）、信号强度等。一旦设备收到信标帧，它就可以在扫描结果中列出相应的 Wi-Fi 网络，以便用户选择连接。 主动扫描（Positive Scanning） 主动扫描涉及到无线设备主动发送探测请求来查找附近的 Wi-Fi 网络。这个请求通常是一个 802.11 探测请求帧（Probe Request Frame），其中包含了设备想要连接的 SSID 信息。接入点在收到探测请求后，可以响应并发送一个探测响应帧（Probe Response Frame），其中包含有关网络的信息，如支持的加密方法、信号强度、频道等。主动扫描允许设备更主动地发现附近的Wi-Fi网络，而不仅仅是等待信标帧的广播。这对于设备在新环境中快速连接到 Wi-Fi 网络或在切换网络时非常有用。 CSMA/CA CSMA/CA（Carrier Sense Multiple Access with Collision Avoidance）是一种用于无线通信的可以避免冲突的载波监听多路访问技术。 工作流程： 不同于 persistent CSMA，802.11 Sender 不会在信道空闲的第一时刻发送数据，而是等待一个时间段 DIFS（Distributed Inter-Frame Space）后发送数据。 如果检测到信道处于繁忙状态，则会随机等待一个退避时间。如果没有收到 ACK 应答，则认为产生了冲突或错误，此时会增大随机退避区间，这里的增加机制和 CSMA/CD 是一样的。 同时，802.11 Receicer 在收到数据帧后会等待一个时间段 SIFS（Short Inter-Frame Space）后再传输 ACK。 为了解决隐藏站和暴露站的问题，CSMA/CA 还可以使用 MACA 中的 RTS/CTS 握手机制： 802.11 帧结构","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"数据链路层","slug":"数据链路层","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"},{"name":"媒体访问控制","slug":"媒体访问控制","permalink":"http://example.com/tags/%E5%AA%92%E4%BD%93%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"name":"ALOHA","slug":"ALOHA","permalink":"http://example.com/tags/ALOHA/"},{"name":"CSMA","slug":"CSMA","permalink":"http://example.com/tags/CSMA/"},{"name":"以太网","slug":"以太网","permalink":"http://example.com/tags/%E4%BB%A5%E5%A4%AA%E7%BD%91/"}]},{"title":"线程与并发","slug":"线程与并发","date":"2023-12-06T10:03:13.000Z","updated":"2023-12-31T04:03:55.227Z","comments":true,"path":"2023/12/06/线程与并发/","link":"","permalink":"http://example.com/2023/12/06/%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/","excerpt":"","text":"线程 线程与进程的关系 回顾：什么是进程？ 进程（Process）是程序运行的实例。一个进程由当前状态和系统资源组成。 当前状态（Current State） 包括 CPU 寄存器、栈指针、PC 指针等。 系统资源（System Resources） 地址空间、I/O 状态等。 每个进程的系统资源都是受到保护的。 什么是线程？ 线程（Thread）是进程中的顺序执行流（Sequential execution stream），进程的一组线程共用进程的系统资源。 多线程 &amp; TCB 多线程（Multithread）是一种技术，即一个程序的进程可以有多个不同的并发线程。 就如进程会将其信息存储在 PCB 中，每个线程也有一个维护自身信息的数据结构 —— TCB（Thread Control Block） 那些线程的私有状态会保存在 TCB 内，如： CPU 寄存器（包括 PC 寄存器） 程序执行的栈指针（Execution stack pointer） 调度信息（包括状态、优先级、CPU 执行时间等） ... 操作系统将 TCB 存储在内核内存中，以便能够轻松地访问和管理所有线程的信息。这样，操作系统可以在需要时对线程进行调度、切换线程的上下文以及管理线程的状态等操作，而这些操作需要访问 TCB 中存储的信息。 每个 PCB 都会指向多个 TCB： 线程切换可以分为两种： 在同一个 PCB 内（Within a PCB），这种切换地址空间保持一致； 在不同的 PCB 之间（Across PCBs），这种切换需要改变地址空间。 多线程的优点 不同于进程的上下文切换，线程切换（Thread Switch）开销低很多； 线程的创建和取消都比进程快很多； 线程之间可以共享内存，更利于通信。 多核操作系统中的线程 多核操作系统中两种线程调度的方式： 每个核维护自己的线程队列 需要更有效的高速缓存 需要平衡的调度策略 所有线程都放置在一个单独的队列内 有可能会导致竞态条件，需要锁机制 处理器亲和性（Processor Affinity）是计算机操作系统中的一个概念，它用于指定一个进程或线程在多核处理器系统中执行时应该绑定到哪个特定的处理器核心上。处理器亲和性允许开发者或系统管理员控制进程或线程的执行位置，以优化性能、降低延迟或满足特定的系统需求。 亲和性有两种类型：软亲和性（Soft Affinity）和硬亲和性（Hard Affinity）。 软亲和性是指系统尝试将进程/线程保持在同一个处理器上运行的策略，但不保证一定能够做到。例如，由于处理器之间的负载平衡，进程可能会迁移到其他处理器。 硬亲和性指的是某些系统提供的系统调用，允许进程指定一组处理器来运行。这意味着进程可以绑定在特定的处理器上，不会被系统迁移。 许多系统同时提供这两种类型的亲和性设置。 Linux系统中的 sched_setaffinity() 是一个系统调用，用于实现硬亲和性。通过这个调用，进程可以指定一个或多个处理器，以便系统将其调度到这些处理器上运行。 sched_setaffinity() 函数接受三个参数： pid_t pid ：进程ID。如果该值为0，则表示当前进程。 size_t cpusetsize ：cpu_set_t 结构大小，通常为系统 CPU 数量的字节大小。 const cpu_set_t *mask ：指向 cpu_set_t 结构的指针，该结构定义了进程可以运行的 CPU 集合。使用 CPU 集合，可以指定一个或多个 CPU 核心。 ULT &amp; KLT 就像进程分为内核进程和用户进程一样，线程也有同样的分类： 内核级别线程（Kernel Level Thread，KLT） KLT 是由操作系统内核管理和调度的线程。每个线程都有一个对应的内核线程。 所有现代操作系统都支持 KLT 直接被内核控制 每个 KLT 都能独立运行或者被阻塞 一个进程可以有多个 KLT 在等待不同的事件 缺点 相比于 ULT 更 “昂贵”，因为要经常和内核打交道 用户级别线程（User Level Thread，ULT） ULT 是在用户空间中由应用程序或线程库管理的线程。操作系统对它们一无所知，只会认为应用程序只有一个线程在运行。 ULT 相比于 KLT 更加轻量级，用户的程序自身一般就能提供进 ULT 的线程调度，由于不需要内核的参与，ULT 的切换一般更快 ULT 在相对于彼此而言，可能会以非抢占（Non-preemptive）的方式进行调度 缺点： 一个线程处于 I/O 阻断，所有线程都会被阻断（多对一模式） 内核无法干预 ULT 的调度，这意味着其不能利用多核处理器的优势 由于操作系统对用户级线程一无所知，它无法将不同的 ULT 分配给不同的处理器核心并进行并行执行。因此，无论多核处理器上有多少个核心，操作系统只会认为应用程序只有一个线程在运行。这限制了 ULT 利用多核处理器的能力。 三种线程模式（Threading Model） 一对一（One-to-One）： 在这个模型中，每个用户级线程都直接映射到一个内核级线程。 这种模型的优点是一个线程在执行系统调用或者进行阻塞操作时，不会影响到其他线程。 这是 Linux 和 Windows 系统中常用的模型，它可以很好地利用多核处理器的并行处理能力。 但是，因为每个线程都需要内核级的结构，所以线程的数量可能受到系统资源的限制。 多对一（Many-to-One）： 在这个模型中，多个用户级线程映射到单个内核级线程。 优点是线程切换和管理的开销很小，因为这些操作都在用户空间完成。 缺点是如果任何一个线程执行阻塞系统调用，整个进程都会被阻塞，因为操作系统只看到一个线程。 这种模型不适合多核处理器，因为它无法同时在多个核心上并行执行多个线程。 多对多（Many-to-Many）： 这个模型结合了前两者的优点。 允许多个用户级线程映射到多个内核级线程，提供了很大的灵活性。 这种模型既可以防止一个线程的阻塞操作影响其他线程，也可以利用多核处理器的并行处理能力。 但是，这种模型的管理相对复杂，调度也更为困难，因为需要在用户和内核空间之间协调线程的管理。 线程交错 线程交错（Thread Interleaving）是指在多线程编程中，多个线程的执行在时间上交错进行的现象。当一个计算机系统具有多个处理核心（例如多核处理器）或者操作系统采用分时调度策略时，多个线程之间会竞争执行权，导致它们交替运行，这就是线程交错。 并行与并发 二者区别 并行（Parallelism）和并发（Concurrency）是两个在多任务处理领域常被讨论的概念，它们描述了系统处理多个任务的方式，但它们指的并不是相同的情形。 并行（Parallelism）： 并行处理指的是系统同时进行多个任务的能力。这通常涉及到多核或多处理器的系统，其中每个核或处理器可以同时执行不同的任务或同一个任务的不同部分。 并行性的关键在于性能的提升，因为它可以显著减少完成多个任务的总时间。 例如，在一个四核处理器上，四个独立的计算可以同时进行，每个核心处理一个计算。 并发（Concurrency）： 并发处理是指系统能够处理多个任务的能力，但不一定是同时进行的。在单核处理器上，操作系统可以通过任务切换，使得用户感觉到多个任务似乎是同时执行的。 并发性不一定提高性能（相对于单任务来说），而是关于多任务管理的效率。并发可以在单核或多核机器上实现。 例如，一个服务器运行多个进程，通过快速切换来服务多个客户端，即使在任何给定的微秒内，只有一个进程在执行。 简而言之，并行是关于同时做多件事情（提高吞吐量），而并发是关于处理多件事情（管理共享资源的访问）。并行是并发的一个子集；所有并行系统都是并发的，但不是所有并发系统都是并行的。并发强调的是正确性和管理多个同时活动的任务，而并行强调的是性能和做相同的事情来加速计算。 并发中的一些概念 竞态条件 竞态条件（Race Condition）是指一种在并发程序中的错误，它出现在当程序的结果依赖于线程的调度顺序的情况，其强调结果的不可预判性。 互斥 互斥（Mutual Exclusion）指一个资源无法被多个线程共享，即一个线程在完成某个任务直到释放资源之前，其他进程都不能访问该资源。 临界区 临界区（Critical Region）就是程序中需要互斥的部分。 为了实现临界区，操作系统会给一些资源分配锁（Lock），当一个线程访问该资源时会拿到该资源的锁，此时其他线程均无法访问而被放置在一个入队列集合。 入队列集合（Entry Set Queue）是一个数据结构，用于存储等待获取锁的线程。每当一个线程尝试获取锁但锁已经被其他线程占用时，该线程会被加入到集合中，等待锁释放。 很多编程语言给了这个抽象概念的具体实现方式，比如 Java 中的 synchronized 关键字。 死锁 死锁（Deadlock）是指在多线程或多进程环境中，两个或多个线程（或进程）由于相互等待对方释放资源而陷入无法继续执行的状态。在死锁状态下，每个线程都在等待其他线程释放资源，但由于相互之间的依赖关系，它们都无法继续执行下去。死锁是一种常见的并发编程问题，可以导致系统停滞，无法正常运行。 死锁通常涉及以下几个关键要素： 互斥（Mutual Exclusion）：多个线程或进程竞争获取某个资源，但同一时刻只能有一个线程或进程占有资源。 请求和保持（Hold and Wait）：线程在持有某些资源的同时，又请求其他资源，但由于资源被其他线程占有，请求线程必须等待。 不可抢占（No Preemption）：资源只能由占有它的线程主动释放，而不能被强制抢占。 循环等待（Circular Wait）：多个线程之间形成了一个循环链，每个线程都在等待下一个线程释放资源，从而造成了死锁。 以上四个条件是死锁的必要条件，缺一不可。 分配图 分配图（Allocation Graph）是一种检测死锁的方式，分配图中一共有两类节点：一是线程，而是资源，如下图。 分配图中所有的边都是有向的： 从线程指向资源的边称为请求边（Request Edge），表示线程正在请求某个资源。 从资源指向线程的边称为分配边（Assignment Edge），表示该资源正在被某个线程占有。 再上图中，资源和线程形成了一个回环，产生了死锁，但并不是有回环就一定会有死锁。关于线程分配图中的回环与死锁之间的关系，有以下几点需要了解： 存在回环不一定意味着死锁：虽然死锁的一个典型特征是资源分配图中的回环，但并不是所有回环都表示死锁。关键在于这个回环是否包含了所有相关资源和线程。如果一个线程（或几个线程）在回环中，但是它们还可以访问其它资源来继续运行，那么这个回环就不一定代表死锁。 如果都只有一个实例，那么回环意味着死锁 如果回环中的资源有很多个实例，那么就不意味着死锁 如下图： 图中存在回环：\\(T_1 \\to R_1 \\to T_3 \\to R_2 \\to T_1\\)，但注意到 \\(T_4\\) 在这里没有请求，说明 \\(T_4\\) 可以正常运行，那么当 \\(T_4\\) 运行结束后 \\(R_2\\) 会被释放，\\(T_3\\) 便可以成功获得 \\(R_2\\) 的请求， 从而打破循环等待，所以不会产生死锁。 没有回环通常意味着没有死锁：如果资源分配图中没有回环，那么一般可以认为系统中没有死锁。这是因为死锁的一个条件是循环等待，这在资源分配图中表现为回环。 因此，线程资源分配图存在回环是产生死锁的必要不充分条件。 如何避免死锁 要避免死锁，就要从死锁产生的四个条件入手，只要破除四个条件中的任何一个就可以成功解决死锁的问题。 解决「互斥」 一种解决方案是让资源可共享，这样就不会有互斥的需求。在某些情况下，这是可能的，例如，多个线程可以同时读取同一个只读文件，因为它们不会对文件内容进行修改，从而不会发生冲突。这个想法很理想，但多数时候不允许。 解决「请求和保持」 我们可以考虑一次性让一个线程拿到所有它请求的资源，阻断其他占取它资源的线程。这样也不现实，可能会导致每个线程在等待资源上浪费过多时间。 解决「不可抢占」 我们可以考虑运行线程抢占资源，从而打破循环请求。但这样又可能导致线程饥饿。 解决「循环等待」 我们可以定义一个严格的资源分配顺序，从而避免循环等待的情况。 例如我们可以给资源进行编号，要求每个线程以递增的枚举顺序请求资源来解决这个问题。 如上图所示，假如 \\(i &lt; j\\)，那么线程 A 可以请求 \\(j\\)，但线程 \\(B\\) 无法请求 \\(i\\)，从而避免了死锁。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"死锁","slug":"死锁","permalink":"http://example.com/tags/%E6%AD%BB%E9%94%81/"}]},{"title":"基于 Transfomer 的预训练模型 | GPT","slug":"Transfomer-家族之-GPT","date":"2023-12-03T08:22:42.000Z","updated":"2023-12-04T11:23:50.125Z","comments":true,"path":"2023/12/03/Transfomer-家族之-GPT/","link":"","permalink":"http://example.com/2023/12/03/Transfomer-%E5%AE%B6%E6%97%8F%E4%B9%8B-GPT/","excerpt":"","text":"GPT（Generative Pre-trained Transformer）是一个由 OpenAI 开发的先进的自然语言处理（NLP）模型，专门用于处理各种语言任务。它基于 Transformer 架构，一种在 NLP 领域非常有效的深度学习模型结构。GPT 模型在多种语言任务上表现出色，包括但不限于：文本生成、问答系统、机器翻译、文本摘要、感情分析等。 要注意的是，不同于 BERT，GPT 是一个自回归模型，使用了监督学习的方式，进行从左到右的语言建模，因此 GPT 在生成时只能查看之前的单词（单向上下文）。 基本结构 由于 GPT 任务的特殊性，其只保留了 Transformer 的解码器（Decoder），舍弃了编码器（Encoder）。所以如果能够理解 Transformer，那么理解 GPT 模型自然也就不难了。 Decoder 层面的自注意力机制允许模型在生成每个新词时看到之前的所有词，这对于生成连贯的文本至关重要。而 Encoder 部分是为了编码输入序列到一个固定长度的连续表征中，这在 GPT 的预训练目标中并不是必要的。此外，省略 Encoder 可以简化模型的结构，并专注于提高文本生成能力。 两种文本生成策略 贪心解码： 在每一步，模型选择概率最高的单词作为下一个单词。 这种方法速度快，计算成本低，但可能不是最佳选择，因为它不考虑整体句子的最佳组合，可能导致局部最优解。 集束搜索解码： 在每一步保持多个可能的候选序列（称为 “集束” 或 “beam”）。 集束的宽度（Beam width）决定了在每一步有多少候选序列被考虑。 集束搜索会在每个时间步骤考虑多个可能的继承候选，并在序列结束时选择整体得分最高的序列。 这种方法更能找到质量高的序列，但计算成本更高，速度也较慢。 代码实现 GPT Decoder 123456789101112131415161718192021222324252627282930313233343536373839# ...class DecoderLayer(nn.Module): def __init__(self): super(DecoderLayer, self).__init__() self.self_attn = MultiHeadAttention() # 多头自注意力层 self.feed_forward = FFN() # 位置前馈神经网络层 self.norm1 = nn.LayerNorm(d_embedding) # 第一个层归一化 self.norm2 = nn.LayerNorm(d_embedding) # 第二个层归一化 def forward(self, dec_inputs, attn_mask=None): # 使用多头自注意力处理输入 attn_output, _ = self.self_attn(dec_inputs, dec_inputs, dec_inputs, attn_mask) # 将注意力输出与输入相加并进行第一个层归一化 norm1_outputs = self.norm1(dec_inputs + attn_output) # 将归一化后的输出输入到位置前馈神经网络 ff_outputs = self.feed_forward(norm1_outputs) # 将前馈神经网络输出与第一次归一化后的输出相加并进行第二个层归一化 dec_outputs = self.norm2(norm1_outputs + ff_outputs) return dec_outputsn_layers = 6 # 设置 Decoder 的层数class Decoder(nn.Module): def __init__(self, corpus): super(Decoder, self).__init__() self.src_emb = nn.Embedding(corpus.vocab_size, d_embedding) # 词嵌入层（参数为词典维度） self.pos_emb = nn.Embedding(corpus.seq_len, d_embedding) # 位置编码层（参数为序列长度） self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)]) def forward(self, dec_inputs): positions = torch.arange(len(dec_inputs), device=dec_inputs.device).unsqueeze(-1) # 位置信息 inputs_embedding = self.src_emb(dec_inputs) + self.pos_emb(positions) # 词嵌入与位置编码相加 attn_mask = get_attn_subsequent_mask(inputs_embedding).to(dec_inputs.device) # 生成自注意力掩码 dec_outputs = inputs_embedding # 初始化解码器输入，这是第一层解码器层的输入 for layer in self.layers: # 每个解码器层接收前一层的输出作为输入，并生成新的输出 # 对于第一层解码器层，其输入是 dec_outputs，即词嵌入和位置编码的和 # 对于后续的解码器层，其输入是前一层解码器层的输出 dec_outputs = layer(dec_outputs, attn_mask) # 将输入数据传递给解码器层 return dec_outputs # 返回最后一个解码器层的输出，作为整个解码器的输出 文本生成 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394from nltk.tokenize import word_tokenize # 分词工具# 贪心搜索def generate_text_greedy_search(model, input_str, max_len=5): # 将模型设置为评估（测试）模式，关闭 dropout 和 batch normalization 等训练相关的层 model.eval() # 使用 NLTK 工具进行词汇切分 input_str = word_tokenize(input_str) # 将输入字符串中的每个 token 转换为其在词汇表中的索引, 如果输入的词不在词表里面，就忽略这个词 input_tokens = [model.corpus.vocab[token] for token in input_str if token in model.corpus.vocab] # 检查输入的有意义的词汇长度是否为 0 if len(input_tokens) == 0: return # 创建一个列表，用于存储生成的词汇 output_tokens = input_tokens # 禁用梯度计算，以节省内存并加速测试过程 with torch.no_grad(): # 生成最多 max_len 个 tokens for _ in range(max_len): # 将当前生成的 tokens 转换为 torch 张量并将其传递给模型 device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot; inputs = torch.LongTensor(output_tokens).unsqueeze(0).to(device) outputs = model(inputs) # 只关心最后一个时间步（即最新生成的 token）的 logits logits = outputs[:, -1, :] # 找到具有最高分数的 token _, next_token = torch.topk(logits, 1, dim=-1) # 如果生成的 token 是 EOS（结束符），则停止生成 if next_token.item() == model.corpus.vocab[&quot;&lt;eos&gt;&quot;]: break # 否则，将生成的 token 添加到生成的词汇列表中 output_tokens.append(next_token.item()) # 将输出 tokens 转换回文本字符串 output_str = &quot; &quot;.join([model.corpus.idx2word[token] for token in output_tokens]) return output_str# 集束搜索def generate_text_beam_search(model, input_str, max_len=5, beam_width=5, repetition_penalty=1.2): # 将模型设置为评估（测试）模式，关闭 dropout 和 batch normalization 等训练相关的层 model.eval() # 分词 input_str = word_tokenize(input_str) # 将输入字符串中的每个 token 转换为其在词汇表中的索引, 如果输入的词不再词表里面，就忽略这个词 input_tokens = [model.corpus.vocab[token] for token in input_str if token in model.corpus.vocab] # 检查输入的有意义的词汇长度是否为0 if len(input_tokens) == 0: return # 创建一个列表，用于存储候选序列，初始候选序列只包含输入 tokens candidates = [(input_tokens, 0.0)] # 创建一个列表，用于存储所有生成的序列及其得分 final_results = [] # 禁用梯度计算，以节省内存并加速测试过程 with torch.no_grad(): # 生成最多max_len个tokens for _ in range(max_len): # 创建一个新的候选列表，用于存储当前时间步生成的候选序列 new_candidates = [] # 遍历当前候选序列 for candidate, candidate_score in candidates: # 将当前候选序列转换为 torch 张量并将其传递给模型 device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot; inputs = torch.LongTensor(candidate).unsqueeze(0).to(device) outputs = model(inputs) # 只关心最后一个时间步（即最新生成的token）的logits logits = outputs[:, -1, :] # 应用重复惩罚：为已经生成的词汇应用惩罚，降低它们再次被选择的概率 for token in set(candidate): logits[0, token] /= repetition_penalty # 将 &lt;pad&gt; 标记的得分设置为一个很大的负数，以避免选择它 logits[0, model.corpus.vocab[&quot;&lt;pad&gt;&quot;]] = -1e9 # 找到具有最高分数的前 beam_width 个 tokens scores, next_tokens = torch.topk(logits, beam_width, dim=-1) # 遍历生成的 tokens 及其得分 for score, next_token in zip(scores.squeeze(), next_tokens.squeeze()): # 将生成的 token 添加到当前候选序列 new_candidate = candidate + [next_token.item()] # 更新候选序列得分 new_score = candidate_score - score.item() # 如果生成的 token 是 EOS（结束符），将其添加到最终结果中 if next_token.item() == model.corpus.vocab[&quot;&lt;eos&gt;&quot;]: final_results.append((new_candidate, new_score)) else: # 将新生成的候选序列添加到新候选列表中 new_candidates.append((new_candidate, new_score)) # 从新候选列表中选择得分最高的 beam_width 个序列 candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)[:beam_width] # 选择得分最高的候选序列，如果 final_results 为空，选择当前得分最高的候选序列 if final_results: best_candidate, _ = sorted(final_results, key=lambda x: x[1])[0] else: best_candidate, _ = sorted(candidates, key=lambda x: x[1])[0] # 将输出 token 转换回文本字符串 output_str = &quot; &quot;.join([model.corpus.idx2word[token] for token in best_candidate]) return output_str GPT 完整实现 12345678910111213141516171819class GPT(nn.Module): def __init__(self, corpus): super(GPT, self).__init__() self.corpus = corpus self.decoder = Decoder(corpus) # 解码器，用于学习文本生成能力 self.projection = nn.Linear(d_embedding, corpus.vocab_size) # 全连接层，输出预测结果 def forward(self, dec_inputs): dec_outputs = self.decoder(dec_inputs) # 将输入数据传递给解码器 logits = self.projection(dec_outputs) # 传递给全连接层以生成预测 return logits # 返回预测结果 def decode(self, input_str, strategy=&#x27;greedy&#x27;, **kwargs): if strategy == &#x27;greedy&#x27;: # 贪心解码函数 return generate_text_greedy_search(self, input_str, **kwargs) elif strategy == &#x27;beam_search&#x27;: # 集束解码函数 return generate_text_beam_search(self, input_str, **kwargs) else: raise ValueError(f&quot;Unknown decoding strategy: &#123;strategy&#125;&quot;) 预训练一个轻量 GPT 定义语料库类 123456789101112131415161718192021222324252627282930313233343536373839# WikiCorpus语料库类class WikiCorpus: def __init__(self, sentences, max_seq_len=256): self.sentences = sentences self.seq_len = max_seq_len self.vocab = self.create_vocabularies() self.vocab_size = len(self.vocab) self.idx2word = &#123;v: k for k, v in self.vocab.items()&#125; def create_vocabularies(self): # counter = Counter(word for sentence in self.sentences for word in sentence.split()) # vocab = &#123;&#x27;&lt;pad&gt;&#x27;: 0, &#x27;&lt;sos&gt;&#x27;: 1, &#x27;&lt;eos&gt;&#x27;: 2, **&#123;word: i+3 for i, word in enumerate(counter)&#125;&#125; with open(&quot;shared_vocab.txt&quot;, &quot;r&quot;) as f: vocab = &#123;line.split()[0]: int(line.split()[1]) for line in f&#125; return vocab def make_batch(self, batch_size): input_batch, target_batch = [], [] # 随机选择句子索引 sentence_indices = torch.randperm(len(self.sentences))[:batch_size] for index in sentence_indices: sentence = self.sentences[index] words = sentence.split()[:self.seq_len - 2] # 截断句子,确保长度不超过 max_seq_len - 2（为了留出 &lt;sos&gt; 和 &lt;eos&gt;） seq = [self.vocab[&#x27;&lt;sos&gt;&#x27;]] + [self.vocab[word] for word in words] + [self.vocab[&#x27;&lt;eos&gt;&#x27;]] # 对序列进行填充 seq += [self.vocab[&#x27;&lt;pad&gt;&#x27;]] * (self.seq_len - len(seq)) # 将处理好的序列添加到批次中 input_batch.append(seq[:-1]) target_batch.append(seq[1:]) # 将批次转换为LongTensor类型 input_batch = torch.LongTensor(input_batch) target_batch = torch.LongTensor(target_batch) return input_batch, target_batch 训练类 1234567891011121314151617181920212223242526import torchimport torch.nn as nnimport torch.optim as optimclass Trainer: def __init__(self, model, corpus, batch_size=24, learning_rate=0.01, epochs=10, device=None): self.model = model self.corpus = corpus self.vocab_size = corpus.vocab_size self.batch_size = batch_size self.lr = learning_rate self.epochs = epochs self.device = device or (&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) self.criterion = nn.CrossEntropyLoss(ignore_index=corpus.vocab[&quot;&lt;pad&gt;&quot;]) self.optimizer = optim.Adam(self.model.parameters(), self.lr) def train(self): self.model.to(self.device) for epoch in range(self.epochs): self.optimizer.zero_grad() dec_inputs, target_batch = self.corpus.make_batch(self.batch_size) dec_inputs, target_batch = dec_inputs.to(self.device), target_batch.to(self.device) outputs = self.model(dec_inputs) loss = self.criterion(outputs.view(-1, self.corpus.vocab_size), target_batch.view(-1)) loss.backward() self.optimizer.step() 训练过程 123456789101112131415161718192021222324from Utilities import read_data# 导入数据集 from CorpusLoader import WikiCorpuscorpus = WikiCorpus(read_data(&#x27;wikitext-103/wiki.train.txt&#x27;)) # 导入 GPT 模型from GPT_Model_with_Decode import GPTWikiGPT = GPT(corpus)print(WikiGPT) # 打印模型架构# 训练 GPT 模型from ModelTrainer import Trainertrainer = Trainer(WikiGPT, corpus, learning_rate=0.01, epochs = 200)trainer.train() import datetime# 获取当前时间戳now = datetime.datetime.now()timestamp = now.strftime(&quot;%Y%m%d_%H%M%S&quot;)# 保存模型import torchmodel_save_path = f&#x27;99_TrainedModel/WikiGPT_&#123;trainer.lr&#125;_&#123;trainer.epochs&#125;_&#123;timestamp&#125;.pth&#x27; 从 GPT 到 ChatGPT GPT 预训练模型是完整语言模型的基础。预训练模型通过在大量文本上学习语言的统计规律，来获得对语言的一般理解。这个阶段模型不专注于任何特定任务，只是学习如何预测文本中下一个单词的出现。 完成预训练后，模型可以用于各种特定的语言任务，如文本生成、翻译、问答等。为了在这些任务上表现得更好，模型通常会进行微调（Fine-tuning），在特定任务的数据集上进一步训练，以适应特定的语言使用场景。预训练模型为这个过程提供了一个强大的起点，微调则根据特定任务进一步优化模型。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"Transformer","slug":"Transformer","permalink":"http://example.com/tags/Transformer/"},{"name":"GPT","slug":"GPT","permalink":"http://example.com/tags/GPT/"},{"name":"LLM","slug":"LLM","permalink":"http://example.com/tags/LLM/"}]},{"title":"Scrapy 框架学习笔记","slug":"Scrapy 框架学习笔记","date":"2023-11-20T05:03:24.000Z","updated":"2023-11-23T10:00:39.226Z","comments":true,"path":"2023/11/20/Scrapy 框架学习笔记/","link":"","permalink":"http://example.com/2023/11/20/Scrapy%20%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Scrapy 是一个基于 Python 的快速的、高级别的 web 爬虫和 web 抓取框架，旨在用于抓取 web 站点并从页面中提取结构化的数据。Scrapy 可以应用于一系列的网路数据抓取任务，从信息提取、数据挖掘到监控和自动化测试。 以下是笔者根据官方文档和 B 站上的教程写的一份学习笔记。 Scrapy 核心组件 爬虫（Spiders）：这些是遍历网络收集数据的网络爬虫。它们向网站发送请求并解析响应。 调度器（Scheduler）：此组件管理爬虫爬行网页的顺序。它安排爬虫发出的请求，通常使用算法来优先决定访问哪些页面。 下载器（Downloader）：请求被调度后，发送给下载器，下载器从互联网上获取网页。下载器处理对网服务器的实际 HTTP 请求。 引擎（Engine）：引擎是系统的核心部分，协调整个过程。它控制系统组件之间的数据流动，并触发事件。 中间件（Middleware）：中间件组件用于处理系统中传递的请求和响应。它们可以修改、丢弃或丰富请求和响应。例如，它们可以处理用户代理轮换、代理管理或内容转换等事宜。 项目管道（Item Pipelines）：数据被爬取后，需要进行处理、清洗和存储。项目管道负责在爬虫提取数据后处理数据项。 Scrapy 框架工作流： 爬虫向引擎发送请求（1）。 引擎将请求发送给调度器（2）。 调度器将请求排队，然后发送回引擎（3）。 引擎再将请求发送至下载器（4）。 下载器从互联网获取数据，并将响应发送回引擎（5）。 引擎将响应发送给爬虫（6）。 爬虫处理响应并提取项目，这些项目被发送到项目管道（7）。 处理过的项目然后从项目管道发送到引擎（8），可能用于进一步处理或存储。 安装库并新建一个 Scrapy 项目 安装 scrapy 库： 1pip install scrapy 新建 Scrapy 项目： 1scrapy startproject project_name 使用 scrapy startproject 后就会在当前工作目录下新建一个 Scrapy 项目，项目目录结构如下： 123456789101112project_name/├── scrapy.cfg└── project_name ├── __init__.py ├── items.py ├── middlewares.py ├── pipelines.py ├── settings.py └── spiders ├── __init__.py ├── spider1.py └── spider2.py 这个结构图展示了一个典型的Scrapy项目的文件和目录层次，其中： scrapy.cfg 是项目的部署配置文件。 myproject 文件夹是项目的Python模块，您的代码会在这里编写和组织。 items.py 中定义了项目中的数据结构。 middlewares.py 中定义了项目的中间件。 pipelines.py 中定义了项目的管道，用于处理抓取的数据。 settings.py 包含了项目的设置。 spiders 目录包含了所有爬虫相关的代码。 在spiders目录下，每个文件代表了一个爬虫。您可以根据需要添加更多的爬虫文件。每个爬虫文件定义了一个Spider类，用于指定如何抓取网页和解析页面内容以提取数据。 scrapy 命令行工具 除了上文提到的创建项目指令，Scrapy 还提供了一系列其他命令： 在当前项目下创建一个新的 Spider ： 1scrapy genspider spider_name &#x27;example.com&#x27; 运行当前项目下的某个 Spider ： 1scrapy crawl spider_name 列出当前所有的 Spider ： 1scrapy list 启动一个交互式的 Scrapy Shell，可以在这里尝试抓取数据 1scrapy shell &#x27;http://example.com&#x27; 下载一个网页并且显示在控制台上： 1scrapy fetch &#x27;http://example.com&#x27; 在浏览器中打开一个网页，方便进行可视化调试 1scrapy view &#x27;http://example.com&#x27; 使用 Spider 解析一个网页，这对于测试和调试爬虫非常有用 1scrapy parse &#x27;http://example.com/page&#x27; --callback parse_item 这将使用 parse_item 方法来解析指定的 URL Spider 类 在 Scrapy 框架中，Spider 类是定义如何抓取某个或某些网站的关键组成部分。这包括抓取的动作，例如：访问网站的哪些页面，如何进行跟进链接，以及如何从页面内容中提取结构化数据（即抓取什么数据）。每个 Spider 都能处理一个或多个特定的网站或页面。 基本属性 name ：识别 Spider 的唯一名称。这个名称在项目中必须是唯一的，即不能为不同的 Spider 设置相同的名字。 start_url ：包含一个或多个 URL 的列表，Spider 将从这些 URL 开始抓取数据。当没有指定特定的 URL 时，Spider 将默认从这个列表中的 URL 开始进行抓取。 allowed_domains ：可选属性，包含一个域名的列表，用于指定 Spider 可以抓取的域名。如果设置了这个属性，Spider 将不会抓取这个列表以外的域名下的页面。 基本方法 start_requests() ：此方法用于生成初始的请求。您可以重写这个方法来实现自定义的请求初始化。默认情况下，它生成 start_urls 中定义的 URL 的请求。 parse() ：当响应返回时，Scrapy 下载器将响应作为参数传递给此方法。这是处理响应并提取数据的主要方法，或者进一步生成要跟踪的 URL 的请求。 工作方式 Spider 在 start_urls 中指定的 URL 开始抓取。 对每个起始 URL，Scrapy 生成 Request 对象，并将 parse 方法作为回调函数指定。 当页面被下载后，Scrapy 引擎调用 parse 方法处理响应。 在 parse 方法内部，您可以使用响应对象来提取信息，或者查找新的 URL 来创建新的请求（Scrapy 会处理这些请求，调用相应的回调）。 通常情况下，parse 方法将解析响应数据，提取信息并用 yield 语句生成 Item 对象，或者生成新的 Request 对象。 基本示例 爬取豆瓣电影排名前 250 的电影的名字和评分： 创建项目： 1scrapy startproject Douban &amp;&amp; cd Douban 编写 item.py 爬虫获取到的数据需要组装成 Item 对象，所以我们需要预先定义封装数据的 Item 对象： 12345import scrapyclass MovieItem(scrapy.Item): title = scrapy.Field() rating = scrapy.Field() 创建并编写一个 Spider 来爬取电影： 1scrapy genspider Movie &#x27;Movie.douban.com&#x27; 1234567891011121314151617181920212223import scrapyfrom scrapy import Selector, Requestfrom Douban.items import MovieItemclass MovieSpider(scrapy.Spider): name = &quot;Movie&quot; allowed_domains = [&quot;movie.douban.com&quot;] start_urls = [&quot;https://movie.douban.com/top250&quot;] def parse(self, response): sel = Selector(response) list_items = sel.css(&#x27;#content &gt; div &gt; div.article &gt; ol &gt; li&#x27;) # 根据 Selector 进行捕获 for item in list_items: movieItem = MovieItem() movieItem[&#x27;title&#x27;] = item.css(&#x27;span.title::text&#x27;).extract_first() movieItem[&#x27;rating&#x27;] = item.css(&#x27;span.rating_num::text&#x27;).extract_first() yield movieItem hrefs_list = sel.css(&#x27;#content &gt; div &gt; div.article &gt; div.paginator &gt; a::attr(href)&#x27;).extract() # 获取底部其他页的链接 next_pages = [response.urljoin(href) for href in hrefs_list if href != &#x27;?start=0&amp;filter=&#x27;] for url in next_pages: yield Request(url=url) 这里 Selector 是一个非常重要的组件，我们传递响应作为参数可以初始化一个 Selector 对象，其可以使用 XPath 或 CSS 表达式来选择 HTML 或 XML 中的特定部分。 将抓取的数据保存： 123scrapy crawl Movie -o top250_movie.csv # 保存为 csv 格式scrapy crawl Movie -o top250_movie.json # 保存为 json 格式scrapy crawl Movie -o top250_movie.xml # 保存为 xml 格式 另外一种 Spider 的定义方式，通过定义 start_requests() 函数来获取到更多页面： 123456789101112131415161718192021import scrapyfrom scrapy import Selector, Requestfrom Douban.items import MovieItemclass MovieSpider(scrapy.Spider): name = &quot;Movie&quot; allowed_domains = [&quot;movie.douban.com&quot;] def start_requests(self): for page in range(10): yield Request(url=f&#x27;https://movie.douban.com/top250?start=&#123;25 * page&#125;&amp;filter=&#x27;) def parse(self, response): sel = Selector(response) list_items = sel.css(&#x27;#content &gt; div &gt; div.article &gt; ol &gt; li&#x27;) # 根据 Selector 进行捕获 for item in list_items: movieItem = MovieItem() movieItem[&#x27;title&#x27;] = item.css(&#x27;span.title::text&#x27;).extract_first() movieItem[&#x27;rating&#x27;] = item.css(&#x27;span.rating_num::text&#x27;).extract_first() yield movieItem 这样定义可以避免同一个网页 URL 相同而导致重复请求的情况，而且保证了请求的次序不被打乱。 定义多个回调函数 假设我们现在要请求 HTML 网页列表的子链接的内容，并对子链接的网页进行爬取，那我们就需要定义多个回调函数。 示例： 分析chinaz.com网站行业网站页面结构（链接：https://top.chinaz.com/hangye/） 爬取每个行业分类下面的网站信息，包括网站标题、网站关键词、网站描述信息。 将爬取结果存取成 csv 格式，每行的数据格式为：网站域名，网站行业分类、网站标题、网站关键词、网站描述信息 12345678910# Item 对象定义import scrapyclass HangyeItem(scrapy.Item): domain = scrapy.Field() web_class = scrapy.Field() title = scrapy.Field() key_words = scrapy.Field() description = scrapy.Field() 1234567891011121314151617181920212223242526272829303132333435363738# Spider 定义import scrapyfrom scrapy import Request, Selectorfrom ChinaZ.items import HangyeItemclass HangyeSpider(scrapy.Spider): name = &quot;Hangye&quot; allowed_domains = [&quot;top.chinaz.com&quot;] def start_requests(self): yield Request(url=&#x27;https://top.chinaz.com/hangye/index.html&#x27;) for page in range(2, 1873): yield Request(url=f&#x27;https://top.chinaz.com/hangye/index_&#123;page&#125;.html&#x27;) def parse(self, response): sel = Selector(response) items_list = sel.css(&#x27;#content &gt; div.Wrapper.TopIndexCentWrap.pt10 &gt; div.TopListCent &gt; div.TopListCent-listWrap &gt; ul &gt; li.clearfix &gt; div.CentTxt&#x27;) for item in items_list: title = item.css(&#x27;h3 &gt; a::text&#x27;).extract_first() domain = item.css(&#x27;h3 &gt; span::text&#x27;).extract_first() href = item.css(&#x27;h3 &gt; a::attr(href)&#x27;).extract_first() yield Request(url=response.urljoin(href), callback=self.parse_sublink, meta=&#123; &#x27;title&#x27;: title, &#x27;domain&#x27;: domain &#125;) def parse_sublink(self, response): hangyeItem = HangyeItem() hangyeItem[&#x27;title&#x27;] = response.meta[&#x27;title&#x27;] hangyeItem[&#x27;domain&#x27;] = response.meta[&#x27;domain&#x27;] sel = Selector(response) hangyeItem[&#x27;web_class&#x27;] = &#x27;, &#x27;.join(sel.css(&#x27;#content &gt; div.Wrapper.TopIndexCentWrap.pt10 &gt; div &gt; div.TopPageCent.clearfix &gt; div.TPageCent-TopMain.mt10.clearfix &gt; div &gt; div &gt; p:nth-child(1) &gt; a::text&#x27;).getall()) hangyeItem[&#x27;description&#x27;] = sel.css(&#x27;#content &gt; div.Wrapper.TopIndexCentWrap.pt10 &gt; div &gt; div.TopPageCent.clearfix &gt; div.TPageCent-TMain01.mb40 &gt; div:nth-child(2) &gt; div.Centright.fr.SimSun &gt; p::text&#x27;).extract_first() hangyeItem[&#x27;key_words&#x27;] = &#x27;, &#x27;.join(sel.css(&#x27;#content &gt; div.Wrapper.TopIndexCentWrap.pt10 &gt; div &gt; div.TopPageCent.clearfix &gt; div.clearfix.mb40 &gt; div.TPageCent-TMainmob.fl &gt; ul &gt; li:not(.ListHead) &gt; span.Lnone::text&#x27;).getall()) yield hangyeItem 运行： 1scrapy crawl Hangye -o cn_web_info.csv 数据管道 Scrapy 中的数据管道（Data Pipeline）是用于处理从网页中提取出的数据的组件。它们提供了一个清晰的方式来处理、过滤和存储爬虫抓取的数据。 要在 Scrapy 项目中使用数据管道，你需要在 settings.py 文件中启用并配置它： 123ITEM_PIPELINES = &#123; &quot;MyProject.pipelines.MyProjectPipeline&quot;: 300&#125; 每个数据管道都是一个 Python 类，定义在 pipelines.py 中，它实现了一个或多个方法，这个方法会被 Scrapy 自动调用来处理每一个提取的项（Item）。 例如，将爬取到的数据保存到数据库： 123456# setting.py# ...ITEM_PIPELINES = &#123; &quot;Douban.pipelines.DoubanPipeline&quot;: 300&#125; 12345678910111213141516171819202122232425262728293031323334# piplines.pyfrom itemadapter import ItemAdapterimport mysql.connectorclass DoubanPipeline: def __init__(self): try: self.my_db = mysql.connector.connect( host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, passwd=&#x27;&#x27;, database=&#x27;movie&#x27; ) self.cs = self.my_db.cursor() self.cs.execute(&#x27;truncate table top250_mv&#x27;) except mysql.connector.Error as err: print(err) def process_item(self, item, spider): mv_name, rating = item[&#x27;title&#x27;], item[&#x27;rating&#x27;] try: self.cs.execute(&#x27;insert into top250_mv(name, rating) values(%s, %s)&#x27;, (mv_name, rating)) self.my_db.commit() return item except mysql.connector.Error as err: print(err) def close_spider(self, spider): try: self.cs.close() self.my_db.close() except mysql.connector.Error as err: print(err) 效果： 设置多个管道 在 Scrapy 的 ITEM_PIPELINES 设置中，数字（如上文例子中的 300）表示该管道的优先级。Scrapy 支持同时定义多个管道，并且通过这个优先级数字来决定各个管道的执行顺序。优先级的范围是从 0 到 1000。 低数字表示高优先级：数字越小，管道的优先级越高。这意味着优先级数字较低的管道会先于优先级数字较高的管道处理 Item。 执行顺序：当一个 Item 被爬虫抓取并传递给 Item Pipeline 时，它会按照由低到高的优先级顺序经过每个激活的管道。 例如，假设你有以下的设置： 12345ITEM_PIPELINES = &#123; &#x27;MyProject.pipelines.MyFirstPipeline&#x27;: 300, &#x27;MyProject.pipelines.MySecondPipeline&#x27;: 400, &#x27;MyProject.pipelines.MyThirdPipeline&#x27;: 100&#125; 在这个例子中，MyThirdPipeline（优先级为 100）将首先处理 Item，其次是 MyFirstPipeline（优先级为 300），最后是 MySecondPipeline（优先级为 400）。 这种机制允许开发者灵活地控制不同管道处理 Item 的顺序，这在进行复杂的数据处理时非常有用，例如，一个管道可能负责清洗数据，另一个管道可能负责将数据存储到数据库中。通过调整它们的优先级，可以确保数据在存储之前被正确地清洗。 中间件的使用 Scrapy 中的中间件是一种可插拔的组件，用于在请求和响应的处理过程中执行自定义的操作。在 Scrapy 中有两种主要类型的中间件：下载器中间件（Downloader Middleware）和蜘蛛中间件（Spider Middleware）。 下载中间件： 下载器中间件用于处理 Scrapy 发出的 HTTP 请求和收到的 HTTP 响应。它在请求从蜘蛛发送到服务器和响应从服务器返回到蜘蛛的过程中起作用。下载器中间件的常见用途包括： 修改发出的请求：比如设置代理、添加或修改请求头、重定向请求等。 处理返回的响应：比如处理重定向或错误的响应、修改响应内容等。 处理请求异常：比如在连接错误或超时时重试请求。 主要方法： process_request(request, spider) ：在请求被发送到下载器之前调用。 process_response(request, response, spider) ：在下载器完成 HTTP 请求，返回响应之后调用。 process_exception(request, exception, spider) ：当下载处理过程中出现异常时调用。 例如，写一个中间件修改所有的请求头： 12345678class MyDownloaderMiddleware: def process_request(self, request, spider): request.headers[&#x27;User-Agent&#x27;] = &#x27;My Custom User Agent&#x27; return None # 返回 None 继续正常处理 def process_response(self, request, response, spider): # 可以在这里处理响应，例如检查状态码 return response # 必须返回 Response 对象 通常，我们可以在请求中间件内给请求加上 Cookie，从而获得某些权限。 蜘蛛中间件： 蜘蛛中间件用于处理蜘蛛的输入（响应）和输出（提取的项目和新的请求）。它主要在解析响应和生成提取项或进一步请求的过程中起作用。蜘蛛中间件的常见用途包括： 修改或丢弃蜘蛛接收到的响应。 修改蜘蛛产生的提取项。 修改或丢弃蜘蛛产生的新的请求。 主要方法： process_spider_input(response, spider) ：在蜘蛛解析响应之前调用。 process_spider_output(response, result, spider) ：在蜘蛛解析响应并返回结果之后调用。 process_spider_exception(response, exception, spider) ：当解析过程中出现异常时调用。 process_start_requests(start_requests, spider) ：在蜘蛛开始发出初始请求时调用。 例如，写一个中间件过滤掉某些响应： 123456789class MySpiderMiddleware: def process_spider_input(self, response, spider): if &#x27;不需要处理的条件&#x27; in response.text: raise IgnoreRequest() return None def process_spider_output(self, response, result, spider): for i in result: yield i 要启用中间，需要在 settings.py 中进行配置： 1234567DOWNLOADER_MIDDLEWARES = &#123; &#x27;MyProject.middlewares.MyCustomDownloaderMiddleware&#x27;: 543,&#125;SPIDER_MIDDLEWARES = &#123; &#x27;MyProject.middlewares.MyCustomSpiderMiddleware&#x27;: 543,&#125; 这里的数字表示中间件的优先级，数字越小优先级越高。","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://example.com/tags/Scrapy/"}]},{"title":"Transfomer 框架 | 逐层剖析，从原理到代码","slug":"Transfomer 框架","date":"2023-11-15T06:12:57.000Z","updated":"2023-12-04T11:22:52.211Z","comments":true,"path":"2023/11/15/Transfomer 框架/","link":"","permalink":"http://example.com/2023/11/15/Transfomer%20%E6%A1%86%E6%9E%B6/","excerpt":"","text":"本文是笔者根据 2017 年由 Google 的研究者发表的论文《Attention is all you need》与 深蓝学院的 LLM 课程 总结的一份 Transformer 框架的技术文档。 Transformer 是当下非常流行的深度学习模型，自从其提出来后，它迅速成为了许多 NLP 任务的基础架构，比如机器翻译、文本摘要、情感分析和问答系统，大名鼎鼎的 ChatGPT 系列其实也是基于 Transformer 模型构建的，后来 Transformer 也被大量用于机器视觉的运用，例如 Non-local、ViT 等等。总而言之，Transformer 是一款非常强大的模型。 Transfomer 整体结构 下图展示了 Transformer 的整体结构： 编码器 &amp; 解码器 Transformer 主要由两部分组成：即编码器（Encoder）和解码器（Decoder）。 编码器的作用是处理输入序列，将输入数据转换成一系列连续的表示形式，这些表示包含了输入数据的复杂内部结构信息。在处理自然语言任务时，这通常意味着将一句话或文档编码为一系列向量，每个向量对应输入序列中的一个元素（比如一个单词）。 解码器的作用是基于编码器的输出以及之前已生成的输出，逐步生成目标序列。对于自然语言生成任务来说，解码器会一个接一个地生成词汇，直到产生结束符号为止。 整体来看，编码器负责理解输入数据，将其转化为一系列高维的内部表示；解码器则负责将这些表示转换为意义明确的输出序列。两者协同工作。以机器翻译为例，以下展示了 Transformer 的整体工作原理。 嵌入层 &amp; 位置编码 嵌入层 嵌入层（Embedding Layer）是 Transformer 输入的第一层，一般而言是通过某种特定的变换（比如 Word2Vec 技术），将输入单词的 One-Hot 编码转化为空间中连续的向量，其维度与模型维度 \\(d_{model}\\) 一致。 通过这种方式，模型能够将离散的、符号化的输入转换为连续的向量，这些向量是神经网络能够处理的形式。 位置编码 位置编码（Positioning Encoding）是 Transformer 模型中的一个关键创新，用于解决模型缺乏序列顺序信息的问题。因为 Transformer 不使用递归神经网络结构，所以需要某种机制来利用输入序列中单词的位置信息。 Transformer 的原始论文提供了一种使用三角函数的位置编码方案： 对于序列中的每个位置 \\(pos\\) 和维度索引 \\(i\\) ，位置编码如下： 对于偶数索引 \\(2i\\) ： \\[ PE_{(pos, 2 i)} = sin(\\frac{ {pos}}{10000 ^ {\\frac{2i}{d_{model}}}}) \\] 对于奇数索引 \\(2i + 1\\) ： \\[ PE_{(pos, 2 i + 1)} = cos(\\frac{pos}{10000 ^ {\\frac{2i}{d_{model}}}}) \\] 这说明了对于不同维度的特征，其位置编码有不一样的频率。 为什么使用正弦函数进行位置编码： 正弦函数具有周期性，可以很好地捕获一些自然语言的周期性问题与重复出现的模式； 事实上在自然语言中，很多语法结构是重复出现的。 注意力机制 注意力机制是 Transformer 的核心组件之一，其允许模型在处理序列的每个元素时动态地聚焦于序列中的其他部分，这种方式对于理解序列内各元素之间的复杂关系尤其有效。 自注意力机制 自注意力（Self-Attention）是一种特殊形式的注意力机制，使模型能够在处理序列的每一个元素时，考虑到序列中的所有元素。对于给定的输入序列，自注意力允许每一个输出在生成时加权引入输入序列中所有位置的信息。 在自注意力机制中，每一个输入会被映射到三个不同的向量，它们通常由学习得到的权重矩阵生成： 查询向量（Query） \\[ q_0 = x_0 W_{xq} \\] 键向量（Key） \\[ k_0 = x_0 W_{xk} \\] 值向量（Value） \\[ v_0 = x_0 W_{xv} \\] 对于序列中的每一个元素，自注意力的计算过程可以分解为以下步骤： 点积计算：计算查询向量与键向量的点积，得到一个分数，表示该元素与序列中每个元素的兼容性或关联程度。 缩放：通常将点积的结果除以一个缩放因子（通常是键向量维度的平方根），以避免梯度消失或爆炸。 Softmax 归一化：应用 Softmax 函数将这些分数转换为概率，用于确定每个元素应该赋予多少关注度。 加权和：利用 Softmax 的输出作为权重，结合值向量计算加权和，得到自注意力的输出。 如上图，计算出所有加权后，我们就可以计算出自注意力的输出： \\[ \\hat x_i = \\sum_{j} \\hat a_i ^ j v_j \\] 自注意力机制的矩阵表达： \\[ Z = softmax(\\frac{Q K ^ T}{\\sqrt{d_k}}) V \\] 其中： \\[ Q = [q_0 ^ T \\ q_1 ^ T\\ ... \\ q_n ^ T] ^ T \\] \\[ K = [k_0 ^ T \\ k_1 ^ T\\ ... \\ k_n ^ T] ^ T \\] \\[ V = [v_0 ^ T \\ v_1 ^ T\\ ... \\ v_n ^ T] ^ T \\] \\[ Z = [\\hat x_0 ^ T \\ \\hat x_1 ^ T\\ ... \\ \\hat x_n ^ T] ^ T \\] 多头注意力机制 多头注意力（Multi-Head Attention）是将自注意力扩展为多个并行的头部。它允许模型在不同的子空间中并行地学习输入之间的不同表示。每个头部执行上述自注意力计算，但是会有不同的权重矩阵。 对于不同的权重矩阵 \\(W_{xq}^{(i)}\\)、\\(W_{xk}^{(i)}\\)、\\(W_{xv}^{(i)}\\)，可以计算出不同的输出 \\(Z_i\\) 。 假设我们有一共 8 个头部，即 24 个权重矩阵，则我们一共可以得到 8 个输出。 接下来我们考虑将 8 个头部的输出矩阵进行拼接，然后右乘一个权重矩阵 \\(W_O\\) 即可得到最后的输出。 \\[ Z = [Z_0 \\ Z_1 \\ ... Z_7] W_O \\] 通过这种方式，模型可以捕获数据在不同表示空间中的不同特征，并且可以在不同级别的抽象上理解信息。 多头注意力机制的优势 并行计算：注意力机制计算每个元素的输出时，不依赖于其他元素的输出，因此可以高效地并行处理。 捕捉长距离依赖：自注意力可以直接计算序列内任意两个元素之间的交互，不受它们在序列中位置距离的影响，这对于捕捉长距离依赖关系非常有效。 灵活的关注焦点：模型可以学习在不同的上下文中关注序列的不同部分，这种动态的关注机制对于理解和生成语言至关重要。 解码器中的多头注意力机制 添加掩码的多头注意力 Masked Multi-Head Attention 是解码器（Decoder）部分的核心组件，它使得解码器能够在生成序列时只关注到当前位置之前的输出，而不是之后的输出，从而防止信息的提前泄露。 在具体操作中，解码器的每个时间步都会生成一个掩码（mask），用于屏蔽（mask out）那些不应被当前位置所“看到”的未来位置。然后在计算 Softmax 函数前，这个掩码会被加到注意力对数分数上（即，对应未来位置的分数变成非常大的负数）。这样经过Softmax 激活函数后，这些位置的注意力权重接近于零，确保模型不会考虑未来的单词。 举个简单的例子，假设在某一时间步，我们正在尝试生成一个句子的第三个词，Masked Attention 会确保注意力机制只会考虑第一个词和第二个词，而不是之后的词。掩码矩阵可能如下所示： \\[ \\begin{bmatrix} 0 &amp; -\\infty &amp; -\\infty &amp; -\\infty \\\\ 0 &amp; 0 &amp; -\\infty &amp; -\\infty \\\\ 0 &amp; 0 &amp; 0 &amp; -\\infty \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] 这个矩阵会与注意力对数分数相加，确保在进行 Softmax 时，每一行的未来位置的权重都接近于零。 编码器-解码器注意力 编码器-解码器注意力层在解码器中扮演着关键角色，它允许解码器聚焦编码器的输出。这个注意力层作为桥梁将编码器的信息传递给解码器。解码器通过这个层来查看编码器的输出，并结合自身已生成的部分翻译来预测下一个单词。 这一层的多头注意力机制使用解码器的输出作为查询（Query），而将编码器的输出作为键（Key）和值（Value）。通过计算查询与键的相似度，得到一个注意力权重，然后用这个权权重来加权对应的值，生成这一层的输出。 层归一化与残差连接 Transformer 架构中使用了层归一化（Layer Normalization）和残差连接（Residual Connection）来促进深度网络的训练。这两种技术都是为了解决训练深层神经网络时常遇到的问题，比如梯度消失和梯度爆炸。 层归一化 层归一化是一种在训练深度神经网络时常用的技术，其目的是稳定神经网络的学习过程。层归一化的工作原理是对单个样本的所有激活进行归一化，这和批量归一化（Batch Normalization）不同，后者是对同一层中不同样本的同一激活进行归一化。层归一化可以使得网络层的输出更加稳定。 具体步骤 对于一个具体的样本，在网络的每一层（通常在非线性激活函数前），层归一化按以下步骤进行： 计算所有激活值 \\(x_i\\) 的均值 \\(\\mu\\) 和方差 \\(\\sigma ^ 2\\) 对每个 \\(x_i\\) 进行归一化：\\(x_i := \\frac{x_i - \\mu}{\\sqrt{\\sigma ^ 2 + \\epsilon}}\\)（这里的 \\(\\epsilon\\) 是一个很小的正实数，用于防止出现分母为 0 的情况） 应用可学习的参数 \\(\\gamma\\) 和 \\(\\beta\\) 来缩放和位移归一化后的值：\\(x_i := \\gamma x_i + \\beta\\) 残差连接 残差连接，也称作跳跃连接（Skip Connection），是指在网络的某一层上将输入直接加到该层的输出上。它允许梯度直接流过网络，这有助于训练过程中更有效地传播梯度，减轻梯度消失的问题。 在 Transformer 中，残差连接的数学表达式可以写为： \\[ Output = LayerNorm(Input + Sublayer(Input)) \\] 这里的 \\(Sublayer()\\) 指多头注意力层或者前馈神经网络层的输出。\\(LayerNorm()\\) 则表示层归一化。通过这种方式，即使网络非常深，输入信息也可以在网络中更远地传播。 前馈神经网络 前馈神经网络（Feed-Forward Network，FFN）是每个编码器和解码器层的主要组成部分之一。 Transformer 中的 FNN 由两个全连接层组成，中间有一个 ReLU 激活函数，数学表达式如下： \\[ FNN(x) = max(0, xW_1 + b_1) W_2 + b_2 \\] 前馈神经网络为 Transformer 模型提供了非线性处理能力。虽然自注意力层非常擅长处理输入序列中元素之间的依赖关系，但它本质上是一个线性操作。前馈神经网络通过非线性变换，增加了模型的表达能力。 除了使用两个线性层，这里也可以使用两个一维卷积层实现同样的功能： \\[ FFN(x) = max(0, x * w_1 + b_1) * w_2 + b_2 \\] 代码实现 组件一：注意力机制 缩放点积注意力 12345678910111213141516171819202122232425262728293031import torchfrom torch import nnd_k = 64d_v = 64# 向量维度class ScaledDotProductAttention(nn.Module): def __init__(self): super(ScaledDotProductAttention, self).__init__() def forward(self, Q, K, V, attn_mask): &#x27;&#x27;&#x27; Q(..., n_seq, d_k) K(..., n_seq, d_k) V(..., n_seq, d_v) attn_mask(..., n_seq, n_seq) &#x27;&#x27;&#x27; scores = torch.matmul(Q, K.transpose(-2, -1)) / d_k ** 0.5 scores.masked_fill_(attn_mask, -1e9) # 掩码机制 # scores(..., n_seq, n_seq) weights = torch.softmax(scores, dim=-1) # weights(..., n_seq, n_seq) context = torch.matmul(weights, V) # context(..., n_seq, d_v) return context, weights # 返回上下文向量和注意力分数 &#x27;&#x27;&#x27; context(..., n_seq, d_v) weights(..., n_seq, n_seq) &#x27;&#x27;&#x27; 多头注意力 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import torchfrom torch import nnfrom ScaledDotProductAttention import *d_embedding = 512n_heads = 8batch_size = 3class MultiHeadAttention(nn.Module): def __init__(self): super(MultiHeadAttention, self).__init__() self.W_Q = nn.Linear(d_embedding, d_k * n_heads) self.W_K = nn.Linear(d_embedding, d_k * n_heads) self.W_V = nn.Linear(d_embedding, d_v * n_heads) self.linear = nn.Linear(d_v * n_heads, d_embedding) self.layer_norm = nn.LayerNorm(d_embedding) def forward(self, x1, x2, x3, attn_mask): &#x27;&#x27;&#x27; x1, x2, x3(batch_size, n_seq, d_embedding) attn_mask(batch_size, n_seq, n_seq) &#x27;&#x27;&#x27; # 对于自注意力而言，x1 == x2 == x3 residual, batch_size = x1, x1.size(0) # 保留残差连接 # 拆分头 q_s = self.W_Q(x1).view(batch_size, -1, n_heads, d_k).transpose(1, 2) k_s = self.W_K(x2).view(batch_size, -1, n_heads, d_k).transpose(1, 2) v_s = self.W_V(x3).view(batch_size, -1, n_heads, d_k).transpose(1, 2) &#x27;&#x27;&#x27; W_Q(x1), W_K(x2) (batch_size, n_seq, d_k * n_heads) q_s, k_s(batch_size, n_heads, n_seq, d_k) W_V(x3) (batch_size, n_seq, d_v * n_heads) v_s(batch_size, n_heads, n_seq, d_v) &#x27;&#x27;&#x27; # 将注意力掩码复制到多头 attn_mask attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask(batch_size, n_heads, n_seq, n_seq) # 使用缩放点积注意力计算上下文向量和注意力权重 context, weights = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask) &#x27;&#x27;&#x27; context(batch_size, n_heads, n_seq, d_v) weights(batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; # 拼接输出 context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context(batch_size, n_seq, n_heads * d_v) # 线性变换 output = self.linear(context) # output(batch_size, n_seq, d_embedding) # 残差连接和层归一化 output = self.layer_norm(output + residual) # output(batch_size, n_seq, d_embedding) return output, weights &#x27;&#x27;&#x27; output(batch_size, n_seq, d_embedding) weights(batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; 组件二：前馈神经网络 使用线性全连接层 12345678910111213141516171819import torchfrom torch import nnd_mid = 2048class FFN(nn.Module): def __init__(self): super(FFN, self).__init__() self.linear1 = nn.Linear(d_embedding, d_mid) self.linear2 = nn.Linear(d_mid, d_embedding) self.layer_norm = nn.LayerNorm(d_embedding) def forward(self, inputs): residual = inputs output = torch.relu(self.linear1(inputs)) output = self.linear2(output) output = self.layer_norm(output + residual) # 残差连接与层归一化 return output 使用一维卷积层 12345678910111213141516171819import torchfrom torch import nnd_mid = 2048class FFN(nn.Module): def __init__(self): super(FFN, self).__init__() self.conv1 = nn.Conv1d(d_embedding, d_mid, kernel_size=1) self.conv2 = nn.Conv1d(d_mid, d_embedding, kernel_size=1) self.layer_norm = nn.LayerNorm(d_embedding) def forward(self, inputs): residual = inputs output = torch.relu(self.conv1(inputs.transpose(1, 2))) output = self.conv2(output).transpose(1, 2) output = self.layer_norm(output + residual) return output 组件三：正弦位置编码表 123456789101112def get_sin_enc_table(n_position, d_embedding): sinusoid_table = torch.zeros(n_position, d_embedding, dtype=torch.float64) for pos_i in range(n_position): for hid_j in range(d_embedding): sinusoid_table[pos_i, hid_j] = pos_i / (10000 ** ((hid_j &amp; ~1) / d_embedding)) sinusoid_table[:, 0::2] = torch.sin(sinusoid_table[:, 0::2]) sinusoid_table[:, 1::2] = torch.cos(sinusoid_table[:, 1::2]) return sinusoid_table &#x27;&#x27;&#x27; sinusoid_table(n_position, d_embedding) &#x27;&#x27;&#x27; 组件四：填充位置掩码生成函数 填充位置掩码是 Transformer 中一种特殊的方法，用来防止对填充部分进行学习。 12345678910111213141516def get_attn_pad_mask(seq_q, seq_k): &#x27;&#x27;&#x27; len_q == len_k seq_q(batch_size, n_seq) seq_k(batch_size, n_seq) &#x27;&#x27;&#x27; batch_size, len_q = seq_q.size() batch_size, len_k = seq_k.size() pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) # 因为在许多 NLP 任务中 0 被用作填充值 # pad_attn_mask(batch_size, 1, n_seq) pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k) return pad_attn_mask &#x27;&#x27;&#x27; pad_attn_mask(batch_size, n_seq, n_seq) &#x27;&#x27;&#x27; 组件五：编码器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchfrom torch import nnfrom MultiHeadAttention import *from FFN import *from functions import *class EncoderLayer(nn.Module): def __init__(self): super(EncoderLayer, self).__init__() self.enc_self_attn = MultiHeadAttention() self.ffn = FFN() def forward(self, enc_inputs, enc_self_attn_mask): &#x27;&#x27;&#x27; enc_inputs(batch_size, n_seq, d_embedding) enc_self_attn_mask(batch_size, n_seq, n_seq) &#x27;&#x27;&#x27; enc_outputs, attn_weights = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) enc_outputs = self.ffn(enc_outputs) return enc_outputs, attn_weights &#x27;&#x27;&#x27; enc_outputs(batch_size, n_seq, d_embedding) attn_weights(batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27;n_layers = 6 # EncoderLayer 的层数class Encoder(nn.Module): def __init__(self, corpus): super(Encoder, self) self.src_emb = nn.Embedding(len(corpus.src_vocab), d_embedding) self.pos_emb = nn.Embedding.from_pretrained(get_sin_enc_table(corpus.src_len + 1, d_embedding=d_embedding), freeze=True) self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)]) def forward(self, enc_inputs): # 生成位置编码并与词嵌入向量相加 pos_indices = torch.arange(1, enc_inputs.size(1) + 1).unsqueeze(0).to(enc_inputs) enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(pos_indices) # enc_outputs(batch_size, n_seq, d_embedding) enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # 生成自注意力掩码 # enc_self_attn_mask(batch_size, n_seq, n_seq) enc_self_attn_weights = [] for layer in self.layers: enc_outputs, enc_self_attn_weight = layer(enc_outputs, enc_self_attn_mask) enc_self_attn_weights.append(enc_self_attn_weight) &#x27;&#x27;&#x27; enc_outputs(batch_size, n_seq, d_embedding) enc_self_attn_weight(batch_szie, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; return enc_outputs, enc_self_attn_weights # 返回编码器输出和编码器注意力权重 组件六：后续位置掩码 前文已经提及，在序列生成任务中，解码器每个时间步都依赖于前面已生成的部分序列，后续位置掩码是为了防止当前位置依赖未来的信息。 12345def get_attn_subsequent_mask(seq): attn_shape = [seq.size(0), seq.size(1), seq.size(1)] subsequent_mask = torch.triu(torch.ones(attn_shape)).bool() return subsequent_mask 组件七：解码器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import torchfrom torch import nnfrom MultiHeadAttention import *from FFN import *from functions import *class DecoderLayer(nn.Module): def __init__(self): super(DecoderLayer, self).__init__() self.dec_self_attn = MultiHeadAttention() self.dec_enc_attn = MultiHeadAttention() self.ffn = FFN() def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask): &#x27;&#x27;&#x27; dec_inputs, enc_outputs(batch_size, n_seq, d_embedding) dec_self_attn_mask, dec_enc_attn_mask(batch_size, n_seq, n_seq) &#x27;&#x27;&#x27; # 多头自注意力层 dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask) &#x27;&#x27;&#x27; dec_outputs(batch_size, n_seq, d_embedding) dec_self_attn(batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; # 编码器-解码器多头注意力层 # 解码器的第一层注意力输出生成 Q, 编码器的最终输出生成 K &amp; V dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask) dec_outputs = self.ffn(dec_outputs) &#x27;&#x27;&#x27; dec_outputs(batch_size, n_seq, d_embedding) dec_enc_attn(batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; return dec_outputs, dec_self_attn, dec_enc_attnn_layers = 6 # DecoderLayer 的层数class Decoder(nn.Module): def __init__(self, corpus): super(Decoder, self).__init__() self.tgt_emb = nn.Embedding(len(corpus.tgt_vacab), d_embedding) self.pos_emb = nn.Embedding.from_pretrained(get_sin_enc_table(corpus.tgt_len + 1, d_embedding=d_embedding), freeze=True) self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)]) def forward(self, dec_inputs, enc_inputs, enc_outputs): &#x27;&#x27;&#x27; dec_inputs, enc_inputs, enc_outputs(batch_size, n_seq) &#x27;&#x27;&#x27; # enc_inputs 在这里仅用于生成掩码 pos_indices = torch.arange(1, dec_inputs.size(1) + 1).unsqueeze(0).to(dec_inputs) # pos_indices(1, n_seq) -&gt; pos_emb(pos_indices) (1, n_seq, embedding) dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(pos_indices) # (batch_size, n_seq, d_embedding) + (1, n_seq, d_embedding) -&gt; dec_outputs(batch_size, n_seq, d_embedding) dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs) # 填充位掩码 # dec_self_attn_pad_mask(batch_size, n_seq, n_seq) dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs) # 后续位掩码 # dec_self_attn_subsequent_mask(batch_size, n_seq, n_seq) dec_self_attn_mask = torch.gt(dec_self_attn_pad_mask + dec_self_attn_subsequent_mask, 0) # 两掩码相加 # dec_self_attn_mask(batch_size, n_seq, n_seq) dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs) # 解码器-编码器掩码 # dec_enc_attn_mask(batch_size, n_seq, n_seq) dec_self_attns, dec_enc_attns = [], [] for layer in self.layers: dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask) # dec_outputs(batch_size, n_seq, d_embedding) # dec_self_attn, dec_enc_attn(batch_size, n_heads, n_seq, n_seq) dec_self_attns.append(dec_self_attn) dec_enc_attns.append(dec_enc_attn) return dec_outputs, dec_self_attns, dec_enc_attns 完整组合 有了以上铺垫，我们就可以实现完整的 Transformer 框架了： 123456789101112131415161718192021222324252627282930313233343536import torchfrom torch import nnfrom MultiHeadAttention import *from FFN import *from functions import *from Encoder import *from Decoder import *class Transformer(nn.Module): def __init__(self, corpus): super(Transformer, self).__init__() self.encoder = Encoder(corpus=corpus) # 编码器 self.decoder = Decoder(corpus=corpus) # 解码器 self.proj = nn.Linear(d_embedding, len(corpus.tgt_vacab), bias=False) # 最后的全连接 def forward(self, enc_inputs, dec_inputs): &#x27;&#x27;&#x27; enc_inputs, dec_inputs(batch_size, n_seq) &#x27;&#x27;&#x27; # 将输入传递给编码器, 获取编码器输出和自注意力权重 enc_outputs, enc_self_attns = self.encoder(enc_inputs) &#x27;&#x27;&#x27; enc_outputs(batch_size, n_seq, d_embedding) enc_self_attns(n_layers, batch_size, n_heads, n_seq, n_seq) &#x27;&#x27;&#x27; # 将解码器输入、编码器输入和编码器输出输入给解码器 dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs) &#x27;&#x27;&#x27; dec_outputs(batch_size, n_seq, d_embedding) dec_self_attns, dec_enc_attns(n_layers, n_heads, batch_size, n_seq, n_seq) &#x27;&#x27;&#x27; # 将解码器输出传递给最后的全连接层 dec_logits = self.proj(dec_outputs) # dec_logits(batch_size, n_seq, num_of_voc) return dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns 案例：基于 Transformer 的翻译器 定义语料库类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from collections import Counter # 导入 Counter 类import jieba # 使用 jieba 库分词# 定义 TranslationCorpus 类class TranslationCorpus: def __init__(self, sentences): self.sentences = sentences self.src_sen = [&#x27; &#x27;.join(jieba.cut(sentence[0])) for sentence in sentences] # 中文句子库 self.tgt_sen = [sentence[1] for sentence in sentences] # 英文句子库 # 计算源语言和目标语言的最大句子长度，并分别加 1 和 2 以容纳填充符和特殊符号 self.src_len = max(len(s.split()) for s in self.src_sen) + 1 # 这里包括 &lt;pad&gt; self.tgt_len = max(len(s.split()) for s in self.tgt_sen) + 2 # 这里包括 &lt;sos&gt;, &lt;eos&gt; # 创建源语言和目标语言的词汇表 self.src_vocab, self.tgt_vocab = self.create_vocabularies() # 创建索引到单词的映射 self.src_idx2word = &#123;v: k for k, v in self.src_vocab.items()&#125; self.tgt_idx2word = &#123;v: k for k, v in self.tgt_vocab.items()&#125; # 创建词汇表的函数 def create_vocabularies(self): # 统计源语言和目标语言的单词频率 src_counter = Counter(w for sen in self.src_sen for w in sen.split()) tgt_counter = Counter(w for sen in self.tgt_sen for w in sen.split()) # 创建源语言和目标语言的词汇表，并为每个单词分配一个唯一的索引 src_vocab = &#123;&#x27;&lt;pad&gt;&#x27;: 0, **&#123;word: i + 1 for i, word in enumerate(src_counter)&#125;&#125; tgt_vocab = &#123;&#x27;&lt;pad&gt;&#x27;: 0, &#x27;&lt;sos&gt;&#x27;: 1, &#x27;&lt;eos&gt;&#x27;: 2, **&#123;word: i + 3 for i, word in enumerate(tgt_counter)&#125;&#125; return src_vocab, tgt_vocab # 创建批次数据的函数 def make_batch(self, batch_size, test_batch=False): input_batch, output_batch, target_batch = [], [], [] # 随机选择句子索引 sentence_indices = torch.randperm(len(self.sentences))[:batch_size] for index in sentence_indices: src_sentence, tgt_sentence = self.src_sen[index], self.tgt_sen[index] # 将源语言和目标语言的句子转换为索引序列 src_seq = [self.src_vocab[word] for word in src_sentence.split()] tgt_seq = [self.tgt_vocab[&#x27;&lt;sos&gt;&#x27;]] + [self.tgt_vocab[word] for word in tgt_sentence.split()] + [self.tgt_vocab[&#x27;&lt;eos&gt;&#x27;]] # 对源语言和目标语言的序列进行填充 src_seq += [self.src_vocab[&#x27;&lt;pad&gt;&#x27;]] * (self.src_len - len(src_seq)) tgt_seq += [self.tgt_vocab[&#x27;&lt;pad&gt;&#x27;]] * (self.tgt_len - len(tgt_seq)) # 将处理好的序列添加到批次中 input_batch.append(src_seq) output_batch.append([self.tgt_vocab[&#x27;&lt;sos&gt;&#x27;]] + ([self.tgt_vocab[&#x27;&lt;pad&gt;&#x27;]] * (self.tgt_len - 2)) if test_batch else tgt_seq[:-1]) target_batch.append(tgt_seq[1:]) # 将批次转换为 LongTensor 类型 input_batch = torch.LongTensor(input_batch) output_batch = torch.LongTensor(output_batch) target_batch = torch.LongTensor(target_batch) return input_batch, output_batch, target_batch 训练 12345678910111213141516171819202122232425262728293031323334353637383940# 准备一些中译英语料sentences = [ [&#x27;我&#x27;, &#x27;I&#x27;], [&#x27;我是&#x27;, &#x27;I am&#x27;], [&#x27;中国人&#x27;, &#x27;Chinese&#x27;], [&#x27;美国人&#x27;, &#x27;American&#x27;], [&#x27;苹果&#x27;, &#x27;apples&#x27;], [&#x27;香蕉&#x27;, &#x27;bananas&#x27;], [&#x27;菠萝&#x27;, &#x27;pineapples&#x27;], [&#x27;我和中国人&#x27;, &#x27;Chinese and I&#x27;], [&#x27;我和美国人&#x27;, &#x27;American and I&#x27;], [&#x27;中国人和美国人&#x27;, &#x27;Chinese and American&#x27;], [&#x27;美国人喜欢苹果&#x27;, &#x27;American like apples&#x27;], [&#x27;中国人喜欢菠萝&#x27;, &#x27;Chinese like pineapples&#x27;], [&#x27;我是中国人&#x27;, &#x27;I am Chinese&#x27;], [&#x27;我是美国人&#x27;, &#x27;I am American&#x27;], [&#x27;我喜欢苹果&#x27;, &#x27;I like apples&#x27;], [&#x27;我喜欢香蕉&#x27;, &#x27;I like bananas&#x27;], [&#x27;我喜欢菠萝&#x27;, &#x27;I like pineapples&#x27;]]corpus = TranslationCorpus(sentences) # 创建语料库类实例import torch.optim as optim # 导入优化器device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;model = Transformer(corpus).to(device) # 创建模型实例criterion = nn.CrossEntropyLoss() # 损失函数optimizer = optim.Adam(model.parameters(), lr=0.0001) # 优化器for epoch in range(100): # 训练 100 轮 optimizer.zero_grad() # 梯度清零 # Generate a batch of input, output, and target sequences enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size) # 创建训练数据 enc_inputs, dec_inputs, target_batch = enc_inputs.to(device), dec_inputs.to(device), target_batch.to(device) outputs, _, _, _ = model(enc_inputs, dec_inputs) # 获取模型输出 # target_batch(batch_size, n_seq) # outputs(batch_size, n_seq, num_of_voc) loss = criterion(outputs.view(-1, len(corpus.tgt_vocab)), target_batch.view(-1)) # 计算损失 if (epoch + 1) % 20 == 0: # 打印损失 print(f&quot;Epoch: &#123;epoch + 1:04d&#125; cost = &#123;loss:.6f&#125;&quot;) loss.backward() optimizer.step() 输出： 12345Epoch: 0020 cost = 0.566277Epoch: 0040 cost = 0.339869Epoch: 0060 cost = 0.029208Epoch: 0080 cost = 0.006405Epoch: 0100 cost = 0.004169 解码器输出 1234567891011121314# 创建一个大小为 1 的批次，目标语言序列 dec_inputs 在测试阶段，仅包含句子开始符号 &lt;sos&gt;enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size=1,test_batch=True) enc_inputs, dec_inputs, target_batch = enc_inputs.to(device), dec_inputs.to(device), target_batch.to(device)print(&quot;编码器输入:&quot;, enc_inputs) # 打印编码器输入print(&quot;解码器输入:&quot;, dec_inputs) # 打印解码器输入print(&quot;目标数据:&quot;, target_batch) # 打印目标数据predict, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs) # 用模型进行翻译predict = predict.view(-1, len(corpus.tgt_vocab)) # 将预测结果维度重塑predict = predict.data.max(1, keepdim=True)[1] # 找到每个位置概率最大的词汇的索引# 解码预测的输出，将所预测的目标句子中的索引转换为单词translated_sentence = [corpus.tgt_idx2word[idx.item()] for idx in predict.squeeze()]# 将输入的源语言句子中的索引转换为单词input_sentence = [corpus.src_idx2word[idx.item()] for idx in enc_inputs[0]]print(input_sentence, &#x27;-&gt;&#x27;, translated_sentence) # 打印原始句子和翻译后的句子 输出结果： 1234编码器输入: tensor([[ 1, 10, 7, 0, 0, 0]])解码器输入: tensor([[1, 0, 0, 0]])目标数据: tensor([[ 3, 11, 8, 2]])[&#x27;我&#x27;, &#x27;喜欢&#x27;, &#x27;香蕉&#x27;, &#x27;&lt;pad&gt;&#x27;, &#x27;&lt;pad&gt;&#x27;, &#x27;&lt;pad&gt;&#x27;] -&gt; [&#x27;I&#x27;, &#x27;I&#x27;, &#x27;I&#x27;, &#x27;I&#x27;] 这里只生成了一个 token，因为还没有使用到 Transformer 解码层的自回归机制。 生成式解码 在 Transformer 模型中，我们通过最大化预测正确词的概率来优化模型。而在推理的过程中，我们可以以选择概率最大的词作为下一个词，这就是我们常说的贪心搜索。 1234567891011121314151617def greedy_decoder(model, enc_input, start_symbol, steps=5): enc_outputs, enc_self_attns = model.encoder(enc_input) dec_input = torch.zeros(1, steps).type_as(enc_input) next_symbol = start_symbol for i in range(0, steps): dec_input[0, i] = next_symbol if next_symbol == corpus.tgt_vocab[&#x27;&lt;eos&gt;&#x27;]: break dec_output, _, _ = model.decoder(dec_input, enc_input, enc_outputs) proj = model.projection(dec_output) # proj(batch_size=1, n_seq, num_of_voc) prob = proj.squeeze(0).max(dim=-1, keepdim=False)[1] # prob(batch_size=1, n_seq) next_word = prob.data[i] next_symbol = next_word.item() # 预测下一词 final_output = dec_input return final_output 12345678910# 使用贪婪搜索翻译文本enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size=1, test_batch=True) enc_inputs, dec_inputs, target_batch = enc_inputs.to(device), dec_inputs.to(device), target_batch.to(device)print(&quot;编码器输入:&quot;, enc_inputs) # 打印编码器输入print(&quot;解码器输入:&quot;, dec_inputs) # 打印解码器输入print(&quot;目标数据:&quot;, target_batch) # 打印目标数据greedy_dec_output = greedy_decoder(model, enc_inputs, start_symbol=corpus.tgt_vocab[&#x27;&lt;sos&gt;&#x27;], steps=corpus.tgt_len)greedy_dec_output_words = [corpus.tgt_idx2word[n.item()] for n in greedy_dec_output.squeeze()]enc_inputs_words = [corpus.src_idx2word[code.item()] for code in enc_inputs[0]]print(enc_inputs_words, &#x27;-&gt;&#x27;, greedy_dec_output_words) 输出： 1234编码器输入: tensor([[1, 6, 7, 0, 0]])解码器输入: tensor([[1, 0, 0, 0]])目标数据: tensor([[3, 7, 8, 2]])[&#x27;我&#x27;, &#x27;喜欢&#x27;, &#x27;苹果&#x27;, &#x27;&lt;pad&gt;&#x27;, &#x27;&lt;pad&gt;&#x27;] -&gt; [&#x27;&lt;sos&gt;&#x27;, &#x27;I&#x27;, &#x27;like&#x27;, &#x27;apples&#x27;, &#x27;&lt;eos&gt;&#x27;] 测试 接下来我们现在找个训练集没有出现的数据来测试模型的泛化能力： 12345678test_enc_inputs = [corpus.src_vocab[w] for w in list(jieba.cut(&#x27;美国人喜欢香蕉&#x27;))]test_enc_inputs = torch.LongTensor(test_enc_inputs + (corpus.src_len - len(test_enc_inputs)) * [corpus.src_vocab[&#x27;&lt;pad&gt;&#x27;]]).unsqueeze(0)dec_inputs = torch.LongTensor([corpus.tgt_vocab[&#x27;&lt;sos&gt;&#x27;]] + (corpus.tgt_len - 1) * [corpus.tgt_vocab[&#x27;&lt;pad&gt;&#x27;]]).unsqueeze(0)greedy_test_dec_output = greedy_decoder(model, test_enc_inputs, start_symbol=corpus.tgt_vocab[&#x27;&lt;sos&gt;&#x27;], steps=corpus.tgt_len)ans = [corpus.tgt_idx2word[idx.item()] for idx in greedy_test_dec_output[0]]print(ans) 输出： 1[&#x27;&lt;sos&gt;&#x27;, &#x27;American&#x27;, &#x27;like&#x27;, &#x27;bananas&#x27;, &#x27;&lt;eos&gt;&#x27;] Transformer 的发展 NLP 领域 自从 Transformer 架构在 2017 年被提出后，大型语言模型的发展经历了显著的变革和快速的进步。 2018 年，BERT（Bidirectional Encoder Representations from Transformers）由 Google 提出，BERT 是基于 Transformer 的首个重要应用。 2018 - 2020 年，OpenAI 发布了 GPT（Generative Pretrained Transformer）系列模型，包括 GPT-2 和 GPT-3。GPT-3 特别因其巨大的规模（1750亿个参数）和强大的生成能力而受到关注。 2021 - 2023 年，模型如 GPT-4 和 Google 的 PaLM（Pathways Language Model）通过扩大规模和改进训练技巧，进一步提高了性能。 ... 视觉领域 Transformer 最初是为自然语言处理（NLP）任务设计的，但其核心思想—基于注意力机制的模型架构—也被发现对于处理视觉信息非常有效。因此，Transformer 在机器视觉领域的应用也变得越来越广泛。 ViT Google Research 在 2020 年推出了 Vision Transformer（ViT），这是首次将 Transformer 完全应用于图像识别任务。ViT 将图像分割成固定大小的图像块，将每个图像块展平并映射到一个高维空间（就像NLP中的词嵌入），然后在这些块上应用标准的 Transformer 模型。ViT 在多个图像识别基准测试中表现出色，与当时的卷积神经网络（CNN）模型相比，它在一些任务上达到了更好的性能。 MAE MAE（Masked Autoencoders）技术是一种自监督学习方法，它是通过预训练一个神经网络以重建被随机遮挡（mask）的输入数据的方法来学习数据的有效表示。这个技术通常与自编码器（Autoencoder）相关，自编码器是一个试图通过较小的隐藏层来重构输入的神经网络结构。MAE 通过随机遮挡输入数据的一部分，然后让网络预测这些遮挡部分的原始内容，从而迫使模型学习到数据的内在结构和模式。 MAE 技术可以应用于多种类型的数据，包括图像、文本、声音等。在视觉任务中，MAE 的一个例子是，输入一张图像，然后在图像上随机选择一些像素或区域并将其遮挡，随后模型的任务是预测这些遮挡区域的像素值。这种方法迫使模型学习到图像的低级特征（如边缘和纹理）以及更高级的概念（如对象的部分和整体结构），因为要正确重建被遮挡的部分，模型需要理解其周围的上下文。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"Transformer","slug":"Transformer","permalink":"http://example.com/tags/Transformer/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"}]},{"title":"Java 多线程编程","slug":"Java-多线程编程","date":"2023-11-15T03:38:27.000Z","updated":"2024-01-01T16:02:37.482Z","comments":true,"path":"2023/11/15/Java-多线程编程/","link":"","permalink":"http://example.com/2023/11/15/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/","excerpt":"","text":"在 Java 中构造一个线程实例 Java 有两种方式定义一个线程，分别是通过继承 Thread 类和实现 Runnable 接口。 通过继承 Thread 类 1234Thread t = new Thread() &#123; @Override public void run() &#123;&#125;;&#125;; 通过实现 Runnable 接口 1234Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123;&#125;&#125;); Thread 构造函数接收一个 Runnable 的实现类。 两种方法都需要重写 run() 方法，run() 方法是一个回调函数，包含线程的运行逻辑，在线程启动后调用。 Java 线程的生命周期 New：即使用 new 关键字创建一个 Thread 实例。 Runnable：表示线程可运行，当实例调用 start() 方法后进入该状态。 示例： 123456789101112public class Test &#123; public static void main(String[] args) &#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;Hello, world!&quot;); &#125; &#125;); t.start(); &#125;&#125; Running：表示线程正在执行。 Blocked/Waiting/Sleeping：分别表示线程处于阻塞、等待和睡眠状态。具体的方法我们在后面介绍。 Dead：当线程执行结束后会被自动销毁。 其他方法 sleep() Thread 类的 sleep 方法用于暂停当前执行的线程指定的毫秒数。当线程调用 sleep 方法时，它告诉线程调度器自己愿意放弃其当前的时间片段，并在指定的时间内不参与调度。sleep 方法主要用于模拟延迟或等待一段时间，让其他线程有机会执行。 形式：sleep(long millis)：使当前执行的线程休眠（暂停执行）指定的毫秒数。 该方法是静态方法，可以通过 Thread.sleep 直接调用。 interrput() interrupt 方法是 Thread 类的一个实例方法，用于中断线程或者更准确地说，是用于请求中断线程。当一个线程运行时，其他线程可以通过调用这个线程的 interrupt 方法来请求它停止当前正在做的事情。 中断机制是一种协作机制。调用 interrupt 并不会立即停止目标线程。相反，它设置了线程的中断状态，然后线程可以决定如何响应中断。 每个线程都有一个状态标识符表示其是否处于中断状态，通过 isInterrupted() 方法可以查看其状态。 1234567891011121314151617181920212223public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; try &#123; while (!Thread.currentThread().isInterrupted()) &#123; // 线程的工作代码 System.out.println(&quot;Thread is running...&quot;); Thread.sleep(1000); // 可能会抛出 InterruptedException &#125; &#125; catch (InterruptedException e) &#123; System.out.println(&quot;Thread was interrupted!&quot;); &#125; &#125;); thread.start(); System.out.println(thread.isInterrupted()); // false // 给线程一些时间来运行 Thread.sleep(3000); // 请求中断线程 thread.interrupt(); System.out.println(thread.isInterrupted()); // true &#125;&#125; Java 内存模型 Java 内存模型（Java Memory Model，JMM）是一种规范，用于管理Java程序中的内存读写和数据同步。Java内存模型的主要目的是定义程序中变量的读取和写入如何在多线程环境下进行。下面是其主要特点和组成部分的简要介绍： 可见性（Visibility）: 在多线程环境中，一个线程对共享变量的修改对其他线程是可见的。Java 内存模型通过 volatile 关键字和 synchronized 块来保证变量修改的可见性。 原子性（Atomicity）: 确保操作的不可分割性。例如，在写入或读取变量时，不会出现只完成一部分操作的情况。在 Java 中，原子性通常通过 synchronized 来实现。 有序性（Ordering）: 在 Java 内存模型中，操作的执行顺序可能与代码顺序不同，这被称为指令重排。为了控制指令重排，Java 提供了 volatile 关键字和 happens-before 原则。 happens-before 原则：这是 Java 内存模型的核心概念之一，它定义了一组规则，这些规则确定了一个操作的结果对另一个操作可见的条件。例如，一个锁的释放 happens-before 于随后对这个锁的获取。 线程内顺序规则：在同一个线程内，按照程序顺序，前一个操作对于后续操作是可见的。也就是说，一个线程内的每一个动作都发生在它后面的动作之前。 监视器锁规则：当一个线程释放（Unlock）一个监视器（也就是释放一个同步块的锁），这个动作发生在随后对同一个监视器加锁（Lock）的任何动作之前。这确保了释放锁之后，后续获取该锁的线程可以看到之前线程在同步块内所有的写入。 volatile 变量规则：对一个 volatile 字段的写入对于后续对这个 volatile 字段的读取是可见的。这意味着一旦一个线程写入一个 volatile 变量，任何后续读取这个 volatile 变量的线程都将看到这个新值。 线程启动规则：主线程 A 中调用另一个线程 B 的 start() 方法发生在任何线程 B 中的动作之前。这意味着，线程 B 可以看到线程 A 在调用 start() 之前的所有操作。 线程终止规则：如果线程 A 执行了线程 B 的 join() 方法并成功返回，那么线程B中的所有动作都发生在线程A从 join() 方法成功返回之前。换句话说，线程 A 在 join() 之后可以看到线程 B 的所有操作。 Java 内存模型的硬件表示 在 Java 多线程环境中，每个线程都可能在自己的 CPU 核心上执行，并且每个核心都有自己的寄存器和高速缓存（即工作内存），这里存储了线程执行时所需要的数据副本。Java 内存模型保证了线程对共享变量的操作最终一致地反映在主内存中，并且其他线程能够看到这些变化。 CPU 寄存器：最快的存储区域，通常用于存储指令、本地变量或临时计算结果。在 JMM 中没有直接对应，但可以看作是线程在执行计算时的临时存储。 CPU 缓存：高速缓存是 CPU 和主内存之间的小容量存储，用于减少访问主内存的延迟。在 JMM 中，这可以被认为是线程的工作内存的一部分，线程在这里读写它们需要的变量。 主内存（RAM）: 所有的 CPU 核心共享主内存，它保存了程序运行时的数据和状态。在 JMM 中，主内存存储共享变量，是多个线程通信的媒介。 当 CPU 需要读取住内存中的变量，其会读取一部分住内存到 CPU 缓存，然后从缓存中读取变量到寄存器再进行操作。 当 CPU 需要将变量写入内存时，其会将内部寄存器的值刷新到 CPU 缓存中，接下来在某时刻将缓存中的数据刷新到住内存（一般是主内存需要这个变量的时候）。 也就是说，不同的线程获取和更新主内存都不是及时的，会在一定程度上出现延迟，这样就带来了两个问题： 不同线程更新的不可见性：当线程 A 的 CPU 修改完变量 x 后，未及时将修改后的值更新到主内存，于此同时，线程 B 在主内存读取到了 x 原来的值。 竞态条件（Race Condition）：两个线程同时对变量 x 做修改，导致了错误的更新。 示例： 在以下代码中，10 个线程同时操作 Counter 对象，可能导致竞态条件的发生。事实上，每次输出的结果可能都不一样。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; Counter c = new Counter(); int num_of_threads = 10; Thread[] th_arr = new Thread[num_of_threads]; for (int i = 0; i &lt; num_of_threads; i++) &#123; th_arr[i] = new Thread(new Increment(c, 20, 1)); th_arr[i].start(); &#125; for (int i = 0; i &lt; num_of_threads; i++) &#123; th_arr[i].join(); &#125; System.out.println(c.getCnt()); // 如果输出不是 200，就说明出现了竞态条件 &#125;&#125;class Counter &#123; private int cnt = 0; public void add(int x) &#123; this.cnt += x; &#125; public int getCnt() &#123; return cnt; &#125;&#125;class Increment implements Runnable &#123; private Counter c; private int max_n; private int x; public Increment(Counter c, int max_n, int x) &#123; this.c = c; this.max_n = max_n; this.x = x; &#125; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; max_n; i++) &#123; c.add(x); Thread.sleep((long)(100 * Math.random())); &#125; &#125; catch (InterruptedException e) &#123;&#125; &#125;&#125; volatile 关键字 volatile 是 Java 中的一个重要关键字，用于声明该变量将会被多个不同的线程修改。volatile 关键字保证了一个线程对该变量的写操作对其他线程立即可见。这意味着当一个线程更新了一个 volatile 变量的值时，新值对于正在读取这个变量的其他线程是立即可知的。 写入 volatile 变量 立即写入主内存: 当线程对一个 volatile 变量执行写操作时，它会立即将这个新值刷新到主内存中。 写屏障（Write Barrier）: 在写入 volatile 变量之后，JVM 会插入一个写屏障（也叫做存储屏障），这防止了指令重排序。具体来说，写屏障会确保所有在写 volatile 变量之前的操作都不会被重排到写操作之后。 无缓存行失效：由于 volatile 变量的操作直接写入主内存，这意味着不会有缓存行失效的问题，因为缓存行失效主要发生在缓存之间的数据同步过程中。 变量的“发布”：写操作实质上是将变量的值“发布”出去，使得之后对这个 volatile 变量的读操作都能看到最新的值。 读取 volatile 变量 直接从主内存读取：当线程对一个 volatile 变量执行读操作时，它会直接从主内存中读取值而不是从缓存中读取。这确保了它看到的是最新写入的值。 读屏障（Read Barrier）：在读取 volatile 变量之前，JVM 会插入一个读屏障，防止指令重排序。这意味着，在读 volatile 变量之前的操作不会被重排到读操作之后。 禁止缓存：volatile 读取操作不会将值缓存在寄存器或其他 CPU 缓存中，因为这个值在后续指令中必须从主内存重新读取。 变量的“获取”: 读操作实际上是“获取”了 volatile 变量的最新值，保证了后续的操作都是在最新值的基础上进行的。 注：虽然 volatile 提供了操作的可见性和有序性，但它并不保证操作的原子性。例如，volatile 不适用于复合操作（比如volatileVar++），因为这类操作包含多个步骤，每个步骤都需要原子性保证。 synchronized 关键字 volatile 保证了操作的有序性，但无法保证操作的原子性（即操作不可分），这里我们就需要使用 synchronized 关键字了。 在介绍 synchronized 关键字之前，我们先简单介绍一下 Java 对象的内部锁（Intrinsic Lock）。在 Java 中，每个对象都有一个内部锁或监视器锁，它是实现同步的一种机制。这个内部锁是用来控制对对象同步部分的并发访问的。当多个线程尝试同时执行对象中的同步代码时，这个锁确保了一次只有一个线程能执行该代码块。 synchronized 关键字有两种修饰方法，一种是直接修饰类方法，另一种是使用 synchronized 代码块： 123public synchronized void fun() &#123;&#125;synchronized(obj) &#123;&#125; 当我们要访问 synchronized 关键字修饰的方法和代码块时，必须要获取到方法或代码块所属对象的内部锁，而当一个线程获取到锁的时候，其他线程都无法获取到该锁。例如，我们只需要稍微修改上述例子中的 Counter 对象，就可以解决竞态度条件的问题： 123456789class Counter &#123; private int cnt = 0; public synchronized void add(int x) &#123; this.cnt += x; &#125; public int getCnt() &#123; return cnt; &#125;&#125; 监视器 监视器（Monitor）是一个同步机制，它用于实现对对象的互斥访问。每个 Java 对象都有一个监视器与之关联，它用来帮助管理那些试图访问同步代码块的线程。监视器内部有几个组成部分，主要包括 Entry Set、Owner 以及 Wait Set。 Owner（锁的所有者） 监视器的 Owner 是当前持有对象锁的线程。在任意时间点，最多只有一个线程可以成为监视器的 Owner。这个线程获得锁后，其他任何试图获得该锁的线程都必须等待，直到当前线程释放锁。Owner 是执行同步代码块的线程。 Entry Set（锁池） 当线程尝试进入同步代码块时，如果锁已经被占用，那么该线程将被放置到 Entry Set 中，这也被称为锁池。这是一个包含了所有等待锁的线程的集合。当锁被释放时，这些线程中的一个（或多个，取决于 JVM 实现）将有机会尝试获取锁。如果获得锁成功，则线程从 Entry Set 移动到 Owner。 Wait Set（等待集合） Wait Set 是一个包含了所有调用了 wait() 方法（在同步代码块内部调用）的线程的集合。这些线程在调用 wait() 方法后释放了锁，并等待其他线程通过 notify() 或 notifyAll() 方法通知它们。一旦线程被通知，它们会离开 Wait Set 并尝试重新进入 Entry Set 以获取锁。 示例 接下来我们定义了一个邮箱对象，并定义了一个读线程和写线程分别操作这个对象： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; MailBox m = new MailBox(); int num_of_msg = 10; Thread w_thread = new Thread(new Writer(m, num_of_msg)); Thread r_thread = new Thread(new Reader(m, num_of_msg)); w_thread.start(); r_thread.start(); w_thread.join(); r_thread.join(); &#125;&#125;class Reader implements Runnable &#123; private MailBox m; private int num_of_msg; public Reader(MailBox m, int num_of_msg) &#123; this.m = m; this.num_of_msg = num_of_msg; &#125; @Override public void run() &#123; for (int i = 0; i &lt; num_of_msg; i++) &#123; m.read(); &#125; &#125;&#125;class Writer implements Runnable &#123; private MailBox m; private int num_of_msg; public Writer(MailBox m, int num_of_msg) &#123; this.m = m; this.num_of_msg = num_of_msg; &#125; @Override public void run() &#123; for (int i = 1; i &lt;= num_of_msg; i++) &#123; m.write(&quot;Message Number: &quot; + i); &#125; &#125;&#125;class MailBox &#123; private String message = null; private volatile boolean empty = true; public synchronized void read() &#123; try &#123; while (empty) &#123; wait(); // 释放锁 &#125; System.out.println(message); empty = true; notifyAll(); // 通知 Wait Set 中的线程 &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; public synchronized void write(String message) &#123; try &#123; while (!empty) &#123; wait(); // 释放锁 &#125; this.message = message; empty = false; notifyAll(); // 通知 Wait Set 中的线程 &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125;&#125; 控制台输出： 12345678910Message Number: 1Message Number: 2Message Number: 3Message Number: 4Message Number: 5Message Number: 6Message Number: 7Message Number: 8Message Number: 9Message Number: 10 一个标准的 wait/notify 用法： 12345678while (status) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123;&#125; // ... notify(); // 或者 notifyAll()&#125; 总结","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"给你的 Python 循环加上进度条","slug":"给你的 Python 循环加上进度条","date":"2023-11-05T08:39:29.000Z","updated":"2023-11-06T14:18:18.313Z","comments":true,"path":"2023/11/05/给你的 Python 循环加上进度条/","link":"","permalink":"http://example.com/2023/11/05/%E7%BB%99%E4%BD%A0%E7%9A%84%20Python%20%E5%BE%AA%E7%8E%AF%E5%8A%A0%E4%B8%8A%E8%BF%9B%E5%BA%A6%E6%9D%A1/","excerpt":"","text":"在使用 Python 编程的过程中，我们有时需要知道 Python 循环的当前进展，特别是机器学习的过程，接下来我们介绍 Python 的进度条库 tqdm。 tqdm 简介 tqdm 是一个快速、可扩展的Python进度条库，可以很容易地添加到现有的Python代码中。tqdm这个名字来源于阿拉伯语单词 \"taqaddum\"（تقدُّم）的缩写，意为 \"进展\"。在使用时，它会显示一个进度条提供信息，比如迭代的完成百分比、已经过时间、预计剩余时间以及每秒的迭代次数。 在使用 tqdm 之前，我们需要安装 tqdm 包： 1pip install tqdm tqdm 可以用在任何可以迭代的对象上，包括列表、字典、文件等。使用 tqdm 最简单的方式是将它包裹在任何迭代器上，例如在 for循环中。下面是一个简单的例子： 12345from tqdm import tqdmimport timefor i in tqdm(range(1, 1000)): time.sleep(0.01) 运行结果： tqdm() 常用参数 为了满足工作的实际需求，tqdm 函数提供了多种参数来自定义进度条的行为和显示效果： desc ：进度条前面的描述文字（即前缀），默认为空。 total ：迭代总次数。如果未提供，则使用 iterable 的长度。如果 iterable 是无法直接获取长度的迭代器，可以通过total参数手动设置。 leave ：布尔值，设置为True时，在进度条结束后，进度条将保留下来；如果设置为 False ，进度条结束后将会被删除。默认为True 。 unit ：进度条每次更新代表的单位，默认是'it'（迭代），可以设置成其他如 'files'、'blocks' 等。 initial ： 设置开始时的初始计数，默认是 0。这个参数在迭代器被部分消费后再使用 tqdm 时很有用。 案例 用于神经网络参数训练时记录当前训练的 epoch 进度： 12345678910for epoch in tqdm(range(epoch_num), unit=&#x27;epoch&#x27;, desc=&#x27;Training&#x27;): for batch_idx, (data, target) in enumerate(train_loader): op.zero_grad() output = model(data) l = loss(output, target) l.backward() op.step() torch.save(model.state_dict(), f&#x27;net/epoch-&#123;epoch&#125;.pth&#x27;) tqdm.write(f&#x27;epoch &#123;epoch&#125; is over, loss = &#123;l.item():.6f&#125;&#x27;) 效果： 我们也可以记录每个 epoch 的迭代进度： 12345678910for epoch in range(epoch_num): for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_datasets) // batch_size, desc=f&#x27;epoch &#123;epoch&#125;&#x27;): op.zero_grad() output = model(data) l = loss(output, target) l.backward() op.step() torch.save(model.state_dict(), f&#x27;net/epoch-&#123;epoch&#125;.pth&#x27;) print(f&#x27;epoch &#123;epoch&#125; is over, loss = &#123;l.item():.6f&#125;&#x27;) 效果： 在下载大文件时显示进度条： 1234567891011url = &quot;http://example.com/large_file.zip&quot;response = requests.get(url, stream=True)total_size_in_bytes = int(response.headers.get(&#x27;content-length&#x27;, 0))chunk_size = 1024with tqdm(total=total_size_in_bytes, unit=&#x27;B&#x27;, unit_scale=True, desc=url.split(&#x27;/&#x27;)[-1]) as progress_bar: with open(&#x27;large_file.zip&#x27;, &#x27;wb&#x27;) as file: for data in response.iter_content(chunk_size): progress_bar.update(len(data)) file.write(data) 注：tqdm 本身是一个迭代器装饰器，其作用是对原始迭代器进行包装，在迭代过程中动态地显示进度，而不更改原始迭代的返回值。","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"tqdm","slug":"tqdm","permalink":"http://example.com/tags/tqdm/"}]},{"title":"内存管理","slug":"内存管理","date":"2023-11-02T05:04:52.000Z","updated":"2023-12-31T04:03:08.680Z","comments":true,"path":"2023/11/02/内存管理/","link":"","permalink":"http://example.com/2023/11/02/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"为什么需要内存管理？ 计算机的内存被所有进程共享，但是编译器和程序员无法得知当前还有多少进程在内存中的什么地方。 内存管理的主要需求： 代码重定向（Code relocation） 代码重定位是指将程序中的某些代码或数据从一个位置移动到另一个位置的过程。 保护 &amp; 共享（Protection &amp; Sharing） 使得每个进程都有自己的地址空间，便于程序员编程 虚拟内存 &amp; 物理内存 虚拟内存（Virtual memory），也称逻辑内存（Logical memory），是给每个程序进程分配的内存，其大小由计算机寻址位数决定，对于 32 位机器而言，虚拟内存的大小为 \\(2 ^ {32}\\) B \\(=\\) \\(4\\) GB；对于 64 为机器而言，虚拟地址的大小为 \\(2 ^ {64}\\) B \\(\\approx\\) \\(4 \\times 10 ^ 9\\) GB，这已经满足绝大多数内存存储需求。 虚拟内存中的地址称为虚拟地址，是每个进程可以访问的地址。如下图，使用 64 位 ARM 机器编写的一个 C 语言程序，所打印的变量地址就是虚拟地址： 物理内存（Phsical memory），也称真实内存（Real memory），物理内存中的地址称为物理地址，是程序真正占用的地址，每个有效虚拟地址都会映射到与之特定的物理地址。 内存映射 由于虚拟内存是不存在的，所以我们在寻址时要根据虚拟内存找到对应的物理内存，这样的技术称为内存映射。 内存分区 内存分区（Partition Memory）是一种古老的内存映射方式，其有两个主要分类，一个是不变分区（Fixed Partitioning），另一个是动态分区（Dynamic Partitioning）。 不变分区： 在机器启动时间（Boot time）就将内存分为几个连续的分区，每个分区只能装载一个进程，分区大小在系统启动时确定，并在整个运行期间保持不变。 如下图所示，x 表示进程已使用内存： Block 1 Block 2 Block 3 Block 4 Block 5 xxxxx xx000 x0000 xxx00 x0000 可见，这样简单粗暴的分区方式一是限制了每个进程内存的增长，同时产生了大量的内部碎片（Internel fragmentation），即我们可能会给一些进程预留一些不会使用到的内存。 硬件要求：一个基地址寄存器（Base register），基地址寄存器存储了每个进程对应物理内存的起始地址，寄存器的数据在上下文切换（Context switch）时由 OS 加载。 映射公式： \\[ \\text{Physical Address} = \\text{Logical Address} + \\text{Base Register} \\] 动态分区 动态分区相对而言更加灵活，动态分区技术只在程序被加载，即操作系统创建新进程时创建分区。 这种按需分配的分区技术可以避免内部碎片，但是未被分配的内存会零散分布在内存中，造成外部碎片（External fragmentation），例如下图： 硬件要求：一个基地址寄存器，这一点和不变分区技术一致；同时还需要一个限制寄存器（Limit register），限制寄存器限制了进程内存的最大偏移量。 映射公式： \\[ \\text{Physical Address} = \\text{Logical Address} + \\text{Base Register} \\] 保护机制： \\[ \\text{if}\\ (\\text{Physical Address} &gt; \\text{Base register} + \\text{Limit register}) \\implies \\text{TRAP!} \\] 当程序尝试访问超出其限制寄存器定义的内存段范围时，操作系统会捕获并处理异常，这就是我们常说的段错误（Segmentation fault）。 页 &amp; 帧 页（Page）和帧（Frame）是现代计算机内存管理中两个重要概念，它们都是一种固定大小且相等的内存块（一般是 4 KB）。页用于指代虚拟内存，而帧用于指代物理内存。有效的页都可以映射到物理内存中的某个帧，即计算机会给每个正在运行的进程的每个页分配一个帧（不考虑多级页表）。 我们根据页查找到帧，然后根据帧号找到真实的物理内存： 页到帧的映射是如何进行的呢？接下来就引入了我们的页表。 页表 &amp; 一级页表寻址 以 32 位操作系统为例，每个逻辑地址我们可以分成两部分： 高 20 位比特：用于表示页编号（Page number），大小从 \\(0\\) 到 \\(2 ^ {20} - 1\\)。 低 12 位比特：用于表示页偏移地址（Offset in page），大小从 \\(0\\) B 到 \\(2 ^ {12} - 1\\) B，说明每个页的大小为 \\(4\\) KB。 操作系统为每个进程维护了一个页表（Page table），每个页表项（PTE）如下： 高 20 位比特表示页帧编号，对应的是物理地址的帧编号，即作为物理地址的高 20 位比特。 后续几个域： P（Present）：一般用作有效位，即该页表项对应的帧是否在内存中。 W（Writeable）：表示页面是否可写。 U（User）：用于表示用户权限。 PWT（Page Write Transparent）：用于指定页面级别的写透明策略（External cache write-through）。 PCD（Page Cache Disabled）：是否禁用高速缓存。 A（Accessd）：表示页面最近是否被访问过。 D（Dirty）：页面最近是否被修改过（只用于 PTE）。 L（Large）：指示操作系统和硬件是否使用大页面（Large Page）而不是标准的小页面（Small Page）来管理内存。 如何根据逻辑地址加页表寻址？ 根据逻辑地址的页编号，加上存储页表地址的寄存器存储的值就可以找到目标页编号对应的页表项； 以 x86 架构为例子，CR3（Control Register 3）用于管理分页机制。CR3寄存器主要用于存储页目录表的基地址（Page Directory Base Address），它是分页机制中的重要组成部分，用于虚拟地址到物理地址的转换。 页表项中的页帧号对应物理内存中的帧编号，加上逻辑地址的偏移值，即可映射到真实的物理地址。 这种映射方式由许多优点： 消除了外部碎片，可能还会有内部碎片，但是对于 4KB 的页面而言内部碎片不会造成多大的空间浪费； 易于实现； 易于保护和共享； 很容易分配物理内存，每次从空闲帧列表中选择一些帧进行分配即可。 空闲帧列表（List of free frames）是一个在操作系统内存管理中常见的数据结构，用于跟踪系统中哪些物理内存帧（或页面帧）当前是空闲的，可以用于分配给新的进程或任务。 于此同时也造成了一些问题： 页表太大（Page table size is too large）： 一个页表项一共 \\(4\\) B，页面编号一共有 \\(2 ^ {20}\\) 个，每个进程都要维护一个 \\(4 \\times 2 ^ {20}\\) B \\(=\\) \\(4\\) MB 的页表，如果当前系统有 1000 个进程，则需要维护约 \\(4\\) GB 的页表，事实上每个进程有许多页面都是完全不使用的，造成了很大的空间浪费。 内存访问慢（Memory access is slow）： 不同于之前的内存分区技术，页面映射需要通过页表进行内存访问，这样使得访问速度大打折扣。 后文我们提及的多级页表和 TLB 技术将解决这两个问题。 页面交换 &amp; 页面错误 页面交换 我们不难注意到，当前 64 位机器的逻辑内存远远大于实际的物理内存大小，那么当物理内存不够后，逻辑内存又是如何分配的呢？ 事实上，物理内存中许多帧长期不会被使用，这样的帧操作系统会将其置换到磁盘中（这里可以类比进程的挂起），这样的技术称为页面交换（Page Swapping）。 回到刚刚的问题，当物理内存不够后，又要给新的逻辑地址分配帧时，又该如何做呢？ 答案是：将当前物理内存中的闲置帧转移到磁盘中，给新的帧预留位置，然后对页表进行对应的更新，如下图所示（图源：B 站）。 帧锁定（Frame Locking） 注意，不是所有帧都可以被置换到磁盘，有些特殊的帧会被锁定而无法被置换到磁盘，比如： 系统内核 I/O 缓存 ... 页面错误 如果某时刻，进程需要访问某个页面，如果发现该页面对应的帧不在内存中，这个时候就会触发页面错误（Page fault）。至于这个页面是否在内存中，由前文提到的 PTE 中的比特位「P」决定。 页面错误主要有两种： Major Page Fault（主要页面错误） 进程尝试访问虚拟内存中的页面，但该页面尚未在物理内存中。一般是我们在上文提到的已加载的页面因为换出到磁盘而不再在物理内存中。 Minor Page Fault（次要页面错误） 次要页面错误是发生在虚拟内存系统中的一种事件。当一个进程尝试访问当前不在其转换后备缓冲器（TLB，这个一会会讲）中但实际上已经加载到物理内存中的页时，就会发生轻微页面错误。换句话说，这意味着所需的数据是在内存中的，只是没有在快速查找的硬件缓存中记录。 这里我们说说主要页面错误的处理流程： 处理器读取到进程访问逻辑地址的请求，将地址传送至内存管理单元（MMU，Memory Management Unit），通过页面编号找到对应的页表项，通过其判断位「P」为 0，说明其对应物理帧不在内存中，触发了一个页面错误； 接着将信息传达给操作系统的页面错误处理器，从磁盘找到对应的物理帧； 找到对应帧后，将数据加载到内存中； 更新对应的页表项； 完成上述步骤后，页面错误处理器通知调度器，重新进行调度。 常规保护错误（GPF） 常规保护错误（General Protection Fault）是一种计算机硬件或操作系统的错误，它表示发生了一种无法处理的保护性异常。通常情况下，GPF 会导致程序崩溃，操作系统终止程序的执行，并通常会生成错误报告以记录问题。 如果是用户级进程触发 GPF，则操作系统会将该进程 kill，如果是内核级的进程，则可能导致系统崩溃而重启。 多级页表 前文我们提到，如果使用一级页表结构，则每个进程都要维护一个包含大约 100 万个 PTE 的页表，十分占用空间。为了解决这个问题，现代操作系统中一般使用多级页表结构。 二级页表 二级页表引入了页表目录（Page Directory）的概念，即很多个页表会被存储在一个页表目录中，处理器寻址时先通过页表目录找到逻辑地址对应的目录，然后找到目录中对应的页表，最后找到页表中的目标页表项，实现多级索引。 以 32 位操作系统为例，在二级页表目录中，一个逻辑地址可以被划分如下： 10 bits 10 bits 12 bits Directory Index Page Table Index Offset in page 寻址过程： 根据逻辑地址高 10 位比特（31 ～ 22）的目录索引，与基地址寄存器的值（页表目录的起始地址）相加，得到目标 PDE 的值； 目标 PDE 的高 20 位比特表示页表的编号，逻辑地址中间 10 位比特（21 ～ 12）表示页表项的索引，从而可以找到目标 PTE； 目标 PTE 的高 20 位比特表示目标物理帧的编号，加上逻辑地址最后 12 个比特表示的偏置，即可得到最后的地址。 为什么二级页表可以节省空间呢？ 让我们来算一算，对于每个进程而言，需要维护一个页表目录，页表目录一共有有 \\(2 ^ {10}\\) 个 PDE，每个 PDE 大小为 \\(4\\) B，因此总大小为 \\(4 \\times 2 ^ {10}\\) B = \\(4\\) KB。接下来，我们根据程序内存需求给页表目录分配页表即可。因此对于每一个进程，需要维护的最小内存就只有 \\(4\\) KB，相对于一级页表足足小了近一千倍。 事实上，如果进程内存分配比较密集，就意味着有大量的 PDE 是不需要分配页表项的。 三级页表 &amp; 四级页表 三级页表和四级页表通常用于 64 位操作系统，特别是在 x86_64 或 AMD64 架构中。这是因为 64 位操作系统能够访问非常大的虚拟地址空间，通常超过了 32 位操作系统的限制。为了有效地管理如此大的虚拟内存空间，需要更多级的页表来进行地址映射和管理。 事实上它们的原理和二级页表差不多，无非就是多了几层映射罢了。 引入多级页表后，我们解决了进程页表空间过大的问题，但我们还没有解决寻址速度慢的问题，而且随着访问级数的增加，访问慢的问题甚至被加剧了。为了解决这个问题，人们又提出了 TLB 技术。 TLB TLB 介绍 TLB（Translation Lookaside Buffer），是计算机体系结构中的一个关键硬件组件，用于加速虚拟内存到物理内存的地址转换过程。TLB是全关联高速缓存（Fully Associative Cache）的一种，专门用于存储最近执行的虚拟地址到物理地址的映射关系，以提高内存访问速度。 Fully associative cache（全关联高速缓存）是一种高速缓存（Cache）的组织结构，其中缓存中的每个数据块可以存储在任何位置，而不受特定的缓存行或集的限制。与其他类型的高速缓存结构相比，全关联高速缓存提供了更大的灵活性，但通常需要更复杂的硬件来实现。 TLB 存储了虚拟地址到物理地址的映射表项。每个表项包括虚拟地址、物理地址和其他控制信息。当处理器执行内存访问指令时，它会首先检查 TLB，看是否存在所需的映射，如果存在，就会使用 TLB 中的映射进行地址转换（TLB hit），否则，它将访问主内存或页表来获取映射（TLB miss），使用页表映射获取物理内存后回过头来更新 TLB，下一次访问同一个进程的同一页只需要访问 TLB 就行。 当操作系统进行进程上下文切换时，TLB 通常会被刷新。这是因为不同的进程具有不同的虚拟地址空间，因此之前在 TLB 中的虚拟地址到物理地址的映射不再有效。切换到新的进程时，TLB 需要被清空，以确保新进程的地址映射生效。 现代操作系统寻址过程： 引用局部性 尽管 TLB 可以提高 CPU 访问逻辑地址的速度，但 TLB 能存储的空间非常小，远小于实际内存大小，它是如何实现一个全局加速效果的呢？ 引用局部性（Locality of reference）是计算机科学和计算机体系结构中的一个重要概念，用于描述在程序访问内存或数据时的一种观察现象。引用局部性指的是程序在一段时间内倾向于多次访问相邻的内存地址或数据元素，而不是随机分散地访问内存。 引用局部性通常分为两种主要类型： 时间局部性（Temporal Locality）：时间局部性表示程序在短时间内多次访问相同的内存地址或数据元素。这意味着一旦程序访问了某个内存位置，它可能会在不久的将来再次访问相同的位置。这种情况下，缓存（如 TLB 等）可以有效地提高性能，因为它们可以保存最近访问的数据，以供稍后的访问使用。 空间局部性（Spatial Locality）：空间局部性表示程序在访问一个内存地址或数据元素时，可能会紧接着访问相邻的内存地址或数据元素。这意味着程序倾向于连续地访问内存位置，而不是跳跃式地访问。空间局部性有助于高效地使用缓存，因为缓存可以将相邻的数据块一起加载，从而提高数据的有效性。 这是一个统计意义上的概念，其很好解释了 TLB 的加速原理。 几个问题 页面大小对寻址速度的影响？ 页面越大，其包含的内存就越大，则可以减少 TLB miss 的数量，可以加快页面映射的速度。 缓存慢之后如何更新 TLB 的条目？ 采用 FIFO 算法进行调度，保证 TLB 存储的页面中永远有最新访问的。 做一个小测试 为了测试 TLB 对运行效率的影响，我们准备以下两段程序： 12345678910111213141516171819202122// demo_1.cpp#include &lt;iostream&gt;#include &lt;chrono&gt;int arr[10000][10000];int main() &#123; auto start = std::chrono::high_resolution_clock::now(); for (int i = 0; i &lt; 10000; i++) &#123; for (int j = 0; j &lt; 10000; j++) &#123; arr[i][j] = i + j; &#125; &#125; auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration&lt;double&gt; elapsed = end - start; std::cout &lt;&lt; &quot;耗时: &quot; &lt;&lt; elapsed.count() &lt;&lt; &quot; 秒&quot; &lt;&lt; std::endl; return 0;&#125; 12345678910111213141516171819202122// demo_2.cpp#include &lt;iostream&gt;#include &lt;chrono&gt;int arr[10000][10000];int main() &#123; auto start = std::chrono::high_resolution_clock::now(); for (int i = 0; i &lt; 10000; i++) &#123; for (int j = 0; j &lt; 10000; j++) &#123; arr[j][i] = i + j; &#125; &#125; auto end = std::chrono::high_resolution_clock::now(); std::chrono::duration&lt;double&gt; elapsed = end - start; std::cout &lt;&lt; &quot;耗时: &quot; &lt;&lt; elapsed.count() &lt;&lt; &quot; 秒&quot; &lt;&lt; std::endl; return 0;&#125; 上面的代码中，二者唯一的区别就是循环的顺序不一样，demo_1.cpp 内层循遍历数组第二维，外层循环遍历数组第一维，demo_2.cpp 反之。 接下来我们比较二者的运行效率，在这里我们使用 -O0 参数保证 g++ 编译器不对程序做过多优化。 注意到两段几乎一样的代码，demo_1.cpp 比 demo_2.cpp 快了一倍不止。 这是为什么呢？ 总所周知，在 C/C++ 中，所有的二维数组本质上还是一维数组，即它们所有行在空间上都是连续的，如果我像 demo_1.cpp 那样先进行行遍历，然后进行列遍历，就意味着当进程第一次访问 arr[i][j] 出现次要页面错误后会将其所在页放置在 TLB 缓存中，之后对 arr[i][j + 1] 、arr[i][j + 2] ... 这些在同一个页面的地址数据的访问都会触发 TLB hit，就不需要再进行一轮页面映射操作了。而对于 demo_2.cpp 而言，其先遍历列，然后遍历行，arr[j][i] 和 arr[j + 1][i] 不在同一个页面内，因此每一次访问都会触发 TLB miss，从而只能进行页面映射找到对应的物理帧，效率远低于 demo_1.cpp。 Thrashing Thrashing 通常用来描述在虚拟内存系统中的一种严重性能问题。Thrashing 指的是操作系统不断地将页面从物理内存交换到磁盘，然后再将其换回物理内存，不断地重复这个过程。这种情况导致系统的性能急剧下降，因为大部分时间都用于页面交换，而不是执行实际的计算任务。Thrashing 一般发生在工作集（Working Set）不在内存中从而导致页面错误率（Page Fault Rate）高的情况。 Working Set（工作集）是计算机内存管理领域的一个重要概念，它用于描述一个进程或应用程序在一段时间内所活跃地使用的物理内存中的一组页面或内存块。工作集有助于了解进程的内存访问模式，以便更好地管理内存资源并优化性能。 除此之外，页面大小也可以影响页面错误率： 小页面：在主存中会发现大量的页面随着执行过程中时间的推移将包含进程中靠近最近引用的部分，从而导致低页面错误率。 大页面：导致页面包含远离最近引用的位置，从而导致高页面错误率。 当一个进程在 Paging 上花费的时间比程序本身执行的时间要长，我们就可以称这个进程处于 Thrashing 状态。 解决 Thrashing 的方案： 增加物理内存； 进程的页按需分配； 使用更高效的页面替换策略（如 LRU 或 LFU 等）。 LRU（Least Recently Used）是一种常见的页面置换算法，用于管理计算机系统中的高速缓存或虚拟内存中的页面。LRU 算法的目标是确定哪个页面最久没有被访问，并将其替换掉，以便给新的页面或数据腾出空间。 如何实现？—— 比如利用 x86 32 位 PTE 中的比特位「A」","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内存管理","slug":"内存管理","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"MMU","slug":"MMU","permalink":"http://example.com/tags/MMU/"},{"name":"页表","slug":"页表","permalink":"http://example.com/tags/%E9%A1%B5%E8%A1%A8/"}]},{"title":"N-gram: 最早的语言模型","slug":"N-gram-最早的语言模型","date":"2023-11-01T14:13:02.000Z","updated":"2023-11-27T11:21:53.966Z","comments":true,"path":"2023/11/01/N-gram-最早的语言模型/","link":"","permalink":"http://example.com/2023/11/01/N-gram-%E6%9C%80%E6%97%A9%E7%9A%84%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"N-gram 模型是自然语言处理（NLP）中一种常用的语言模型。它基于一个假设：一个词出现的概率仅依赖于它前面的有限个词。这种模型用于文本数据的各种任务，如语言模型构建、文本生成、拼写检查和机器翻译。 N-gram 模型的概念最早可以追溯到 20 世纪初。这一概念的早期形式出现在安德烈·马尔可夫（Andrey Markov）的工作中，他是一位俄罗斯数学家，以马尔可夫链著称。马尔可夫在 1913 年发表了一篇论文，其中介绍了马尔可夫链的概念，这可以被视为 N-gram 模型的一个早期形式。在马尔可夫的工作之后，20 世纪 40 年代和 50 年代，信息论的先驱如克劳德·香农（Claude Shannon）开始探索语言建模和信息内容的概念。香农在他的开创性论文中使用了类似于 N-gram 的概念来建模和分析语言结构，尽管他没有直接使用“N-gram”这个术语。 模型说明 在 N-gram 模型中，我们通过文本分割近似成连续的 n 个词的组合（即 N-gram），来近似描述词汇序列的联合概率。 以句子 I love that cat 为例子： N 名称 文本组合 1 Unigram I love that cat 2 Bigram I love love that that cat 3 Trigram I love that love that cat ... ... ... N-gram 模型中假设一个词出现的概率只取决于前 \\(n - 1\\) 个词，数学概率表示如下： \\[ P(W_i | W_{i - 1}, W_{i - 2}, ..., W_{i - n + 1}) \\] N-gram 流程： 构建实验语料库，将句子分为 \\(N\\) 个 \"gram\" 统计每个 N-gram 出现的频率 输入一个前缀，根据之前计算过的词频预测后文 代码实现 分词 分词，就是将给定的句子分成一个个基本单位 \"gram\"，也称为 \"token\"。 Python 中常用的分词工具有 NLTK（英文）、jieba（中文）等。 示例： 1234567import jiebatext = &#x27;世界上只有一种英雄主义，就是看清生活的真相之后依然热爱生活&#x27;tokens = jieba.cut(text) # 返回分词结果的迭代器for token in tokens: print(token) 输出： 1234567891011121314世界上只有一种英雄主义，就是看清生活的真相之后依然热爱生活 计算词频 123456789101112131415161718from collections import defaultdict, Counterimport jiebadef n_grams_prob(dataset: list[str], n: int) -&gt; defaultdict(Counter): n_grams_prob = defaultdict(Counter) for sent in dataset: tokens = list(jieba.cut(sent)) for i in range(0, len(tokens) - n + 1): n_gram = tuple(tokens[i : i + n]) prefix = n_gram[: -1] suffix = n_gram[-1] n_grams_prob[prefix][suffix] += 1 for prefix, cnt in n_grams_prob.items(): total_sum = sum(cnt.values()) for suffix in cnt: cnt[suffix] /= total_sum return n_grams_prob 以以下数据集为例子，使用 Bigram： 123456789101112131415161718dataset = [ &#x27;今天天气真好。&#x27;, &#x27;今天天气怎么样？&#x27;, &#x27;今天天气很晴朗。&#x27;, &#x27;今天天气很阴沉。&#x27;, &#x27;今天的天气很晴朗。&#x27;, &#x27;今天的天气很好！&#x27;, &#x27;你觉得今天的天气怎么样？&#x27;, &#x27;今天的天气太好了！&#x27;]def main(): bigram_prob = n_grams_prob(dataset=dataset, n=2) for prefix, distribution in bigram_prob.items(): print(prefix, distribution)if __name__ == &#x27;__main__&#x27;: main() 输出： 12345678910111213(&#x27;今天天气&#x27;,) Counter(&#123;&#x27;很&#x27;: 0.5, &#x27;真&#x27;: 0.25, &#x27;怎么样&#x27;: 0.25&#125;)(&#x27;真&#x27;,) Counter(&#123;&#x27;好&#x27;: 1.0&#125;)(&#x27;好&#x27;,) Counter(&#123;&#x27;。&#x27;: 0.5, &#x27;！&#x27;: 0.5&#125;)(&#x27;怎么样&#x27;,) Counter(&#123;&#x27;？&#x27;: 1.0&#125;)(&#x27;很&#x27;,) Counter(&#123;&#x27;晴朗&#x27;: 0.5, &#x27;阴沉&#x27;: 0.25, &#x27;好&#x27;: 0.25&#125;)(&#x27;晴朗&#x27;,) Counter(&#123;&#x27;。&#x27;: 1.0&#125;)(&#x27;阴沉&#x27;,) Counter(&#123;&#x27;。&#x27;: 1.0&#125;)(&#x27;今天&#x27;,) Counter(&#123;&#x27;的&#x27;: 1.0&#125;)(&#x27;的&#x27;,) Counter(&#123;&#x27;天气&#x27;: 1.0&#125;)(&#x27;天气&#x27;,) Counter(&#123;&#x27;很&#x27;: 0.5, &#x27;怎么样&#x27;: 0.25, &#x27;太好了&#x27;: 0.25&#125;)(&#x27;你&#x27;,) Counter(&#123;&#x27;觉得&#x27;: 1.0&#125;)(&#x27;觉得&#x27;,) Counter(&#123;&#x27;今天&#x27;: 1.0&#125;)(&#x27;太好了&#x27;,) Counter(&#123;&#x27;！&#x27;: 1.0&#125;) 根据前缀预测后文 12345678def next_tokens(n_grams_prob: defaultdict(Counter), prefix: tuple[str]) -&gt; str: yield &#x27;&#x27;.join(prefix) while prefix in n_grams_prob: next_tokens_prob = n_grams_prob[prefix] next_token = max(next_tokens_prob, key=next_tokens_prob.get) yield next_token prefix = (*prefix[1 :], next_token) yield &#x27;\\n&#x27; 示例： 123456def main(): bigram_prob = n_grams_prob(dataset=dataset, n=2) prefix = (&#x27;今天&#x27;, ) for token in next_tokens(n_grams_prob=bigram_prob, prefix=prefix): print(token, end=&#x27;&#x27;) 输出： 1今天的天气很晴朗。 N-gram 的优点和局限 优点：模型简单，易于实现。 缺点：无法捕捉到长距离的词汇关系。 虽然 N-gram 局限性较大，但它启发了后来许多更强大的自然语言处理技术，具有启程碑意义。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"N-gram","slug":"N-gram","permalink":"http://example.com/tags/N-gram/"}]},{"title":"循环神经网络 RNN","slug":"循环神经网络","date":"2023-10-30T12:36:24.000Z","updated":"2024-01-12T03:31:01.113Z","comments":true,"path":"2023/10/30/循环神经网络/","link":"","permalink":"http://example.com/2023/10/30/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"时序神经网络 时序神经网络（Time Series Neural Networks, TSNN）并不是一个特定的神经网络类型，而是指那些用于处理时间序列数据的神经网络。这种数据具有时间顺序的特点，如自然语言、股票价格、气象数据、音频信号、视频帧等。常见的时序神经网络有 RNN、LSTM、GRU、1D CNN 等等。 设想接下来一个场景：我们设计了一个自动购票系统，我们根据用户输入的语句自动判断其起点、终点以及出发时间。 Input： I wish to go to Changsha from Beijing on December 12th Output： Time：12.12 From：Beijing To：Changsha 在该系统中，用户的输入被认为是具有时序性的，即 3 个关键词通过不同的组合或使用句势语法结构可能影响到输出的结果。 因此，我们需要一个能够处理时序信息的神经网络。 RNN 循环神经网络（Recurrent Neural Networks, RNN），也叫递归神经网络，它的关键思想是利用网络的循环链接来储存之前时间步的信息。 在 RNN 中，会有一个记忆单元，每次存储上一次隐藏层的输出，然后在下一次输入时使用该记忆单元中的向量。 其更新方式通常为： \\[ a_t = \\sigma(W_{xa} x_t + W_{aa} a_{t - 1} + b_a) \\] 其中，\\(x_t\\) 是时间步 \\(t\\) 的输入，\\(a_{t - 1}\\) 是上一个时间步的隐藏状态，\\(W_{xa}\\)、\\(W_{aa}\\) 表示权重矩阵，\\(b_a\\) 表示一个偏置，\\(\\sigma\\) 在这里是一个激活函数。 RNN 神经网络早期有两种主要形式，分别是 Elman 神经网络和 Jordan 神经网络，这两种网络在 90 年代初由 Jeffrey Elman 和 Michael I. Jordan 分别提出。 Elman 网络是一种三层网络，包括输入层、隐藏层和输出层。其特点是隐藏层的输出（即隐藏状态）被反馈到一个特殊的上下文单元，然后在下一个时间步，这些上下文单元作为额外的输入供给隐藏层。 Jordan 网络与 Elman 网络非常相似，但它们的循环连接方式有所不同。在 Jordan 网络中，输出层的值被反馈到上下文单元，然后这些上下文单元作为额外的输入提供给隐藏层。 BPTT BPTT（Backpropagation Through Time）是一种特殊的反向传播算法，用于训练时间序列数据上的循环神经网络（RNN）。由于 RNN 的特殊结构，标准的反向传播算法不能直接应用于它们。BPTT 是对反向传播的一个扩展，使其适用于处理 RNN 的时间依赖性。 接下来我们举一个具体的例子，来说说 BPTT 是如何计算的。 假设在上述 RNN 网络中，输入层、输出层、隐藏层和参数矩阵 \\(U\\)、\\(W\\)、\\(V\\) 的大小定义如下： \\[ \\begin{array}{} x_t \\in R ^ n \\\\ h_t \\in R ^ d \\\\ \\hat y_t \\in R ^ k \\\\ U \\in R ^ {n \\times d} \\\\ V \\in R ^ {d \\times k} \\\\ W \\in R ^ {d \\times d} \\end{array} \\] 其中： \\[ \\begin{array}{} h_t = \\delta(x_t U + h_{t - 1} W + b_W) \\\\ \\hat y_t = \\delta(h_t V + b_V) \\end{array} \\] \\(\\delta(\\cdot)\\) 在这里是激活函数。 假设损失函数是 \\(f(\\hat y_t, y_t)\\)，则我们可以认为到 \\(T\\) 时刻为止，总损失值 \\(L = \\frac{\\sum_{t = 0} ^ T L_t}{T + 1} =\\frac{\\sum_{t = 0} ^ T f(\\hat y_t, y_t)}{T + 1}\\)。 在上图中可学习参数一共有 5 个：\\(U\\)、\\(W\\)、\\(V\\)、\\(b_W\\) 和 \\(b_V\\)。 其中，\\(V\\) 和 \\(b_V\\) 的梯度计算与经典的梯度下降算法没有什么区别，其只在输出层使用，不参与隐藏层的计算。 而对于 \\(U\\)、\\(W\\) 和 \\(b_W\\) 而言，其梯度的计算则会复杂很多。这里我们以 \\(\\nabla_{W} L_t\\) 为例，来介绍 BPTT 的具体计算过程： 根据 RNN 网络的计算规则，我们可以得到隐藏层和输出层的计算图： 根据链式法则，\\(L_t\\) 关于 \\(W\\) 的偏导等于计算图上所有 \\(W\\) 到 \\(L_t\\) 的路径偏导之和： \\[ \\nabla_W L_t = \\frac{\\partial L_t}{\\partial y_t} \\frac{\\partial y_t}{\\partial h_t} \\sum_{k = 0} ^ {t - 1} \\frac{\\partial h_k}{\\partial W} \\prod_{i = k} ^ {t - 1} \\frac{\\partial h_{i + 1}}{\\partial h_i} \\] 由此可见，BPTT 的计算中会引入大量的矩阵连乘，这使得传统 RNN 在长距离依赖序列的梯度计算上容易出现梯度消失和梯度爆炸的问题。 传统 RNN 面临的问题 梯度消失（Vanishing Gradients） 描述：当神经网络反向传播过程中的梯度值变得非常小，以至于权重几乎不更新，这种情况被称为梯度消失。 原因：主要因为链式法则和非线性激活函数。例如，当使用 sigmoid 或 tanh 激活函数时，如果输入值过大或过小，其导数会趋近于 0，多层网络中这种小导数的连乘会导致整体的梯度非常小。 结果：深度神经网络的低层（接近输入层的层）权重更新非常缓慢，导致训练过程停滞。 梯度爆炸（Exploding Gradients） 描述：神经网络反向传播过程中的梯度值变得非常大，使权重更新过大，这种情况被称为梯度爆炸。 原因：与梯度消失类似，梯度爆炸也与链式法则有关。但在这种情况下，网络中的梯度值大于 1，多层网络中这些大梯度值的连乘导致整体的梯度变得非常大。 结果：权重更新过大，可能导致网络不稳定，损失函数值震荡或发散。 解决方案：常见的解决方案有梯度裁剪（Gradient Clipping），即给反向传递的梯度设定一个阈值 \\(M\\)，若梯度的模长超过了该阈值，则减小梯度到合适大小的值。 不难发现：上述提及的梯度消失和梯度爆炸都是由一个原因导致的，那就是传统 RNN 神经网络中，如果时间序列过长，可能造成隐藏层中大梯度值的连乘，指数级的增长或衰减很可能造成梯度爆炸或梯度消失。 代码实现 PyTorch 提供了 nn.RNN 模块，用于构建循环神经网络（RNN）。 示例： 1234567891011121314from torch import nnclass SimpleRNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(SimpleRNN, self).__init__() self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) self.fc = nn.Linear(hidden_size, output_size) def forward(self, x): # x shape: (batch, seq_length, input_size) out, hidden = self.rnn(x) # 只使用最后一个时间步的输出 out = self.fc(out[:, -1, :]) return out 主要参数 nn.RNN 的主要参数包括： input_size ：输入特征的维度。 hidden_size ：隐藏层的维度，即隐藏状态的大小。 num_layers ：RNN 的层数，默认为1。 nonlinearity ：激活函数的类型，可以是 'tanh' 或 'relu'，默认是 'tanh'。 batch_first ：如果为 True，则输入和输出的张量的形状为 (batch, seq, feature)，默认为 False，即 (seq, batch, feature)。 dropout ：如果不为零，则在除最后一层外的每层后添加一个Dropout层。 bidirectional ：如果为 True，则使用双向 RNN，默认为 False。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"时序神经网络","slug":"时序神经网络","permalink":"http://example.com/tags/%E6%97%B6%E5%BA%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"}]},{"title":"数据链路层——流量控制","slug":"数据链路层——流量控制","date":"2023-10-29T06:50:53.000Z","updated":"2024-01-06T07:45:21.128Z","comments":true,"path":"2023/10/29/数据链路层——流量控制/","link":"","permalink":"http://example.com/2023/10/29/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E2%80%94%E2%80%94%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/","excerpt":"","text":"为什么需要流量控制 ？ 流量控制（Flow control）是链路层中主要功能之一，主要目的是确保发送方不会溢出接收方的缓冲区。这是一种防止发送方发送太多数据给接收方，后者来不及处理的机制。 流量控制协议 乌托邦协议 乌托邦协议（Utopian simplex protocol）是最理想状态下的传输协议，此协议有以下假设： 单工信道（Simplex channel） 信道无错（Error-free），即不会发生帧错误 接收方有不受限制的缓存（Unlimitied buffers） 乌托邦协议是非常理想的协议，正如其名字一样，实际的链路层通信是完全不一样的，由于接收方缓存有限，且信道的差错无可避免，我们需要考虑流量控制和差错控制。 ARQ 自动重传请求（Automatic Repeat reQuest，简称 ARQ）是一种用于数据通信中的错误控制方法。当传输的数据帧在接收端被检测到有错误时，ARQ 协议会要求发送端重新发送该帧。这种机制确保了数据的完整性和正确性。ARQ 通常与前向纠错编码（FEC）相结合，后者允许在不重新发送数据的情况下纠正错误。 接下来要介绍的停等协议和滑动窗口协议，都属于 ARQ。 停等协议 停等协议（Stop-and-Wait protocol）引入了应答（ACK）的概念，每次发送方发出一个数据帧后，接收方接受数据帧，如果接受成功就会发送一个应答（ACK），只有发送方接收到 ACK 后才会发送下一个数据帧。如果发送方长时间没有收到 ACK，则其会认为接收方没有收到目标数据帧，就会重新发送该数据帧。 有些协议中可能会有否定应答（NAK），即接收方收到数据，通过纠错码（如 CRC）判断数据出错后会向发送方发送 NAK，发送方收到 NAK 后则会重新发送数据帧。 以上展示了停等协议的四种主要情况，在情况（d）中，发送方没有成功接收到接收方的 ACK，其认定数据帧传输失败，于是重新传输数据帧，造成了数据冗余（Duplication）。 为了解决 ACK Lost 的问题，我们引入了 SN（Sequence number）编号。 在停等协议中，帧和 ACK 的 SN 编号只需要 1 个 bit 即可，具体操作如下： 发送方按照奇偶次序依次发送 SN 编号为 0 和 1 的帧，接收方则在收到发送方的信号后返回对应的 ACK。 使用 SN 编号的停等协议就可以解决之前提到的全部问题了。 数据帧丢失（Frame gets lost） ACK 丢失（ACK Lost） ACK 延迟（ACK Delayed） 注：ACK 也必须要有 SN 编号，如果只对数据帧编号，则上图的接收方在收到 Frame 0 的重传递后会发送一个一样的 ACK，若发送方发送了 Frame 1 且接收方没有收到，则发送会误判接收方成功收到了 Frame 0 和 Frame 1，实际上接收方只收到了 Frame 0。 计时器（Timer）： 一般而言，发送方会设置一个固定的 Timeout interval，一旦在发送目标帧 i 后如果没有在规定的时间内收到 ACK（i），则会重新发送数据帧 i，这个时间段不宜过短，如果太短，可能导致发送方发送过多不必要的数据帧；也不宜过长，不然会导致数据接收的响应慢。 停等协议的优缺点 优点： 简单性（Easy to implement）：停等协议的结构简单，容易实现。对于需要简单可靠数据传输的应用，该协议可能是合适的。 完整性（Integrity）：由于每次只发送一个数据帧并等待确认，所以在低误差率的通信环境中，可以确保数据的完整性。 缺点： 低效率（Low efficiency）：在高带宽或大延迟的通信环境中，停等协议的效率可能会很低。因为大部分时间可能都花在了等待确认上，而不是数据传输。 延迟（Dalay）：每次发送一个数据帧后都要等待确认，这增加了传输的总延迟。 资源利用不足（Insufficient utilization of resources）：在有大量可用带宽的情况下，停等协议可能无法充分利用所有的带宽，导致带宽浪费。 滑动窗口协议 捎带应答 捎带应答（Piggybacking）指的是在全双工（Full-duplex）信道传输中，接收方在收到数据帧后先将 ACK 暂存起来，然后将其捎带在数据帧处发送出去，这样能一定程度上节约信道的使用。 什么是滑动窗口协议 ？ 更确切来说，这里提到的滑动窗口（Sliding window），主要由两部分组成： 发送窗口（Sending window） 发送方维护一个窗口，只有处于该窗口的数据帧可以被发送。 接收窗口（Receiving window） 接收方维护一个窗口，只能处于该窗口的数据帧可以被接收。 滑动窗口协议允许发送方在收到 ACK 之前发送多个数据帧。 在滑动窗口协议中，若发送窗口大小为 \\(W_T\\) ，接收窗口大小为 \\(W_R\\) ，SN 模数为 \\(m\\)（通常 \\(m = 2 ^ n\\)），则必须满足 \\(W_T + W_R \\leq m\\) ，至于原因，我们会在下文中介绍。 累积 ACK 累计 ACK（Cumulative ACK），即一种记录累积效果的 ACK，若发送方收到 ACK（i），则说明 Frame（0 ~ i）都被成功接收。 Go-Back-N 在 Go-Back-N 协议中，如果某个帧接收失败，则接收方会拒绝所有在此之后发送过来的数据帧直到错误帧被成功接收。因此若发送方发送的数据帧未被成功接收，则其必须回退重发该帧。 一般而言，GBN 协议中接收窗口的尺寸为 1，因此某一时刻只能接收特定帧。 数据帧损坏： 接收方检测到 Frame（i）出错 接收方丢弃 Frame（i）与所有后续帧 超时之后，发送方重发 Frame（i）与后续帧 ACK 丢失： 接收方成功收到 Frame（i）并发送了 ACK（i），但是发送方没有成功收到 ACK 但由于这里的 ACK 记录累积效果，所以如果在 Frame（i）重传之前收到了 ACK（i + n），那么 Frame（i）就不需要再重传 如果超时，重传 Frame（i）与后续帧 根据上文提及的 \\(W_T + W_R \\leq m\\)，我们不难得出在 GBN 协议中有 \\(W_T + 1 \\leq m\\) ，即 \\(W_T &lt; m\\) ，如果 \\(W_T \\geq m\\) 会发生什么事情呢？ 如上图所示，接收窗口的大小等于 SN 模数（4），若前 4 帧的 ACK 均未被成功接收，则发送方会因为超时重新发送 Frame（0），此刻接收方的接收窗口恰好与发送窗口有重叠部分 0，此时接收方会错误地接收冗余的 Frame（0）并认为这是新的一帧。 因此 \\(W_T + W_R \\leq m\\) 其实就是为了保证： 当发送方发送完发送窗口内所有帧，在未收到 ACK 之前，接收方正确接收到所有发送来的帧，接收窗口向前推移，此时，必须保证发送窗口与接收窗口在序号上不能重叠。 选择重传协议 选择重传协议（Selective Repeat ARQ），与 GBN 协议相比，选择重传协议更加高效，其减少了重传的次数，同时也更加复杂。 与 GBN 协议不同的是，选择重传协议的接收窗口尺寸通常更大，这意味着接收方可以接受失序的帧。当接收到失序的帧时，它不会丢弃这些帧，而是将它们缓存起来，并为每个正确接收的帧发送确认。 上图中接收方在收到 Frame（4）和 Frame（5）后依然发送 ACK（1）是因为目前连续接收成功的帧只有 0 ~ 1，在收到 Frame（2）后才会发送 ACK（5）。 假设 SN 模数为 \\(2 ^ n\\) ，则在选择重传协议中发送窗口和接收窗口尺寸的选择有以下要求： \\(W_T + W_R \\leq 2 ^ n\\) \\(W_T \\geq W_R\\) 一般而言，我们会选择 \\(W_T = W_R = 2 ^ {n - 1}\\)","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"流量控制","slug":"流量控制","permalink":"http://example.com/tags/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/"},{"name":"数据链路层","slug":"数据链路层","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"}]},{"title":"RSA 加密算法","slug":"RSA 加密算法","date":"2023-10-17T09:32:24.000Z","updated":"2024-01-01T02:50:52.603Z","comments":true,"path":"2023/10/17/RSA 加密算法/","link":"","permalink":"http://example.com/2023/10/17/RSA%20%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","excerpt":"","text":"前置知识 欧拉函数 欧拉函数，即 \\(\\phi(n)\\) ，表示不超过 \\(n\\) 的数中与 \\(n\\) 互素的数的个数。 当 \\(n\\) 为素数时，显然有 \\(\\phi(n) = n - 1\\) 欧拉函数的常用性质 积性函数：若 \\(gcd(x, y) = 1\\) ，则有 \\(\\phi(xy) = \\phi(x) \\phi(y)\\) \\(n = \\sum_{d | n} \\phi(d)\\) 若 \\(n = p ^ k\\) ，\\(p\\) 是素数，则有 \\(\\phi(n) = p ^ k - p ^ {k - 1}\\) 若 \\(n = \\prod_{i = 1} ^ s p_i ^ {k_i}\\) ，则有 \\(\\phi(n) = n \\prod_{i = 1} ^ s \\frac{p_i - 1}{p_i}\\) \\(\\phi(n) = \\sum_{d | n} d\\ \\mu(\\frac{n}{d})\\) 欧拉定理 若 \\(gcd(a, n) = 1\\)，则有： \\[ a ^ {\\phi(n)} \\equiv 1\\ (mod\\ n) \\] 逆元 对于整数 \\(x\\) 而言，若存在 \\(y\\) 使得 \\(xy \\equiv 1\\ (mod\\ p)\\)，则称 \\(y\\) 是 \\(mod\\ p\\) 意义下的逆元，记做： \\[ y \\equiv x ^ {-1}\\ (mod\\ p) \\] RSA 加密算法 RSA（Rivest-Shamir-Adleman）是一种非对称加密算法，它使用一对密钥，分为公钥和私钥。公钥用于加密数据，而私钥用于解密数据。RSA 是目前广泛用于加密和数字签名的加密技术之一。它的名称源自其发明者：Ron Rivest、Adi Shamir 和 Leonard Adleman。 RSA 的具体过程可以描述如下： 挑选两个大素数 \\(p\\) 和 \\(q\\)，令 \\(n = pq\\)，\\(n\\) 在这里称为模数 计算 \\(n\\) 的欧拉函数，\\(\\phi(n) = (p - 1)(q - 1)\\) 选择一个公开的加密指数（公钥）\\(e\\)（通常是一个小素数，\\(e &lt; \\phi(n)\\)），同时生成 \\(e\\) 在 \\(mod\\ \\phi(n)\\) 意义下的逆元 \\(d\\)，即 \\(ed \\equiv 1\\ (mod\\ \\phi(n))\\) 加密过程：\\(c = m ^ e\\ mod\\ n\\) \\(key_e = \\{e, n\\}\\) 解密过程：\\(m = c ^ d\\ mod\\ n\\) \\(key_d = \\{d, n\\}\\) 原理： \\[ c ^ d = m ^ {ed} = m ^ {k\\phi(n) + 1} \\] 由欧拉定理： \\[ c ^ d \\equiv m ^ {k\\phi(n) + 1} \\equiv m\\ (mod\\ n) \\] 代码实现 生成密钥： 12345678910111213141516171819202122232425262728293031from cryptography.hazmat.backends import default_backendfrom cryptography.hazmat.primitives.asymmetric import rsafrom cryptography.hazmat.primitives import serialization# 生成RSA密钥对private_key = rsa.generate_private_key( public_exponent=65537, key_size=2048, backend=default_backend())# 保存私钥到文件with open(&quot;private_key.pem&quot;, &quot;wb&quot;) as private_key_file: private_key_pem = private_key.private_bytes( encoding=serialization.Encoding.PEM, format=serialization.PrivateFormat.PKCS8, encryption_algorithm=serialization.NoEncryption() ) private_key_file.write(private_key_pem)# 获取公钥public_key = private_key.public_key()# 保存公钥到文件with open(&quot;public_key.pem&quot;, &quot;wb&quot;) as public_key_file: public_key_pem = public_key.public_bytes( encoding=serialization.Encoding.PEM, format=serialization.PublicFormat.SubjectPublicKeyInfo ) public_key_file.write(public_key_pem) 加密 &amp; 解密： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from cryptography.hazmat.backends import default_backendfrom cryptography.hazmat.primitives import hashesfrom cryptography.hazmat.primitives.asymmetric import paddingfrom cryptography.hazmat.primitives import serialization# 加载私钥with open(&quot;private_key.pem&quot;, &quot;rb&quot;) as private_key_file: private_key = serialization.load_pem_private_key( private_key_file.read(), password=None, backend=default_backend() )# 加载公钥with open(&quot;public_key.pem&quot;, &quot;rb&quot;) as public_key_file: public_key = serialization.load_pem_public_key( public_key_file.read(), backend=default_backend() )# 要加密的数据data = b&quot;Hello, RSA encryption!&quot;# 加密数据ciphertext = public_key.encrypt( data, padding.OAEP( mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None ))print(&quot;Ciphertext:&quot;, ciphertext)# 解密数据plaintext = private_key.decrypt( ciphertext, padding.OAEP( mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None ))print(&quot;Decrypted Data:&quot;, plaintext.decode(&#x27;utf-8&#x27;))","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"密码学","slug":"密码学","permalink":"http://example.com/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"RSA","slug":"RSA","permalink":"http://example.com/tags/RSA/"}]},{"title":"I/O 与磁盘","slug":"IO 与磁盘","date":"2023-10-15T15:43:38.000Z","updated":"2023-12-31T04:02:58.519Z","comments":true,"path":"2023/10/15/IO 与磁盘/","link":"","permalink":"http://example.com/2023/10/15/IO%20%E4%B8%8E%E7%A3%81%E7%9B%98/","excerpt":"","text":"I/O I/O 是计算机科学中的一个常见缩写，它代表了输入/输出（Input/Output）的意思。在计算机系统中，I/O 涉及到计算机与外部设备之间的数据传输。输入通常是指从外部设备（如键盘、鼠标、磁盘驱动器、网络等）传输数据到计算机系统，而输出是指从计算机系统传输数据到外部设备。 I/O 是操作系统中非常复杂的一个话题，因为其牵涉到相当多部分。 计算机系统中不同操作的延迟或响应时间的估计数字： 内存访问延迟： 访问计算机内存通常是非常快的操作，延迟通常在纳秒级别（几十纳秒或更短）。这意味着从内存读取或写入数据的速度非常快。 磁盘 I/O 延迟： 与内存相比，访问磁盘通常更慢。典型的磁盘读取操作可能需要几毫秒（毫秒）的时间，具体取决于磁盘驱动器的类型和性能。 网络通信延迟： 网络通信延迟取决于网络延迟和带宽，通常在几毫秒到数十毫秒之间。这包括发送数据到远程服务器和接收响应的时间。 计算机存储结构 下图展示了典型现代计算机系统的数据存储结构以及 I/O 在该结构中的位置： 寄存器（Registers）是计算机系统中最快速、最小的存储设备之一，用于存储和处理数据。它们通常位于中央处理单元（CPU）内部，并用于执行计算和控制指令。由于其极高的速度，寄存器在执行计算和控制任务时起到关键作用，而且在 CPU 设计和程序优化中具有重要意义。 高速缓存（Cache）是计算机系统中用于提高数据访问速度和性能的关键组件。它是一种快速存储器，用于存储最常用的数据，以减少对较慢存储器（如主内存或硬盘驱动器）的访问次数。 计算机系统通常采用多层内存层次结构，其中包括高速缓存、主内存和较慢的外部存储器（如硬盘驱动器）。高速缓存位于主内存和中央处理单元（CPU）之间，具有不同级别，如一级缓存（L1）、二级缓存（L2）、三级缓存（L3）等。 动态随机访问存储器（Dynamic Random-Access Memory，DRAM）的缩写，它是计算机系统中广泛使用的主要内存类型之一。DRAM 是一种易失性存储器，用于存储计算机程序和数据，但它需要不断刷新以保持数据的完整性。与 CPU 缓存不同，DRAM 的容量通常较大，但速度较慢。 次级存储（Secondary storage）是计算机系统中的一种主要存储层级，用于长期数据存储和备份。与主内存（RAM）不同，它通常是非易失性的，意味着数据在断电后仍然保持完好。次级存储包括各种设备和媒体，例如硬盘驱动器（HDD）、固态硬盘（SSD）、光盘（如 CD 和 DVD）、磁带、USB 闪存驱动器、网络附加存储（NAS）以及云存储服务等。 硬盘驱动器（Hard Disk Drive，HDD）是一种常见的计算机数据存储设备，用于长期数据存储和检索。HDD 使用旋转的磁性盘片和机械臂来读写数据。 HDD 内部包含一个或多个盘片（通常是金属或玻璃制成），盘片上分成了一系列磁性轨道和扇区。数据以磁性方式存储在这些表面上。机械臂负责将读/写头移动到正确的磁道上来读取或写入数据。磁头将数据编码为磁性位，然后根据需要将其读取或写入。 固态硬盘（Solid-State Drive，SSD）是一种用于数据存储的非机械式存储设备。SSD 是一种高性能、可靠、耐用且节能的数据存储解决方案，它已经取代了许多传统的 HDD，并成为现代计算机和移动设备的标配之一。 I/O 控制器（I/O Controller），是计算机系统中的硬件组件，用于管理和协调输入和输出设备的数据传输和通信。I/O 控制器起到桥梁的作用，协调主处理器（CPU）与外部设备之间的数据交换。不同类型的 I/O 控制器针对不同类型的设备，如存储设备、网络设备和外围设备等，都具有特定的功能和特点。 I/O 传输 I/O bus I/O 总线（I/O Bus）是计算机体系结构中的一个关键组成部分，用于传输数据和控制信息，以连接计算机主板上的主处理器（CPU）和内存与外部设备之间。I/O总线是计算机系统内部的物理或电子通道，它允许不同类型的输入/输出设备与计算机进行通信，包括硬盘驱动器、键盘、鼠标、显示器、打印机、USB 设备和网络适配器等。 总得来说，我们可以认为 I/O 总线由两部分组成： 一组连接设备用于数据传输的线（Wires） 数据传输操作的协议（Protocols） 不同类型的计算机和体系结构可能使用不同的 I/O 总线标准，如 PCI（Peripheral Component Interconnect）、PCI Express、USB、SATA 等。这些标准规定了总线的电气和物理规格，以确保设备的互操作性。 PCI Bus（Peripheral Component Interconnect Bus）： PCI 是一种高性能总线标准，最早于1992年引入，并经过多次更新和改进。PCI 总线具有较高的数据传输速度和带宽，通常适用于连接高性能设备，如图形卡等等。 SCSI Bus（Small Computer System Interface Bus）： SCSI 是一种用于连接计算机和外部设备的标准接口。它最早出现于1980年代。现在 SCSI 总线用于连接各种类型的设备，包括硬盘驱动器、光盘驱动器、打印机、扫描仪、磁带驱动器等。它通常用于需要高性能和可靠性的存储设备。 操作系统与 I/O 的交互 操作系统和 I/O 设备之间的交互通常需要使用寄存器来管理和监控 I/O 操作的进展和状态。这些寄存器通常是硬件设备上的寄存器，用于记录设备的状态和控制信息。 状态寄存器（Status Register）： 状态寄存器通常包含设备的当前状态信息，如设备是否忙碌、是否就绪、是否有错误等。操作系统可以定期轮询这个寄存器来检查设备状态，以决定是否可以执行 I/O 操作。 典型的状态位包括忙碌位（Busy）、错误位（Error）、就绪位（Ready）等。 数据寄存器（Data Register）： 数据寄存器用于实际的数据传输，包括从 CPU 发送数据到设备或从设备接收数据到 CPU。操作系统通过读取或写入数据寄存器来传递数据。我们可以认为数据寄存器充当了数据传输的临时存储区域，允许数据在不同硬件模块之间进行有效的交换。 命令寄存器（Command Register）： 命令寄存器包含了控制 I/O 设备的命令码。这些命令码告诉设备要执行的操作，例如读取、写入、打开、关闭、复位等。通过命令寄存器，操作系统可以向设备发送启动或停止命令，以开始或终止 I/O 操作。 一个典型的操作系统与 I/O 交互的执行过程： 操作系统根据状态寄存器判断什么时候某个设备处于就绪状态（Ready）； 若启动 I/O，则操作系统会向数据寄存器写入数据，并且设置命令寄存器的数据为我们需要的 I/O 操作的操作码（此时，I/O 控制器会设置该设备的状态寄存器为 Busy）； I/O 控制器接下来读取命令寄存器和数据寄存器的内容，并开始执行命令； 操作系统根据执行结果对状态寄存器进行修改： 若正常执行结束，即所有指令都执行完成，控制器将清除该命令，并将其 Busy 状态复位 若出现异常状态，则在必要情况下将状态寄存器设置为 Error 中断 &amp; 轮询 在执行 I/O 操作时，操作系统需要知道： 某个设备是否完成了 I/O 操作 某个设备的特定 I/O 操作是否遇到了异常 这意味着 I/O 设备必须与 OS 实现有效通信。 I/O 中断（I/O Interrupt） 当设备需要 CPU 的处理时，I/O 设备会生成一个中断信号，CPU 在接收到中断信号后立即暂停正在执行的任务，保存当前状态（通常通过将寄存器内容保存到堆栈），并跳转到中断处理程序。中断处理程序负责执行与中断相关的任务，然后返回到先前中断之前的任务。 中断是异步的，它们随时可能发生，而不需要 CPU 连续地检查设备状态。 优点：能较好地处理不可预判的异常（Great robustness） 缺点：开销大（High overhead） 这里的开销主要来自于 I/O 中断造成的上下文切换（Context switching） 轮询（Polling） 在轮询中，操作系统或应用程序周期性检查设备的状态寄存器，以查看是否需要处理。如果发现有事件发生，系统会采取相应的措施。 优点：开销小（Low overhead） 缺点：如果 I/O 操作不频繁或不可预测，则会在轮询上花费过多时间 设备驱动程序 设备驱动程序（Device Driver）是计算机软件的一部分，它允许操作系统与硬件设备进行通信。它的主要作用是作为操作系统和物理硬件设备之间的桥梁，使得操作系统可以控制和操作硬件。 设备驱动程序为操作系统提供了一个统一的接口，使得操作系统可以与各种各样的硬件设备进行交互，而不需要知道它们的具体细节。 编程 I/O &amp; DMA 在解决状态访问的问题后我们还需要实现数据传输，常见的两种方法是编程 I/O 和直接内存访问。 编程 I/O（Programmed I/O） 编程 I/O（Programmed I/O）是计算机系统中的一种基本 I/O 操作方法，它通过 CPU 执行的程序来控制数据的传输和通信。在 Programmed I/O中，CPU 负责直接处理 I/O 操作，包括从外部设备读取数据或将数据写入外部设备。即编程 I/O 所有数据的传输都依托于处理器的指令。 优点：因为是从编程角度出发的，因此易于实现，对硬件需求低 缺点：会消耗与数据大小成比例的处理器周期 直接内存访问（Directly Memory Access，DMA） 直接内存访问（Direct Memory Access，DMA），是一种计算机系统中用于提高数据传输性能的技术。DMA 允许外部设备（如硬盘驱动器、网络适配器、图形卡等）直接访问主内存，而无需 CPU 的直接干预，从而减少 CPU 的负担，提高数据传输效率。 DMA 的具体过程： 设备驱动程序被通知：首先，CPU 告诉设备驱动程序需要从磁盘将数据传输到内存中的某个缓冲区（地址 X）。 设备驱动程序通知磁盘控制器：设备驱动程序随后指示磁盘控制器从磁盘传输 C 字节的数据到内存中的缓冲区（地址X）。 磁盘控制器启动 DMA 传输：磁盘控制器开始 DMA 传输的过程。 磁盘控制器与 DMA 控制器的交互：磁盘控制器将每一个字节发送到 DMA 控制器。 DMA 控制器传输数据：DMA 控制器开始向缓冲区 X 传输字节，同时递增内存地址，并减少 C 的值，直到 C 变为 0。 DMA 中断 CPU：当所有的数据都被传输完毕（即 C = 0）时，DMA 会发出一个中断信号给 CPU，告知其数据传输已经完成。 内存映射 I/O 内存映射 I/O（Memory-mapped I/O）是一种在计算机系统中用于管理 I/O 设备的通用方法，它允许操作系统和应用程序将 I/O 设备视为内存地址范围的一部分，使其可以直接读取和写入设备数据，就像操作内存一样。 在内存映射 I/O 中，每个 I/O 设备都被分配一个在物理内存地址空间中的范围。这个地址范围通常称为设备寄存器的地址空间，其中包含了与设备通信的特定寄存器（状态寄存器、数据寄存器、命令寄存器等等）和数据缓冲（Buffer）。 注：该内存分配区域一般只用于 I/O 通信而不会进行其他操作。 I/O 的四大类型 同步阻塞 I/O（Synchronous Blocking I/O） 最常见的 I/O 模型之一就是同步阻塞 I/O 模型。在这种模型中，用户空间应用程序执行一个系统调用，导致应用程序阻塞。这意味着应用程序会一直阻塞，直到系统调用完成（数据传输或出错）。调用应用程序处于不消耗 CPU 的状态，只是等待响应，因此从处理角度来看是高效的。 同步非阻塞 I/O（Synchronous Non-blocking I/O） 同步非阻塞 I/O 是同步阻塞的一个效率较低的变体。在这种模型中，设备以非阻塞方式打开。这意味着，与其立即完成一个 I/O 操作，读操作可能返回一个错误代码，表明命令不能立即得到满足（EAGAIN 或 EWOULDBLOCK）。 异步阻塞 I/O（Asynchronous Blocking I/O） 另一种阻塞范式是使用阻塞通知的非阻塞 I/O。在这种模型中，配置了非阻塞 I/O，然后使用阻塞的 select 系统调用来确定何时存在针对 I/O 描述符的任何活动。使 select 调用变得有趣的是，它可以用来为不只一个描述符提供通知，而是多个。对于每个描述符，你可以请求通知描述符写数据的能力、可读数据的可用性，以及是否发生了错误。 异步非阻塞 I/O（Ansynchronous Non-blocking I/O） 最后，异步非阻塞 I/O 模型是一个 I/O 与处理重叠的模型。读取请求立即返回，表示读取操作已经成功启动。应用程序随后可以在后台读取操作完成的同时执行其他处理。当读取响应到达时，可以生成一个信号或基于线程的回调来完成 I/O 事务。 一个 I/O 请求的生命周期 磁盘 磁盘（Disk）是计算机系统中用于存储数据的主要外部设备之一。磁盘是一种非易失性存储媒体，意味着数据会在断电或重启后仍然保留。 HDD 基本结构 硬盘驱动器（Hard Disk Drive，HDD）是一种用于存储数据的计算机存储设备。HDD 是一种机械式存储设备，其工作原理是使用旋转的磁性盘片和移动的读写磁头来读取和写入数据。 磁道（Track）： 磁道是硬盘驱动器上的一个圆形轨迹或路径，位于硬盘盘片的表面上； 硬盘的每个盘片通常包含多个同心圆磁道，这些磁道从盘片的中心开始，向外扩展； 每个磁道上的数据通常具有相似的物理位置，因此可以更快地被访问。 柱面（Cylinder）： 柱面是多个硬盘盘片上相同位置的磁道的集合； 每个盘片上具有相同半径位置的磁道被组合成一个柱面； 从柱面的角度来看，这些磁道在不同盘片之间对齐，因此它们可以一起被读取或写入，从而提高数据的传输速度。 扇区（Sector）： 扇区是磁道上的最小存储单位，通常包含 512 字节或更多数据； 每个磁道被划分成多个扇区，以便更有效地存储和检索数据； 操作系统和硬件通过扇区来访问硬盘上的数据。数据的读取和写入是以扇区为单位进行的。 时延分析 HDD 技术寻址并传输数据的时间开销我们可以认为由以下 3 部分组成： 寻道时间（Seek time）：即移动磁头到目标所在柱面和磁道所花费的时间。寻道时间受到磁头移动的距离和速度的影响。较短的寻道时间表示硬盘可以更快地访问数据，因此是一个性能指标。 旋转延迟（Rotational delay）：找到目标位置后需要旋转磁盘使得磁头落在目标扇区，这由磁盘盘片的旋转速度相关（单位：RPM，每分钟旋转次数）。 传输延迟（Transfer delay）：使用读写头来传输数据。实际的数据传输时间取决于硬盘的数据传输速度。这通常以每秒字节（Bps）或兆字节每秒（MBps）来表示。 我们假设某个 HDD 设备的平均寻道时间是 5ms，盘片旋转速度为 7200 RPM，传输速率为 50 MB/s，一个数据块的大小为 4KB，则有： 平均旋转延迟 = 盘片旋转一圈的时间 / 2 = 8ms / 2 = 4ms 一个数据块的平均传输时间 = 4 KB / 50 MB/s = 0.08ms 进一步，我们可以得到： 随机读取一个数据块的时间开销 = 平均寻道时间 + 平均旋转延迟 + 数据块传输延迟 = 9.08ms 随机读取同一个柱面的某个数据块的时间开销 = 平均旋转延迟 + 数据块传输延迟 = 4.08ms 读取同一个柱面同一个磁道的下一个数据块的时间开销 = 数据传输延迟 = 0.08ms 磁盘调度 由于 HDD 获取盘片速度较慢，所以我们当我们的任务队列中有多个任务时需要合适的调度策略来处理任务。 假设我们的任务队列当前有 6 个任务，每个任务所在磁道与盘片圆心的距离分别为 99，10，50，150，11，30。则这些任务在不同调度策略下的磁头移动方式如下： FIFO 先来先服务（First In First Out，FIFO），即严格按照队列结构实行先进先出。 优点：最公平。 缺点：由于任务位置可能是随机的，可能会花费很多寻道时间。 SSTF 最短寻道时间优先（Shortest Seek Time First，SSTF），即磁头每次都向最近的任务移动。 优点：利于减少寻道时间。 缺点：可能在调度出现某个任务长期未得到响应而造成饥饿。 Scan Scan 调度，也叫电梯算法（Elevator algorithm），相比于 SSTF，Scan 策略每次只选择当前运动方向最近的请求。当完成磁道半径最大的请求后就会逆转当前方向。 优点：避免了请求饥饿。 缺点：某些情况可能不够公平。（比如上图在磁道 10 处的请求） C-Scan C-Scan 调度，就是在 Scan 调度的基础上，不处理逆转方向过程中遇到的任何请求，这可以使得 C-Scan 调度相比于 Scan 调度而言更加公平。 SSD 即固态硬盘（Solid State Drive，SSD），是一种用于数据存储的存储设备，它使用集成电路（Integrated circuits）来存储数据，而不像传统硬盘驱动器（HDD）那样使用旋转磁盘和机械臂来读写数据，SSD 中没有任何异动的机械器件。 SSD 由于不依赖机械臂读写数据，所以 SSD 读写数据就不再受到像 HDD 中的寻道时间和旋转延迟的限制。 NAND 闪存 在 SSD 中广泛使用 NAND 闪存（NAND cell flash memory）技术，其通过晶体管（Transistor）存储一个或多个 bit，通过此可以划分为两种类型： SLC（Single Level Cell）：每个存储单元只存储一个 bit。 特点：快速、高耐用性（Endurance）、成本高 MLC（Multiple Level Cell）：每个存储单元可以存储多个 bit，一般是 2 ~ 3。 特点：相对较慢、低耐用性、成本低 有关耐用性： SSD 中存储单元的擦除/写入次数是受到限制的，每次执行擦除和写入操作时，存储单元中的浮动栅承受一定的电荷和电压压力。随着时间的推移，这些操作会导致存储单元中的浮动栅逐渐受损，降低了其可靠性和性能。 MLC 闪存相对 SLC 而言更容易受到擦除/写入次数限制，因为它每个存储单元的擦除/写入次数较少。这意味着 MLC 闪存的寿命可能会较短，尤其在高度写入密集的应用中。 Flash 芯片结构 SSD 采用 Flash 芯片结构（Flash Chip Structure），其结构可以划分如下： 一个芯片可以划分为多个块组（Banks） 一个块组可以划分为多个块（Blocks）（e.g. 256KB） 一个块可以划分为多个页（Pages）（e.g. 4KB） SSD 中的读与写 读取（Reading） 操作单位：页（Page) 运行时间大约 10ms，远快于 HHD 写（Writing） 每次在执行写操作前要先擦除数据（Erasing a block），具体操作如下： 将目标数据块的所有 bit 置为 1（1 ～ 2ms） 对相应的页执行写操作，将一些 bit 设置为 0（200ms 左右） HDD vs SSD 对于随机访问 I/O（Random-access I/O），SSD 具有更大的优势，因为其没有机械部件带来的时间开销。 对于顺序访问 I/O（Sequential-access I/O），二者差距较小。 相比于 HDD，SSD 质量更轻、功耗更少、运行噪声也更小。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"I/O","slug":"I-O","permalink":"http://example.com/tags/I-O/"}]},{"title":"贝叶斯分类器","slug":"贝叶斯分类器","date":"2023-10-14T11:42:20.000Z","updated":"2023-11-18T05:04:24.466Z","comments":true,"path":"2023/10/14/贝叶斯分类器/","link":"","permalink":"http://example.com/2023/10/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/","excerpt":"","text":"核心思想 贝叶斯分类器是一种基于贝叶斯定理的统计分类方法。在给定数据的情况下，它使用概率模型来预测数据点的类别。贝叶斯分类器的核心思想是，对于给定的样本，我们可以计算它属于每个类别的概率，并将样本分配给概率最大的类别。 贝叶斯公式： \\[ P(A | B) = \\frac{P(B | A) P(A)}{P(B)} \\] 先验概率（Prior Probability）：指在没有额外信息的情况下，一个事件发生的概率。 后验概率（Posterior Probability）：给定某些证据后，时间发生的概率。 似然性（Likelihood）：给定假设为真时观察到证据的概率。 使用后验概率来进行分类的分类器称之为贝叶斯分类器（Bayes Classifier）。 数学表示 我们以二分类问题为例，假设在数据集 \\(S\\) 中的数据有两个类 \\(A\\) 和 \\(B\\) ，则贝叶斯分类器一般用优势比（Odds Ratio）来描述某个数据点的所属类别： \\[ \\frac{P(y = A|x)}{P(y = B|x)} \\] 若上式子大于 1，即 \\(P(y = A | x) &gt; P(y = B | x)\\)，则认为数据点的特征向量为 \\(x\\) 的情况下，其属于 \\(A\\) 类的概率更大，反之则认为其属于 \\(B\\) 类的概率更大。 根据贝叶斯公式，上式可以表示为： \\[ \\frac{P(x | y = A) P(y = A)}{P(x | y = B) P(y = B)} \\] 其中 \\(P(y = A)\\) 和 \\(P(y = B)\\) 由两个类别在数据集中的占比决定，而 \\(P(x | y = A)\\) 和 \\(P(x | y = B)\\) 则由两个类别中数据的分布相关。 判别分析 判别分析（Discriminant Analysis）是机器学习和统计学中的一种技术，用于将一组观测值分类到预定义的类别中。该方法假设不同的类别通过不同的高斯分布（Guassian Distribution）生成数据。 \\[ p(x | y = A) = \\frac{1}{(2 \\pi) ^ {\\frac{d}{2}} {|\\Sigma_A|} ^ \\frac{1}{2}} exp(-\\frac{1}{2}(x - \\mu_A) ^ T \\Sigma_A^{-1} (x - \\mu_A)) \\] \\[ p(x | y = B) = \\frac{1}{(2 \\pi) ^ {\\frac{d}{2}} {|\\Sigma_B|} ^ \\frac{1}{2}} exp(-\\frac{1}{2}(x - \\mu_B) ^ T \\Sigma_B^{-1} (x - \\mu_B)) \\] 主要类型的判别分析包括： 线性判别分析（Linear Discrinant Analysis，LDA）：这种方法假设不同类别具有相同的协方差矩阵。它找到一个特征的线性组合，这个组合能够表征或者区分两个或多个类别。目的是在类别之间找到一个线性边界。 二次判别分析（Quadratic Discrinant Analysis，QDA）：与 LDA 不同，QDA 假设每个类别都有自己的协方差矩阵。它在分类上更加灵活，因为它可以创建二次边界，因此得名。 通常而言，两个类别的协方差矩阵相等或者十分接近，例如其差值的矩阵二范数 \\(||\\Sigma_A - \\Sigma_B || ^ 2\\) 是一个很小的值，我们就可以认为数据集的判别分析类型为 LDA。 考虑错误分类成本 在机器学习和统计分类问题中，错误分类成本（Misclassification Costs）指的是将一个实例错误分类为另一个类别时所产生的代价或损失。在某些情况下，不同类型的错误可能会导致不同程度的负面影响。例如，在医疗诊断中，将患有疾病的病人错误地判定为健康（漏诊）通常比将健康的病人错误判定为患病（误诊）带来更严重的后果。 错误分类成本可以是不对称的，意味着对于不同的错误分类，成本可以不一样。在设计分类器时，我们通常希望最小化总体的错误分类成本，而不仅仅是错误分类的数量。 考虑错误分类成本的贝叶斯分类器（也称为成本敏感的贝叶斯分类器）是一种在决策过程中考虑到不同类型错误分类所带来成本的分类器。这种分类器不仅仅追求最大化整体的准确率，而是尝试最小化总的期望分类成本。 以上文提及的二分类为例，我们定义成本矩阵（Costs Matrix）： \\[ C = \\begin{bmatrix} C(A | A) &amp; C(A | B) \\\\ C(B | A) &amp; C(B | B) \\end{bmatrix} \\] 在成本矩阵中 \\(C(I | J)\\) 表示将标签为 \\(J\\) 类的数据识别为 \\(I\\) 类需要付出的成本。 对于一个新的实例 \\(x\\) ，我们可以计算出其属于每个类别的期望成本： \\[ EC(y = A | x) = P(y = A | x)C(A | A) + P(y = B | x) C(A | B) \\] \\[ EC(y = B | x) = P(y = B | x)C(B | B) + P(y = A | x)C(B | A) \\] 最后我们只需要选择期望成本最小的类别即可，我们一般认为 \\(C(A | A) = C(B | B) = 0\\)，因为通常情况下正确识别不需要花费额外的成本。 因此考虑错误分类成本的优势比可以表示如下： \\[ \\frac{P(y = A | x)C(B | A)}{P(y = B | x)C(A | B)} \\] 即如果满足 \\(\\frac{P(y = A | x)}{P(y = B |x)} &gt; T\\ (T = \\frac{C(A | B)}{C(B | A)})\\) ，则考虑将样本 \\(x\\) 划分为 A 类更合适。\\(T\\) 在这里就是分类器的阈值，不同的 \\(T\\) 会有不同的分类边界。 分类器的评估 混淆矩阵 混淆矩阵（Confusion Matrix）是一种特定的表格用于可视化算法性能，尤其是在监督学习中对分类问题的性能评估。它展示了实际类别与模型预测类别之间的关系，以此来揭示模型在各个类别上的错误类型。 对于一个二分类问题，混淆矩阵包含四个部分： 真正例（True Positives, TP）：模型正确预测为正类的数量。 假正例（False Positives, FP）：模型错误预测为正类的数量。 真负例（True Negatives, TN）：模型正确预测为负类的数量。 假负例（False Negatives, FN）：模型错误预测为负类的数量。 混淆矩阵通常如下所示： \\[ \\begin{array}{cc} &amp; \\text{预测正类} &amp; \\text{预测负类} \\\\ \\text{实际正类} &amp; TP &amp; FN \\\\ \\text{实际负类} &amp; FP &amp; TN \\\\ \\end{array} \\] 这个矩阵使我们能够快速计算出几个重要的性能指标，如： 准确率（Accuracy）：所有正确分类的观测值占总观测值的比例，计算公式为 \\((TP + TN) / (TP + TN + FP + FN)\\)。 精确率（Precision）：正确预测为正类的观测值占预测为正类的比例，计算公式为 \\(TP / (TP + FP)\\)。 召回率（Recall）或灵敏度（Sensitivity）：正确预测为正类的观测值占实际正类的比例，计算公式为 \\(TP / (TP + FN)\\)。 特异性（Specificity）：正确预测为负类的观测值占实际负类的比例，计算公式为 \\(TN / (TN + FP)\\)。 解决一个分类问题，实际上即使要找到一个分类边界，可以最大化敏感度和特异性。 ROC 平面与 AUC 指标 ROC（接收者操作特征）平面是用来评估二分类系统性能的图形化工具。它通过绘制真正例率（True Positive Rate, TPR）对假正例率（False Positive Rate, FPR）来展示分类器的性能。 在 ROC 平面中： 真正例率（TPR），也就是召回率（Recall）或灵敏度（Sensitivity），是指正确识别为正例的样本占所有实际正例的比例。计算公式为：\\(\\text{TPR} = \\frac{TP}{TP + FN}\\)。 假正例率（FPR），是指错误识别为正例的样本占所有实际负例的比例。计算公式为：\\(\\text{FPR} = \\frac{FP}{TN + FN}\\) ，即 \\(1 - \\text{specificity}\\)。 在 ROC 曲线上，每个点代表对应于某个决策阈值的（FPR，TPR）对。曲线下面积（Area Under the Curve，AUC）用来量化分类器的总体性能：AUC值为 1 表示完美分类器，AUC 值为 0.5 表示无效分类器，即其性能不如随机猜测。 ROC平面上的主要特点包括： ROC 曲线越靠近左上角，分类器的性能越好：这意味着高的真正例率和低的假正例率。 ROC 曲线下的面积（AUC）越大，分类器的整体性能越好：它为我们提供了一个分类器性能的单一度量，可以用来比较不同的分类器。 ROC 曲线提供了一个无需担心类别分布或者决策阈值选择的性能度量：这使得它在评估不平衡数据集的分类器时特别有用。 因此，ROC平面和AUC指标是评估和比较分类模型性能的强有力工具。它们允许我们在不同的阈值设置下考虑分类器的性能，为选择最佳模型提供了依据。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"http://example.com/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"贝叶斯公式","slug":"贝叶斯公式","permalink":"http://example.com/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/"}]},{"title":"文件系统","slug":"文件系统","date":"2023-10-06T09:06:04.000Z","updated":"2023-10-26T03:28:05.089Z","comments":true,"path":"2023/10/06/文件系统/","link":"","permalink":"http://example.com/2023/10/06/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"文件系统介绍 文件系统（File system）是操作系统的一层，它将磁盘（或其他块设备）的块接口（Block interface）转换为文件、目录等。 文件系统的主要功能： 磁盘管理（Disk management） 将磁盘块集成文件。 命名（Naming） 接口通过名字访问文件而不是磁盘块。 保护（Protection） 保护文件数据安全。 可靠性/耐用性（Reliability/Durability） 保证文件的持久性。 文件 文件是一种对计算机上非易失性（non-volatile）存储的抽象。 其包括了： 数据（Data）： 在硬件上存储的数据块。 元数据（Metadata） 用户（Owner） 大小（Size） 最近开启时间（Last opened） 最后一次修改时间（Last modified） 权限（Access rights） 在 Unix / Linux 操作系统中，一般用 9 个 bit 来描述文件的权限，分别表示所属用户、群组用户和外部用户对该文件是否有读（Read）、写（Write）和执行（Execute）的权限。 硬链接的数量（Number of hard links to the file） 在 Unix / Linux 操作系统中，我们可以使用 ls 指令输出文件详细信息： 1ls -l demo.txt 终端输出： 1-rw-r--r--@ 1 username staff 0 10 12 16:38 demo.txt -rw-r--r-- ： 这部分显示了文件的权限模式。在这个权限模式中，有10个字符，它们按顺序表示了文件的不同权限。这个权限模式可以分为三部分： 第一位是文件的类型， - 表示 demo.txt 是一个普通文件。 接下来的 3 位（rw-）表示文件的所有者（username）具有读（r）和写（w）的权限，但没有执行（x）权限。 再接下来的3位（r--）表示文件的组（staff）具有只读（r）的权限，但没有写入（w）或执行（x）的权限。 最后的3位（r--）表示其他用户也具有只读（r）的权限，但没有写入（w）或执行（x）的权限。 可以使用 chmod 指令对文件权限进行修改： 1 ：这个数字表示文件的硬链接数。在这个示例中，文件 demo.txt 有一个硬链接。硬链接是指多个文件名指向相同的文件数据块。每个文件都有一个硬链接计数，当这个计数变为零时，文件数据才会被删除。 username ：文件所有者（Owner）的用户名。 staff ：文件所属组（Group）名。 0 ：这是文件的大小，以字节为单位。在这个示例中，文件大小为0字节，表示这是一个空文件。 10 12 16:38 ：这是文件的最后修改时间。具体来说，这个文件的最后时间是在 10 月 12 日的 16:38。 文件的需求 可变的大小（Variable size） 可实现多个并发用户和进程，同时能有保护作用（Multiple concurrent users / peocesses but with protection） 高效的查找技术（Being able to find files） 管理空闲磁盘块（Manage free disk blocks） 文件系统的组成部分 目录结构（Directory Structure） 目录结构是文件系统中用于组织和管理文件和目录的方式。通常，它采用树状结构（Hierarchy tree-like structure），类似于文件夹（目录）和文件的层次结构。根目录位于顶层，包含子目录和文件，这些子目录又可以包含更多的子目录和文件，以此类推。每个目录都可以包含文件和其他目录。 Unix / Linux 操作系统使用的目录结构是一个树状结构，根目录通常表示为 /，然后有多个子目录和文件，如 /home、/usr 等等。 文件索引结构（File Index Structure） 文件索引结构是文件系统用于管理文件和文件属性的内部数据结构。它包含有关文件的元数据信息，例如文件名、大小、创建日期、修改日期、权限和链接数等。文件索引结构的设计取决于文件系统的类型。 例如，在 Unix / Linux 中，常见的文件系统如 Ext4 使用了索引节点（Inode）结构来存储文件的元数据。每个文件和目录都有一个唯一的索引节点号，而这个索引节点包含了关于文件的所有信息。这使得操作系统能够有效地查找和管理文件。 我们可以给 ls 指令加上 -i 参数来显示文件的 inode 属性： 数据块（Data Block） 数据块是文件系统用来存储文件内容的基本单位。当文件太大以至于无法一次存储在内存中时，文件会被划分为多个数据块，每个数据块包含文件的一部分内容。这些数据块通常由文件系统管理，而文件索引结构中的信息将告诉操作系统如何组合这些数据块以获取完整的文件内容。 在大多数文件系统中，数据块通常是一个连续的、固定大小的块，例如 4KB 或 8KB。文件系统会维护一个映射，将文件的逻辑块地址映射到物理磁盘上的数据块。 文件的启动与关闭 打开文件表 操作系统需要在内存维护所有开启文件的信息。 打开文件表（Open file table）是操作系统内部用于跟踪已打开文件的数据结构，它包含了文件的元数据和状态信息，允许操作系统和进程有效地管理对文件的访问。每个正在运行的进程都有其自己的打开文件表，用于跟踪该进程所打开的文件。 系统范围的打开文件表（System-wide open file table） 系统范围的打开文件表是操作系统维护的一个数据结构，用于跟踪在整个系统范围内打开的文件。它存储了有关每个系统中已打开文件的信息（Information for every currently open file in the system），例如存储在 inode 属性中的信息（文件名、大小、所属用户等）。 系统范围的打开文件表允许不同的进程共享文件的访问信息。当多个进程打开同一个文件时，它们可以共享相同的系统范围的打开文件表条目，这意味着它们可以看到对该文件的更改。这有助于提高操作系统的效率，因为不需要为每个打开的文件创建独立的系统资源，只需在系统范围的打开文件表中引用相同的信息即可。 进程内的打开文件表（Per-process open file table） 每个进程都有自己的进程内打开文件表，用于跟踪该进程打开的文件。每个进程内的打开文件表包含了一个指向系统打开文件表的指针（A pointer to the system open file table） 和其他信息如文件描述符、文件状态标志、当前文件偏移量等。 进程内的打开文件表使每个进程能够独立地管理其打开的文件，包括读取、写入和定位文件指针等操作。这确保了不同进程之间的文件访问彼此隔离，一个进程的文件操作不会影响其他进程。 open() 和 close() 在 Linux 内核中，open() 和 close() 是两个重要的系统调用函数，用于打开和关闭文件。这些函数在文件操作中起着关键作用，允许进程与文件进行交互。 一下展示两个系统调用在 C 语言中的接口： open() 函数： open() 函数用于打开文件，并返回一个称为文件描述符（File Descriptor）的整数值，该文件描述符在后续的文件操作中用于唯一标识打开的文件。函数原型如下： 1int open(const char* pathname, int flags, mode_t mode); pathname：是要打开的文件的路径或文件名。 flags：是一组标志，用于指定文件的打开方式，如只读、只写、追加等。常见的标志包括O_RDONLY（只读）、O_WRONLY（只写）、O_RDWR（读写）、O_APPEND（追加写入）、O_CREAT（如果文件不存在则创建）、O_TRUNC（截断文件）等。 mode：是文件权限的设置，通常与 O_CREAT 标志一起使用，用于新创建的文件。（如果文件已存在则不需要传递该参数） open() 函数返回一个非负整数文件描述符，如果打开文件失败，则返回 -1。文件描述符在进程的打开文件表中唯一标识已打开的文件，可以用于后续的读取、写入和关闭操作。 close() 函数： close() 函数用于关闭先前通过 open() 函数打开的文件，释放与文件描述符相关的资源。函数原型如下： 1int close(int fd); fd：是要关闭的文件描述符。 close() 函数会关闭指定的文件描述符，使该文件描述符不再可用，同时释放与该文件描述符相关的资源，如文件表项和文件描述符表中的条目。关闭文件是一项重要的操作，它有助于避免资源泄漏和确保文件在不再需要时不会继续占用系统资源。 当我们打开一个文件： 先进行 open() 系统调用，从磁盘中读取目标文件的 inode 信息，并存储在系统范围的打开文件表内。 当前进程内的打开文件表新增一个指向系统范围内打开文件表的索引（或指针），并通过 open() 函数返回给程序（在 Unix / Linux 中称为 File descriptor，在 Windows 中称为 File handle）。 当我们关闭一个文件： 释放进程表项（Per-process table entry）。 当前存储在此文件的内存缓存（Memory cache）中的任何数据都将在必要时写入磁盘。 文件的共享 一个文件可以被多个用户 / 进程访问，如果同一时间多个用户或进程以只读方式打开文件，那该过程可以正常执行，但如果多个用户或进程同时读写就可能引发冲突。 因此 OS 中引入了锁（Lock）： 文件锁技术是一种用于控制对文件的并发访问的机制。它允许多个进程或线程协调共享对文件的访问，以防止竞争条件和数据损坏。文件锁通常用于多进程或多线程环境中，其中多个实体需要访问相同的文件。 有两种主要类型的文件锁：共享锁（Shared Lock）和独占锁（Exclusive Lock）。这些锁可以在文件上的不同部分或整个文件上设置。 共享锁（Shared Lock）： 多个进程可以同时持有共享锁。 共享锁允许多个进程同时读取文件，但阻止其他进程获得独占锁。 共享锁通常用于并发读取操作，以防止竞争条件。 独占锁（Exclusive Lock）： 仅一个进程可以持有独占锁。 独占锁阻止其他进程获得任何类型的锁，共享锁和独占锁都被阻止。 独占锁通常用于写入和修改文件的操作，以确保数据的一致性。 例如，用户 A 在读取文件时每个进程都持有共享锁，其他进程无法对文件内容进行修改，只能以只读方式打开文件。 文件索引与文件信息 Unix/Linux Inode 在 Unix 和 Linux 文件系统中，\"inode\"（索引节点）是一个关键的数据结构，用于管理和存储文件的元数据信息。每个文件和目录都有一个唯一的 inode，用于跟踪文件的属性、权限、所在位置等等，我们可以认为一个文件的 inode 主要维护了以下两类信息： 元数据（Metadata） 数据块地址（Which disk blocks belong to which file） 元数据在上文中已经介绍，包括文件的一些基本信息，数据块地址则是文件实际内容的存储地址。 我们可以使用 stat 指令查看文件包括 inode 在内的各种详细信息： 1stat filename 示例： Inode 存储在什么地方？ 在早期的 UNIX 系统中，它们被存储在磁盘。 Inode 不在数据块附近存储。要读一个小文件，先查找索引节点，再查找回数据。（Poor performance） 如果外部磁盘损坏，意味着文件系统会丢失。（Poor reliability） 在后来的系统中，索引节点分布在磁盘块组中，更接近数据块本身。 文件链接 文件链接允许我们创建一个文件的副本，即一份文件有两份不同名的实例，文件链接有以下两种： 软链接（Symbolic (soft) links） 保存原文件的路径，类似于 Windows 中的快捷方式。 1ln -s original link 硬链接（Hard links） 链接文件与原文件拥有同样的 Inode 编号，但需要注意的是目录是无法创建硬链接的。 1ln original link 如上图，(a) 表示文件初始状态；(b) 表示创建了一个硬链接，此时文件的硬链接数变为 2；(c) 表示文件原来所属用户将文件删除，此时文件的硬链接数变为 1。 Unix 目录 目录（Directory）是一种特殊的文件，其包含： 文件名列表（A list of filenames） 指向 Inode 的指针（Pointers to inodes） We are used to thinking about a directory containing files. This is really an illusion. Directories do not contain files. The data of the files is not stored in the directory. A directory is really just a file. It's a special file with special rules (you can't just type cp /dev/null directory to erase it. It's got special bits to make sure a mere mortal can't mess it up. Because if a file system gets corrupted, then you can say goodbye to your data. On older UNIX systems, you actually could \"read\" the contents, using cat . , of a directory. But let me get back to that in a second... A Unix file is \"stored\" in two different parts of the disk - the data blocks and the inodes. (I won't get into superblocks and other esoteric information.) The data blocks contain the \"contents\" of the file. The information about the file is stored elsewhere - in the inode. Above all, the directory is just a table that contains the filenames in the directory, and the matching inode. 文件分配 连续分配 连续文件分配（Contiguous File Allocation）即所有文件在存储空间内是连续存储的，在文件分配表中所有文件只需要两个值来维护： 起始位置（Start address） 数据大小（Length） 这种分配方式在 CD 和 DVD 中常用。 这样的分配方式的优点就是易于实现，缺点也很明显，就是数据块之间存在许多未分配的小空间，这里我们称为外部碎片（External fragmentation），另一个就是其不能完全满足文件大小动态增长的需求，例如文件过大则可能超过预先分区的大小。 链式分配 链式分配（Linked Allocation）是一种文件存储分配方式。在链式分配中，文件中的数据块不是连续分配的，而是通过链表来链接。每个数据块都包含一个指向下一个数据块的指针，创建一个链表结构，使文件的数据块按照其实际分配的顺序链接在一起。 FAT FAT（File Allocation Table）是一种经典的文件系统结构，通常用于存储媒体，如硬盘驱动器、闪存驱动器和其他可移动存储设备。 在 FAT 文件系统中，每个文件都由一系列链接在一起的簇来表示。文件的起始簇被存储在文件的目录项中，而接下来的簇号在 FAT 表格中找到。这样，文件的数据块通过 FAT 表格中的指针链起来，形成一个链表结构。 在 FAT 中，未被使用的数据块也会被放在一个链表中，称为 FAT free-list。 因此当我们格式化磁盘后，会发生以下两件事： 清空所有数据块的信息 将所有数据块链接为 free-list 优点：易于实现 缺点：对于大型文件而言，FAT 访问需要跳转许多数据块，可能造成过大的时间开销 Bitmap 操作系统需要管理未分配区域（Free space），除了上文提及的 FAT 中的 free-list 之外，还有另外一个常见的解决方案，就是使用 Bitmap。 Bitmap 是一个数组，其维护了每个数据块是否被使用，如果该数据块被使用了，则为 1，否则为 0。 优点： 对任意一种存储方式都适用 只需要很小的存储空间 常用文件系统 Unix / Linux EXT 2/3/4 EXT（Extended File System）广泛用于 Linux 和 Unix 操作系统家族，特别是在 Linux 系统中。它有多个版本，其中 EXT2、EXT3、和 EXT4 是最常见的。 ZFS ZFS（Zettabyte File System）是一种先进的、先进的文件系统和存储管理系统，最初由 Sun Microsystems（现在是 Oracle Corporation 的一部分）开发。 Apple HFS+ HFS+（Hierarchical File System Plus）最初由 Apple Inc. 开发并用于 Macintosh 计算机。它是 HFS（Hierarchical File System）的升级版本，引入了许多改进和新特性。 Microsoft FAT 16/32 主要在 MS-DOS 和 Windows XP 中使用。 NTFS NTFS（New Technology File System）是一种现代的文件系统，最初由 Microsoft 开发并引入到 Windows NT 操作系统中。 exFAT exFAT（Extended File Allocation Table）由 Microsoft 于 2006 年引入，旨在解决一些早期文件系统（如 FAT 32）存在的限制和问题。exFAT 主要设计用于存储在可移动存储介质（如闪存驱动器、SD 卡、外部硬盘等）上的大容量文件，尤其是用于跨平台数据交换。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"mysql-connector 学习笔记","slug":"mysql-connector 学习笔记","date":"2023-10-04T10:04:35.000Z","updated":"2023-10-04T13:13:29.294Z","comments":true,"path":"2023/10/04/mysql-connector 学习笔记/","link":"","permalink":"http://example.com/2023/10/04/mysql-connector%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"简介 mysql-connector 是一个用于 Python 编程语言的 MySQL 数据库连接库，它允许开发人员连接到 MySQL 数据库并执行各种数据库操作，如查询、插入、更新和删除数据。 安装 1pip install mysql-connector 使用 创建数据库连接 我们先在本地创建一个名为 demo 的数据库： 12345678mysql -u root -p# 以 root 登陆 mysql 客户端create table demo;# 创建数据库show databases;# 如果显示有 demo，则表示创建成功 创建成功后，我们就可以使用 mysql-connector 连接到数据库了。 123456789101112131415import mysql.connectordef main(): try: demo_connection = mysql.connector.connect( host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, passwd=&#x27;xxxxx&#x27;, # Your password database=&#x27;demo&#x27; # 指定具体的数据库，也可以不加 ) except mysql.connector.Error as err: print(&#x27;Connection Error!&#x27;, err)if __name__ == &#x27;__main__&#x27;: main() 操作数据库 连接成功后我们就可以操作本地数据库了。为了操作数据库，我们需要创建一个 「Cursor」 对象。 Cursor 是一个重要的对象，它用于执行 SQL 查询和操作数据库。 创建 Cursor 对象： 在使用 mysql-connector 连接到 MySQL 数据库后，首先需要创建一个 cursor 对象。通常，可以使用 connection.cursor() 方法来创建一个新的 cursor 对象，其中 connection 是数据库连接的实例。 1my_cursor = demo_connection.cursor() 执行 SQL 语句： 通过 cursor 对象，可以执行各种 SQL 查询。要执行查询，可以使用 cursor.execute(sql_query) 方法，其中 sql_query 是包含 SQL 语句的字符串。 假设 demo 数据库中有表格 stuff(s_id, s_name, gender, salary, dept_id) 123my_cursor.execute(&#x27;select * from stuff&#x27;)my_cursor.execute(&#x27;insert into stuff values(%s, %s, %s, %s, %s)&#x27;, (2023100, &#x27;Frank&#x27;, &#x27;男&#x27;, 40000, 3)) 注：如果要一次性向表格插入多个数据，execute() 方法的第二个参数可以接收一个包含了多个元组的列表。 获取查询结果： 一旦执行了查询，可以使用不同的方法来获取查询结果。例如，可以使用 cursor.fetchone() 获取一行记录，或者使用 cursor.fetchall() 获取所有匹配的记录。 12345# 获取一行记录row = my_cursor.fetchone()# 获取所有匹配的记录rows = my_cursor.fetchall() 提交事务： 在执行写操作（如 INSERT、UPDATE 或 DELETE ）后，通常需要提交事务以确保更改生效。可以使用 connection.commit() 方法来提交事务。 12# 提交事务demo_connection.commit() 关闭 Cursor 和连接： 使用完 cursor 和数据库连接后，应该关闭它们以释放资源。 12345# 关闭 Cursormy_cursor.close()# 关闭连接demo_connection.close()","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"数据库系统","slug":"数据库系统","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"}]},{"title":"Servlet 学习笔记","slug":"Servlet 学习笔记","date":"2023-10-03T05:46:39.000Z","updated":"2023-12-13T06:02:12.356Z","comments":true,"path":"2023/10/03/Servlet 学习笔记/","link":"","permalink":"http://example.com/2023/10/03/Servlet%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Servlet 简介 Servlet 是 Java EE（Java Platform, Enterprise Edition）中的一种 Java 程序组件，用于处理 Web 应用程序中的 HTTP 请求和响应。Servlet 通常运行在 Web 服务器或 Servlet 容器中，并提供了一种有效的方式来创建动态的 Web 内容。 Servlets were Java’s answer to CGI (Common Gateway Interface), and programs that run on web server acting as middle layer between HTTP request and databases or other applications. MVC 模型 MVC（Model-View-Controller）是一种软件架构模式，用于组织和分离应用程序的不同组成部分，以提高应用程序的可维护性、可扩展性和可重用性。MVC模型将应用程序分为三个主要组件，每个组件都有不同的责任。 Java classes/beans —— The business logic (Model) JSP —— The presentation logic (View) Servlet —— Handling the HTTP protocol and coordination (Controller) 模型（Model）： 模型代表应用程序的数据和业务逻辑。 模型负责处理数据的获取、存储、验证和操作，以确保数据的完整性和一致性。 模型通常不直接与用户界面交互，而是通过控制器来处理数据的请求和响应。 视图（View）： 视图负责呈现数据给用户，并负责用户界面的显示。 视图通常不包含应用程序的业务逻辑，它只负责显示数据和接收用户输入。 视图可以是图形用户界面（GUI）、Web 页面、命令行界面或其他任何用户界面形式。 控制器（Controller）： 控制器充当模型和视图之间的中介，它接收来自用户界面的用户输入。 控制器负责解释用户输入，并相应地调用模型的方法来执行业务逻辑。 控制器还可以更新视图以反映模型的状态变化。 Servlet 优点 高效性（Efficient，lower overhead） Servlet 在 JVM 上运行，每一个请求都使用线程而不是开启一个新的进程。 便利（Convenient） 提供解析和解码 HTML 表单的基础设施。 功能强大（Powerful） 可以直接和 Web Server 连接； 多个 Servlet 可以共享数据库链接。 跨平台（Portable） 使用 Java 编写，可移植性强。 Tomcat Apache Tomcat（通常称为Tomcat）是一个开源的 Servlet 容器，用于实现和管理 Java Servlet 和 JSP。它是 Apache 软件基金会的一个项目，作为一个轻量级的 Web 服务器，被广泛用于运行 Java Web 应用程序。 目录结构： Servlet 生命周期 Servlet 生命周期可被定义为从创建直到毁灭的整个过程。以下是 Servlet 遵循的过程： Servlet 初始化后调用 init() 方法。 注：init() 方法不等同于构造方法，构造方法只会创建一个对象，只有调用完 init() 方法后对象才是一个合格的 Servlet。 Servlet 调用 service() 方法来处理客户端的请求。 Servlet 销毁前调用 destroy() 方法。 第一个 Servlet 实例 通过 IDEA 构建一个 Jakarta EE 项目，创建一个简单的 Servlet 实例： 123456789101112131415161718192021222324252627282930package com.example.Servlet_demo;@WebServlet(name = &quot;helloServlet&quot;, value = &quot;/hello-servlet&quot;)public class HelloServlet extends HttpServlet &#123; private String message; public void init() &#123; message = &quot;Hello World!&quot;; &#125; @Override public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; super.service(req, res); System.out.println(&quot;Hello World!&quot;); &#125; public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; response.setContentType(&quot;text/html&quot;); // Hello PrintWriter out = response.getWriter(); out.println(&quot;&lt;html&gt;&lt;body&gt;&quot;); out.println(&quot;&lt;h1&gt;&quot; + message + &quot;&lt;/h1&gt;&quot;); out.println(&quot;&lt;/body&gt;&lt;/html&gt;&quot;); &#125; public void destroy() &#123; System.out.println(&quot;Servlet is destroyed&quot;); &#125;&#125; 配置 web.xml 文件： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;https://jakarta.ee/xml/ns/jakartaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;https://jakarta.ee/xml/ns/jakartaee https://jakarta.ee/xml/ns/jakartaee/web-app_5_0.xsd&quot; version=&quot;5.0&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.example.servlet_demo.HelloServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/HelloServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Servlet 中的部署描述符（Deployment Descriptor，DD）是一个 XML 文件，通常命名为 web.xml，用于配置和管理 Web 应用程序中的 Servlet 组件。Deployment Descriptor 提供了一种在 Servlet 容器中配置 Servlet 和其他 Web 应用程序组件的方式，这样 Web 服务器可以正确地加载和运行这些组件。 以下是一些常用的 web.xml 配置标签及其功能： &lt;web-app&gt; ：web.xml 文件的根元素，用于定义整个 Web 应用程序的配置。它包含各种子元素，如 &lt;servlet&gt;、&lt;servlet-mapping&gt;、&lt;filter&gt;、&lt;filter-mapping&gt; 等，用于配置 Servlet、Filter、Listener 等。 123456&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;!-- 配置其他元素 --&gt;&lt;/web-app&gt; &lt;servlet&gt; ：用于配置 Servlet，指定 Servlet 类名、Servlet 名称等信息。 1234&lt;servlet&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.example.MyServlet&lt;/servlet-class&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; ：将 Servlet 映射到 URL 模式，指定哪些 URL 请求将由哪个 Servlet 处理。 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/Myservlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; &lt;filter&gt;：用于配置过滤器（Filter），允许对请求和响应进行处理。过滤器通常用于执行预处理、日志记录、身份验证等任务。 1234&lt;filter&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.example.MyFilter&lt;/filter-class&gt;&lt;/filter&gt; &lt;filter-mapping&gt;：将过滤器映射到 URL 模式，指定哪些请求将由哪个过滤器处理。 1234&lt;filter-mapping&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/myfilter&lt;/url-pattern&gt;&lt;/filter-mapping&gt; &lt;listener&gt;：配置监听器（Listener），用于监听 Web 应用程序的生命周期事件，如启动和销毁。 123&lt;listener&gt; &lt;listener-class&gt;com.example.MyListener&lt;/listener-class&gt;&lt;/listener&gt; &lt;init-param&gt; ：用于为特定的 Servlet 提供初始化参数。这些初始化参数可以在 Servlet 的初始化阶段读取，以配置和自定义 Servlet 的行为。通常情况下，&lt;init-param&gt; 标签是放在 &lt;servlet&gt; 标签内的，用于为特定的 Servlet 配置参数。以下是有关 &lt;init-param&gt; 的详细信息： 123456789101112&lt;servlet&gt; &lt;servlet-name&gt;MyServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.example.MyServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;param1&lt;/param-name&gt; &lt;param-value&gt;value1&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;param2&lt;/param-name&gt; &lt;param-value&gt;value2&lt;/param-value&gt; &lt;/init-param&gt;&lt;/servlet&gt; 上述示例中，我们在 &lt;servlet&gt; 标签内定义了两个 &lt;init-param&gt; 子元素，每个 &lt;init-param&gt; 都包含一个 &lt;param-name&gt; 和一个 &lt;param-value&gt;。这些元素的含义如下： &lt;param-name&gt;：用于指定初始化参数的名称。这是一个字符串，用于标识参数。 &lt;param-value&gt;：用于指定初始化参数的值。这是实际的参数值，可以是字符串、数字或其他合适的数据类型。 在 Servlet 类中，您可以通过 getInitParameter(String paramName) 方法来获取这些初始化参数的值。例如： 1234567891011121314public class MyServlet extends HttpServlet &#123; public void init(ServletConfig config) throws ServletException &#123; super.init(config); // 获取初始化参数 String param1 = getInitParameter(&quot;param1&quot;); String param2 = getInitParameter(&quot;param2&quot;); // 使用参数值进行初始化 // ... &#125; // 其他 Servlet 方法&#125; 通过这种方式，您可以在部署描述符中为 Servlet 配置一些参数，以在 Servlet 初始化时使用这些参数进行定制。这对于在不同环境中部署同一个 Servlet 并根据需要进行不同的配置非常有用。 index.jsp 文件： 12345678910111213&lt;%@ page contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;JSP - Hello World&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;&lt;%= &quot;Hello World!&quot; %&gt;&lt;/h1&gt;&lt;br/&gt;&lt;a href=&quot;hello-servlet&quot;&gt;Hello Servlet&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; JSP (JavaServer Pages) 是一种基于 Java 的技术，用于创建动态的、数据驱动的网页。JSP 允许开发者直接在 HTML 页面中嵌入 Java 代码，这使得动态生成的内容可以轻松地与静态的 HTML 内容结合起来。 基于 HTML：JSP 页面看起来很像普通的 HTML 页面。实际上，你可以直接将一个 HTML 文件的扩展名从 .html 更改为 .jsp，它仍然可以正常工作。但是，这只是 JSP 最基本的用法。 动态内容：与纯 HTML 页面只能展示固定内容不同，JSP 允许开发者在 HTML 中嵌入 Java 代码片段。这些代码片段在页面请求时执行，并动态生成内容。在 JSP 中，可以使用特殊的标签（如 &lt;%= ... %&gt;）来插入动态内容。例如，&lt;%= new Date() %&gt; 会在页面上显示当前的日期和时间。 JSP 标签库：除了基本的 Java 代码，JSP 还支持自定义标签库，如 JSTL (JavaServer Pages Standard Tag Library)。这些标签库提供了一组可在 JSP 页面中使用的预定义功能，从而避免了直接嵌入复杂的 Java 代码。 生命周期：当请求一个 JSP 页面时，它首先被转换为一个 Java Servlet，然后由 Servlet 容器（如 Apache Tomcat）编译和执行。这意味着，虽然 JSP 允许你以更声明性的方式编写动态网页，但在幕后，它实际上是一个完整的 Java Servlet。 在生成的 HTML 网页中点击超链接 \"Hello Servlet\" ，即调用 HelloServlet 的 doGet() 方法，在页面打印 \"Hello World!\"，同时每次刷新页面都会调用 service() 方法，在控制台窗口打印 \"Hello World!\"。 执行原理： 当服务器接收到客户浏览器的请求后，会解析请求 URL 路径，获取访问的 Servlet 的资源路径 查找 web.xml 文件，查找是否存在 &lt;url-pattern&gt; 标签体内容 如果有，则在找到对应的 &lt;servlet-class&gt; 全类名 Tomcat 会将类的字节码文件加载进内存，并且创建其对象 调用对应方法 Servlet 基本方法详解 生命周期 init() init() 方法是 Servlet 生命周期中的一个非常重要的方法。它主要用于执行只需要在 Servlet 启动时进行一次的初始化操作。这意味着，在 Servlet 的整个生命周期中，init() 方法只会被调用一次。 定义： 1void init(ServletConfig config) throws ServletException; 方法参数： ServletConfig ：此对象包含 Servlet 的初始化参数，这些参数在部署描述符（通常是 web.xml 文件）中定义。你可以使用这个对象来获取 Servlet 的名称、初始化参数等。现如今在定义 init() 方法的时候已经可以不需要带该参数了，不带参数的 init() 方法内部会通过 getServletConfig() 方法获取到 ServletConfig 对象，所以你仍然可以在这个方法内访问 Servlet 的配置信息。 123456@Overridepublic void init() throws ServletException &#123; // 初始化代码 String configFile = getServletConfig().getInitParameter(&quot;configFile&quot;); loadConfig(configFile);&#125; service() service() 方法是 Servlet 生命周期中的一个核心方法，负责处理来自客户端的请求并返回响应。 定义： 1void service(ServletRequest req, ServletResponse res) throws ServletException, IOException; 方法参数： req ：代表客户端发送给服务器的请求信息。这个对象提供了读取输入流、获取参数、查询头信息等方法。 res ：代表服务器发送回客户端的响应信息。这个对象提供了设置响应内容、设置响应状态、设置响应头等方法。 service() 方法根据请求的类型（如 GET、POST、PUT、DELETE 等）将请求分派到相应的处理方法，如 doGet(), doPost(), doPut(), doDelete() 等。 例如，当一个 HTTP GET 请求到达时，service() 方法会调用 doGet() 方法进行处理。同样地，对于 HTTP POST 请求，service() 会调用 doPost() 方法。 通常，你不需要直接重写 service() 方法。相反，你应该重写 doGet() ， doPost() ，doPut() ，doDelete() 等方法来处理特定类型的请求。 1234567891011@Overrideprotected void service(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException &#123; // 在所有请求前执行的逻辑 // ... // 调用父类的 service 方法以确保请求被分派到 doGet(), doPost() 等方法 super.service(req, res); // 在所有请求后执行的逻辑 // ...&#125; doGet(HttpServletRequest request, HttpServletResponse response) ： 该方法用于处理 HTTP GET 请求。 它通常用于获取资源或执行只读操作，不应该对服务器状态进行更改。 通过request对象获取请求参数、头信息等，并通过 response 对象生成响应内容发送给客户端。 doPost(HttpServletRequest request, HttpServletResponse response) ： 该方法用于处理HTTP POST请求。 POST 请求通常用于提交数据，例如表单数据，用于对服务器状态进行更改。 通过 request 对象获取请求参数、头信息等，并通过 response 对象生成响应内容发送给客户端。 doPut(HttpServletRequest request, HttpServletResponse response) ： 该方法用于处理 HTTP PUT 请求。 PUT 请求通常用于更新或替换指定的资源，客户端通常会提供完整的资源表示。 通过request对象获取请求参数、头信息等，并通过 response 对象生成响应内容发送给客户端。 doDelete(HttpServletRequest request, HttpServletResponse response) ： 该方法用于处理 HTTP DELETE 请求。 DELETE 请求通常用于删除指定的资源。 通过 request 对象获取请求参数、头信息等，并通过 response 对象生成响应内容发送给客户端。 destroy() destroy() 方法是 Servlet 生命周期中的最后一个方法，它在 Servlet 的生命周期结束时被调用，通常用于释放资源、执行清理操作或执行其他与终止相关的任务。 定义： 1void destroy(); 当 Servlet 容器（例如 Tomcat）决定从服务中移除一个 Servlet 实例时，它首先会调用该 Servlet 的 destroy() 方法。此时，Servlet 可以释放它所持有的资源，如数据库连接、线程、文件句柄等，并确保所有的清理工作都已完成。 12345@Overridepublic void destroy() &#123; // 清理代码 // 例如：关闭数据库连接、释放资源等&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Servlet","slug":"Servlet","permalink":"http://example.com/tags/Servlet/"}]},{"title":"进程管理","slug":"进程管理","date":"2023-09-24T05:13:21.000Z","updated":"2023-12-31T04:03:22.882Z","comments":true,"path":"2023/09/24/进程管理/","link":"","permalink":"http://example.com/2023/09/24/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"","text":"进程 早期的计算机一次只能执行一个程序（如 MS-DOS），这种程序完全控制系统，并且访问所有系统资源。 相比之下，现代计算机系统允许加在多个程序到内存，以便并发执行。这种改进要求：对各种程序提供更严格的控制和划分。这些需求导致了进程（Process）概念的产生，即进程为执行程序。进程是现代分时操作系统的工作单元。 进程概念 一个进程就是一个运行程序的实例，其由以下两个部分组成： 当前状态（Current state） 内存信息（Memory contents） 程序计数器（Program counter） 堆栈指针（Stack / Heap pointers） ... 系统资源（System resources） 我们强调：程序本身不是进程。程序只是被动（passive）实体，进程是活动（active）实体。 当一个可执行文件（executable file）被加载到内存时，这个程序就成为进程。 进程状态 二状态模型 &amp; 排队模型 在任何时刻，一个进程要么在执行中，要么未执行，因此我们可以简单将线程构建为最简单的两个状态： 执行中（Running） 未执行（Not running） Enter 即产生新的进程，进入队列。 Dispatch Dispatch 在这里是调度器的意思，即进行进程切换，处理器将处理新的进程。 Pause 当前运行的进程被中断，操作系统的调度器将选择一个新的进程运行。 这里中断的原因有很多，最常见的原因就是超过了操作系统的指令周期。 假设操作系统为了避免任何一个进程独占处理器时间，仅允许一个进程最多连续执行 6 个指令周期： 若进程 A 有 12 条指令，且刚刚出队列进入运行状态，则其执行完前 6 条指令后则会超时而重新入队，同时处理器切换到下一个进程。进程 A 在下一次出队后执行完接下来的 6 条指令后结束，然后退出该系统。 Exit 即进程结束退出系统。 二状态模型具有很大的漏洞，即如果存在一些处于运行状态但已经就绪等待执行的进程，同时还存在一些阻塞状态例如等待 I/O 结束的进程，又由于该模型使用单队列，因此无法区分出未被阻塞的进程从而在阻塞状态的进程上浪费大量处理器资源。具体来说就是若进程 A 处于 I/O 阻塞状态，则在需要的 I/O 结束之前进程 A 会一直参与到进程排队的循环中，既浪费了处理器的工作时间，也增加了其他正常可执行的进程的排队时间。 五状态模型 为了解决以上二状态模型的问题，又提出了五状态模型： 新的（New） New 状态用于存储那些暂时不能进入 Ready 队列的进程，一方面可能是资源问题，另一方面可能是优先级问题。 运行（Running） 阻塞（Blocked） 就绪（Ready） 退出（Exit） 五状态模型在二状态模型的基础上新增了阻塞态，可以理解为用于存放等待 I/O 的阻塞态进程的队列。 当相关的 I/O 发生后，处于阻塞态的进程将会进入就绪态。 五状态模型依然存在潜在的问题。对于一般的计算机而言，处理器远快于 I/O，会出现内存中所有进程都在等待 I/O 的现象，此时处理器多数时间处于空闲状态，且需要大量的空间来维护处于阻塞状态的进程。 被挂起的进程 为了解决以上问题，操作系统会将部分进程挂起（Suspend），即把内存内存中某个进程的一部分或者全部移动到磁盘中。 当内存中不存在就绪态的进程时，操作系统就会把被阻塞的进程换出到磁盘的挂起队列（Suspend queue），即临时从内存中移除的进程队列。操作系统从此要么从挂起队列中取出一个进程，要么接受一个新的进程，将其放在内存中运行。 特别说明： Blocked \\(\\to\\) Blocked/Suspend 若没有就绪进程，则至少换出一个阻塞进程，以便为另外一个未阻塞进程腾出空间。 Blocked/Suspend \\(\\to\\) Ready/Suspend 若等待的时间发生 I/O，则处于 阻塞/挂起 状态的进程可以转化到 就绪/挂起 状态。 Ready/Suspend \\(\\to\\) Ready 若内存没有就绪态进程，则操作系统需要调入一个进程来执行。处于 就绪/挂起 状态的进程与处于就绪状态的进程相比优先级更高。 Ready \\(\\to\\) Ready/Suspend 通常，操作系统更倾向于挂起阻塞态进程而非就绪态进程，因为就绪态进程可以立即执行，而阻塞态进程虽然占用了空间却不能执行。若释放内存来得到足够空间的唯一方式是挂起一个就绪态进程，则这种转化是必须的。 操作系统的控制结构： 操作系统为了管理进程和资源，必须掌握每个进程和资源的当前状态。 普遍采用的方法是：OS 构造并维护其管理的每个实体的信息表。我们称其为 OS control table，如下图。 内存表（Memory table） 用于跟踪内存和外存。 I/O 表（I/O table） 管理计算机的 I/O 设备和通道。 文件表（files table） 用于提供文件信息。 进程表（Process table） 用于管理计算机进程。 进程控制块（PCB） 操作系统在管理和控制进程时，首先要知道进程的位置，其次要知道进程的属性（如 PID，进程状态等）。 为了维护进程的这些值，我们采用进程控制块（Process Control Block, PCB），它包括许多与某个特定进程相关的消息： 进程状态（Process state） 程序计数器（Program counter，PC） 计数器表示进程将要执行的下个指令的地址。这里可以理解为 8086 CPU 中的 CS 和 IP 寄存器指向的地址。 CPU 寄存器（CPU register） 包括累加器、索引寄存器、堆栈指针、通用寄存器、条件码寄存器等等。 CPU 调度信息（CPU-sheduling information） 这类信息包括进程优先级、调度队列的指针和其他参数。 内存管理信息（Memory-management information） 根据操作系统使用的内存系统，这类信息可以包括基地址和界限寄存器的值、页表或段表。 记账信息（Accounting information） 这类信息包括 CPU 时间、实际使用时间、时间期限、记账数据、作业或进程数量等。 I/O 状态信息（I/O status information） 这类信息包括分配给进程的 I/O 设备列表、打开文件列表等等。 Linux 操作系统的进程控制块采用 C 语言结构体 task_struct 来表示，它位于内核源码目录内的头文件 &lt;linux/sched.h&gt; 内。 linux/sched.h 内核源码 进程控制 执行模式 大多数处理器至少支持两种执行模式。某些指令只能在特权模式下运行，包括读取或改变诸如程序状态字之类的控制寄存器的指令、原始 I/O 指令和与内存管理相关的指令。另外，部分内存区域仅能在特权模式下访问。 非特权模式通常称为用户模式（User mode），特权模式通常称为内核模式（Kernel mode），后者也常常被称为系统模式（System mode）或者控制模式（Control mode），内核模式指的是操作系统的内核，它是操作系统中包含重要系统功能的部分。 使用两种模式的原因是保护操作系统和重要的操作系统表（如 PCB）不受用户程序的干扰。在内核模式下，软件会完全控制处理器及其所有指令、寄存器和内存。为了安全起见，这种级别的控制对用户程序而言没有必要。 在给出两种模式后，我们就遇到了两个问题： 处理器如何区分当前的进程是以什么模式来运行的？ 我们通常在程序状态字中设定几个指示执行模式的位。 当用户调用一个操作系统服务或中断来触发系统例程的执行时，执行模式被置为内核模式；而当从系统服务返回到用户进程时，执行模式将被置为用户模式。 例如 64 位 IA-64 体系的 Intel Itanium 处理器中，就有一个包含 2 位 CPL（Current Privilege Level）字段的处理器状态寄存器（PSR）。级别 0 表示内核模式，是最高特权级别，其他级别（1 ~ 3）则是用户模式。 模式如何转变？ User \\(\\to\\) Kernel 开启内核模式，并存储当前的用户 PC 指针。 Kernel \\(\\to\\) User 清空内核模式，将 PC 指针指向合适的用户进程。 进程创建 ☁️ 操作系统创建一个新进程时，会按照如下步骤操作： 为新进程创建一个唯一标识符 为进程分配空间 初始化 PCB 设置正确的链接 若操作系统将每个调度队列都维护为一个链表，则新进程必须放在就绪或者 就绪/挂起 链表中。 创建或扩充其他数据结构 例如为每个进程维护一个记账文件。 进程切换 基于此，我们可以得到进程切换的一般过程： 存储当前进程的 PC、SP 指针与寄存器等（统称 Context） 更新当前进程的 PCB 将当前进程移动到等待队列（具体状态视情况而定） 从进程队列中选取一个新的进程来执行，从其 PCB 中读取信息 ... 何时切换进程？进程切换可能在操作系统从当前正在运行进程中获得控制权的任何时刻发生。 由于进程切换需要内核模式的权限，所以进程切换的过程中一般都会发生执行模式的改变。 其一般有 3 种原因： 中断（Interrupt） 与当前正运行进程无关的某种外部事件相关，如： 时钟中断（Timer interrupt） 当前进程运行时间已经达到最大允许时间段（Time slice）。若超时，进程就切换到就绪态，并调入另一个进程。 I/O 中断（I/O interrupt） 操作系统确定是否已发生 I/O 活动。若 I/O 活动是一个或多个进程进程正在等待的事件，则操作系统就会把所有处于阻塞态的进程转化为就绪态，此时操作系统必须决定是继续执行当前处于运行态的进程还是让优先级更高的就绪态进程抢占该进程。 陷阱（Trap） 与当前正在运行的进程相关，一般指当前进程出现错误或者异常条件时发生的进程切换。 此时，操作系统会判断该进程的错误或异常条件是否致命，致命时会直接进入退出态，并切换进程；若不致命，操作系统的动作取决于错误的性质和操作系统本身的设计。 Trap 有很多例子，比如常见的 Segmentation fault（段错误）、Divide by zero Exception（除 0 异常）等等。 系统调用（System call） 类似于函数调用，不过在当前进程之外。例如，当用户执行了一个 I/O 操作的指令，如打开一个文件，这时该调用会转移到操作系统代码一部分的一个例程。使用系统调用会将用户进程置为阻塞态。 Linux 常见系统调用的 C 语言接口： fork() ： 创建一个新的子进程，该子进程是当前进程的复制。子进程和父进程将在不同的地址空间中运行，但它们会共享相同的代码和文件描述符。用于创建新进程。 wait() 和 waitpid() ： 用于等待子进程的终止，并获取子进程的终止状态。这些函数通常与 fork() 配合使用，用于处理子进程的退出状态。 exec() 系列函数（如 execve() 、execl() 、execp() 等）： 用于加载并执行新的程序。这些函数会替代当前进程的映像，将其替换为一个新的程序。exec() 函数允许传递参数、环境变量和命令行参数给新程序。 open() 和 close() ： 用于打开和关闭文件。open() 函数用于打开文件，并返回文件描述符，close() 函数用于关闭文件。 read() 和 write() ： 用于从文件描述符读取数据和将数据写入文件描述符。它们是输入和输出的基本系统调用。 进程调度 知道了进程的工作模式，OS 就需要采取合适的策略进行进程调度（Process scheduling）。进程调度有以下目标： 响应时间（Response time）：降低任务的响应时间，以满足实时要求或减少用户感知的等待时间。低延迟对于需要快速响应的应用程序非常重要。 高吞吐量（High Throughput）：确保系统可以同时运行多个任务，并且能够高效地处理大量的工作负载。这对于服务器和数据中心等高负载环境至关重要。保证处理器在一定的时间内可以尽可能处理更多任务。 资源利用率（Resource Utilization）：最大化系统资源的利用率，以确保资源得到有效利用，同时避免浪费。这包括处理器时间、内存、I/O 设备等资源的有效管理。 避免进程饥饿（Process starvation）：不要出现某个进程长时间等待而没有执行。 公平性（Fairness）：确保每个进程都有平等的机会获得处理器时间和其他系统资源。 批处理进程和交互式进程 批处理进程（Batch processes，CPU-intensive） 批处理进程通常用于执行大量相似的、非交互性的任务，这些任务按照一定的顺序依次执行，而不需要用户的交互或实时响应。 对于批处理进程而言，吞吐量（Throughput）最重要。 交互式进程（Interactive processes，I/O-intensive） 交互式进程是需要与用户进行实时交互的进程。它们等待用户的输入并立即做出响应，通常以图形用户界面（GUI）或命令行界面的形式展示给用户。 对于交互式进程而言，响应时间（Response time）最重要。 绝大多数进程的 CPU 峰值时间都很短（Short CPU burst）。 FCFS 策略 先来先服务（First-Come-First-Served）策略，顾名思义就是让进程按照排队的策略进行调度。 FCFS 策略十分容易实现，只需要维护一个就绪进程的队列结构，让每个新进程入队，将要执行的进程出队即可。 优点： 易于实现； 当所有进程耗时差不多时 FCFS 策略的效果会很好。 缺点： 一些短进程可能需要长时间的等待，可能造成进程饥饿。 SJF 策略 SJF 策略即最短作业优先策略（Shortest-Job-First）策略，在 SJF 策略中，操作系统会选择等待队列中最短的作业（最短的执行时间）来执行，以期望最小化平均等待时间，提高系统的性能。 非抢占性策略和抢占性策略 非抢占性策略（Non-Preemptive Scheduling）： 特点：在非抢占性策略中，一旦一个进程开始执行，它将一直运行，直到完成。其他进程无法强制中断正在执行的进程，除非当前进程主动放弃 CPU（Voluntarily gives up the CPU），例如等待 I/O 操作完成。 优点：非抢占性策略通常比抢占性策略具有较低的上下文切换开销，因为不需要频繁地切换执行的进程。 适用性：这种策略适用于不需要实时性要求的场景，如批处理系统或一些传统的桌面应用程序。它也可以简化并发编程，因为无需处理抢占和竞争条件。 以上讨论的 FCSF、SJF 调度策略都属于非抢占性策略。 抢占性策略（Preemptive Scheduling）： 特点：在抢占性策略中，操作系统可以强制中断当前正在执行的进程，并将 CPU 分配给其他等待的进程。这种策略允许更灵活地管理进程，根据进程的优先级、时间片或其他条件来决定进程的执行。 优点：抢占性策略可以提高系统的响应性，因为操作系统可以在需要时迅速切换到更高优先级的进程，以满足实时性要求或更紧急的任务。 适用性：抢占性策略通常适用于需要实时性、响应性和更精细的调度控制的场景，如操作系统内核、服务器应用、多媒体处理和实时系统。 RR 策略 轮转调度（Round Robin，RR）是一种抢占性的进程调度策略。在 RR 调度中，操作系统将 CPU 时间分成固定大小的时间片（也称为时间量或量子），然后按照先来先服务（FCFS）的顺序将这些时间片分配给就绪队列中的进程。每个进程在一个时间片内运行，然后如果它还没有完成，就被移到队列的末尾等待下一个时间片。 RR 调度比 FCFS 更加公平，特别是对于时间差别较大的进程。 时间片的选择： 选择一个合适长度的时间片对于 RR 策略而言至关重要，太长或者太短都不合适。 太长： 响应性差（Poor responsiveness）。 太短： 过于频繁的上下文切换（Overhead of context switching）可能造成较大的时间开销。 备用队列（Auxiliary queue）： 用于存放那些从 I/O 阻塞状态释放的进程； 相对于那些在就绪队列中的进程而言拥有更高的优先级。 优先级调度策略 优先级调度策略（Scheduling with Priorities）根据进程的优先级来决定下一个执行的进程。具有较高优先级的进程先执行。这可以用于根据进程的重要性和紧迫性来调度。其会给每个进程设定一个优先级（Priority value），调度器总是先选择优先级更高的进程来运行。 优先级可分为静态和动态两种，对于动态优先级而言，OS 可以动态调整进程的优先级。 实现方式：对于不同优先级的进程，使用不同的队列来维护。 如下图，RQ0 级别的队列优先级最高，然后随着编号增加，优先级递减。则每次处理器会先从优先级高的队列选择进程运行。 多级反馈队列 多级反馈队列（Multi-Level Feedback Queue，MLFQ）特别是用于多任务处理系统。MLFQ 结合了多个队列和反馈机制，以实现灵活的进程调度，同时考虑了进程的优先级、等待时间和历史执行表现。 MLFQ 包含多个队列，每个队列具有不同的优先级。通常，系统会维护一个队列数组，其中队列的优先级逐渐降低。高优先级队列中的进程在低优先级队列中的进程之前执行。在每个队列中，通常会使用一种基本的调度策略，如先来先服务（FCFS）或轮转调度（Round Robin）。不同队列可以使用不同的基本调度策略。 反馈机制： MLFQ 使用反馈机制来动态调整进程的优先级。 如果一个进程在高优先级队列中等待了一段时间但没有完成，它将被移到较低优先级的队列中，从而允许其他进程有机会获得 CPU 时间。 如果一个进程在低优先级队列中等待了很长时间而没有被执行，系统可能会提高其优先级。这是为了防止饥饿现象，即确保所有进程最终都能获得处理器时间。 解决饥饿问题： MLFQ 调度中如果频繁有新的进程进入系统，可能导致优先级低的进程频繁被抢占，从而造成进程饥饿问题。 这个问题有很多解决方案，比如对于不同的优先级的队列，我们设置不同的抢占时间。 例如，对于 \\(RQ_i\\) 队列，我们将抢占时间设定为 \\(2 ^ i\\)，从而给低优先级队列的进程更多执行时间。 抢占时间（Preemption time）是指一个进程在被操作系统抢占（即中断并停止执行）之前能够持续执行的时间长度。这个概念在抢占式进程调度策略中非常重要，因为它决定了操作系统何时可以选择停止当前正在执行的进程，以分配 CPU 时间给其他等待的进程。 进程优先级在 Unix/Linux 操作系统的具体体现 —— Niceness 在 Unix 和类 Unix 操作系统中，Niceness（也称为 Nice 值）是一个用于表示进程优先级的概念。Niceness 值通常在 -20 到 19 之间，默认是 0，其中 -20 表示最高优先级，19 表示最低优先级。更负的 Niceness 值表示更高的优先级，而更正的 Niceness 值表示更低的优先级。 我们可以使用 ps 指令打印进程信息，从而看到进程的 Nice 值。 ps aux：显示所有用户的详细进程列表。 ps aux | grep &lt;进程名&gt;：通过管道和grep命令来筛选特定进程。 ps -e：显示所有进程，包括系统进程。 ps -ef：以全格式显示所有进程。 ps -u &lt;用户名&gt; : 查看某个用户的进程。 CFS CFS（Completely Fair Scheduler）是 Linux 操作系统中的一种进程调度算法，用于在多任务环境中公平地分配 CPU 时间给不同的进程。CFS 的目标是实现公平的 CPU 时间分配，确保每个进程在一定时间内获得相同比例的 CPU 时间，而不受其他进程的干扰。 底层实现原理 —— 红黑树。 Ubuntu 实操 其实也不一定得是 Ubuntu，其他类 Unix 系统如 MacOS，本身就可以完成以下实验。 使用 Python 的 os 模块实现部分 System call Python 的 os 模块提供了标准 UNIX 库接口与不少 POSIX 系统调用，如 fork() ，exec() 系列函数等等。 fork() fork() 函数用于创建一个新进程。fork() 函数不接收任何参数，当 fork() 被调用后，其会复制一份相同的进程，对于两个相同的进程，fork() 函数返回不同的值，对于当前进程，返回子进程的 pid，对于子进程，会返回 0。 示例： 123456789101112import osdef main(): pid = os.fork() if pid == 0: print(&quot;Child process&quot;) else: print(f&quot;Father process, child pid = &#123;pid&#125;&quot;)if __name__ == &#x27;__main__&#x27;: main() 运行结果： 12Father process, child pid = 37012Child process waitpid() os.waitpid() 是 Python 中用于等待子进程结束的函数之一，它允许你在父进程中等待指定的子进程完成执行。这个函数通常与 os.fork() 一起使用，以管理子进程的执行。 1os.waitpid(pid, options) pid ：要等待的子进程的进程 ID（Process ID）； options：控制等待行为的选项标志，有以下取值： os.WNOHANG：如果没有子进程退出，立即返回，不会阻塞。 os.WUNTRACED：如果子进程进入暂停状态（例如，收到了 SIGTSTP 信号），也会返回。 0，表示在子进程结束前，父进程始终是阻塞状态。 os.waitpid() 的返回值是一个包含两个值的元组 (pid, status)，其中： pid 是已经退出的子进程的进程 ID。 status 包含有关子进程退出状态的信息，可以使用 os.WIFEXITED(status)、os.WEXITSTATUS(status)、os.WIFSIGNALED(status)、os.WTERMSIG(status) 等函数来提取这些信息。 示例： 12345678910111213import osdef main(): pid = os.fork() if pid == 0: print(&quot;Child process&quot;) else: os.waitpid(pid, 0) # 等待子进程完成 print(f&quot;Father process, child pid = &#123;pid&#125;&quot;)if __name__ == &#x27;__main__&#x27;: main() 输出： 12Child processFather process, child pid = 37267","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程","slug":"进程","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"进程管理","slug":"进程管理","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"Linux Shell 学习笔记","slug":"Linux Shell 学习笔记","date":"2023-09-21T10:02:30.000Z","updated":"2024-01-12T16:37:30.015Z","comments":true,"path":"2023/09/21/Linux Shell 学习笔记/","link":"","permalink":"http://example.com/2023/09/21/Linux%20Shell%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"文件管理 ls 命令 ls 来自英文单词中的 \"list\" 的缩写，用于列出目录中文件以及其属性信息。 1ls [参数] [文件名] 常用参数： 参数 解释 -a 显示所有文件及目录 -A 在 -a 的基础上不显示当前目录和父目录 -d 显示目录本身的属性信息 -i 显示文件的 inode 属性 -l 显示文件的详细属性信息，包括类型、权限等 -m 以逗号为间隔符，水平显示文件信息 -r 依据首字母将文件以相反次序显示 -R 递归显示所有子文件 -S 依据内容大小将文件排序显示 -t 依据最后修改时间将文件排序显示 -X 依据拓展名将文件排序显示 --color 显示信息带有着色效果 不添加任何参数的情况下，ls 命令会列出当前工作目录的文件信息。 cp 命令 cp 命令来自英文单词中 \"copy\" 的缩写，用于复制文件或目录。 1cp [参数] 源文件名 目标文件名/复制目录 常用参数： 参数 解释 -b 覆盖目标文件前先进行备份 -d 复制链接文件时，将目标文件也建立成链接文件 -f 若目标文件已存在，则会直接覆盖 -i 若目标文件已存在，则会询问是否覆盖 -l 对源文件建立硬链接，而非复制文件 -p 保留源文件或者目录的所有基本属性 -r 递归复制所有子文件 -s 对源文件建立软链接，而非复制文件 -a 功能等同于 -d -p -r -v 显示执行过程详细信息 示例： 在同一目录下复制 demo.txt 的副本： 1cp demo.txt demo_copy.txt 将 demo.txt 复制到 ./demo_dict 目录，如果目标文件存在则覆盖： 1cp -f demo.txt ./demo_dict 建立 dmeo.txt 的软链接： 1cp -s demo.txt demo_soft_link mkdir 命令 mkdir 命令来自于英文 \"Make directories\" 的缩写，用于创建目录文件。 1mkdir [参数] 目录名 常用参数： 参数 解释 -m 创建目录的同时设置权限 -p 递归创建多级目录 -v 显示执行过程详细信息 -z 设置目录安全上下文 示例： 创建一个权限为 740 的文件： 1mkdir -m 740 dir_test 123ls -ld dir_test# 输出结果：drwxr-----@ 2 username staff 64 9 29 23:20 dir_test 一次创建多个嵌套关系的目录： 1mkdir -p dir1/dir2/dir3 mv 指令 mv 指令，来自于英文单词中的 \"move\"，用于移动或者更改文件名。 1mv [参数] 源文件名 目标文件名 常用参数： 参数 解释 -b 覆盖前为目标文件创建备份 -f 若文件已存在，强制覆盖目标文件 -i 若文件已存在，则询问用户是否覆盖 -n 不要覆盖已有文件 -u 当源文件比目标文件更新时，才执行覆盖操作 -v 显示执行过程详细信息 -Z 设置文件安全上下文 示例： 将 demo.txt 改名为 demo2.txt ： 1mv demo.txt demo2.txt 将 dir1 移动到 dir2 ： 1mv dir1 ./dir2 在 (1) 的基础上将 dir1 重命名为 dir0 1mv dir1 ./dir2/dir0 pwd 指令 pwd 指令来自于英文中的 \"Print working directory\" 的缩写，用于显示当前工作目录的路径。 1pwd [参数] 常用参数： 参数 解释 -L 显示逻辑路径（默认） -P 显示实际物理地址 tar 指令 tar 指令用于压缩和解压文件，能解压或压缩 Linux 系统中常见的 .tar 、.tar.gz 、tar.bz2 等格式的压缩包文件。 1tar 参数 压缩包名 [文件或目录名] 常用参数： 参数 说明 -A 添加文件到已存在压缩包 -B 设置区块大小 -c 创建新的压缩包 -C 解压缩到指定目录 -d 记录文件的差别 -f 指定压缩包文件 -j 使用 bzip2 压缩格式 -l 设置文件系统边界 -m 保护文件不被覆盖 -N 只将较新日期的文件保存到压缩包中 -p 保留原来的文件权限和属性 -t 显示压缩包的内容 -u 更新压缩包内的文件 -v 显示执行过程详细信息 -w 确认压缩包的完整性 -x 从压缩包内提取文件 -z 使用 gzip 压缩格式 --exclude 排除指定的文件不压缩 --remove-files 操作完后删除源文件 示例： 使用 gzip 压缩格式将 demo 目录打包，压缩包后缀指定为 .tar ： 1tar -czvf demo.tar ./demo 将 demo.tar 解压到当前工作目录： 1tar -xvf demo.tar 查看压缩包 demo.tar 内到文件信息： 1tar -tvf demo.tar chmod 命令 chmod ，来自英文缩写 \"change mode\"，用于更改文件权限。 1chmod [参数] 权限 文件名 常用参数： 参数 解释 -c 改变文件权限成功后再输出成功信息 -f 改变文件权限失败后不显示错误信息 -R 递归处理所有子文件 权限： 权限可以用数字表示，例如 755，表示 rwxr-xr-x 权限，也可以使用 + 和 - 进行权限追加。 文件所属者、群组用户和外部用户分别用 u 、g 、o 表示； 读、写、执行的权限分别用 r 、w 、x 表示。 示例： 将 demo.txt 的权限设置为 755： 1chmod 755 demo.txt 给所有用户增加读 demo.txt 的权限： 1chmod +r demo.txt 剥夺外部用户写 demo.txt 的权限： 1chmod o-w demo.txt 文档编辑 cat 命令 cat 命令来自于英文中 \"concatenate files and print\" 的缩写，用于在终端设备上显示文件内容。 1cat [参数] 文件名 常用参数： 参数 解释 -b 显示行数 -E 每行结束时以 $ 结尾 -n 显示行数，空行也编号 -s 显示行数，多个空行算一个编号 more 命令 more 是一个用于在 Linux Shell 中分页显示文本文件内容的命令行工具，它允许用户逐页查看文件。 1more [参数] 文件名 使用方法： 按空格键：向下滚动一页。 按 Enter 键：向下滚动一行。 按 q 键：退出 more，返回到 Shell 提示符。 按 / 键：进行文本搜索，然后输入要搜索的文本并按 Enter 键。 按 n 键：查找下一个匹配的搜索结果。 按 p 键：查找上一个匹配的搜索结果。 参数： 参数 解释 -l 显示进程名和 PID -d 显示文件名和当前行号 -c 清屏后显示内容 -f 忽略控制字符 -s 合并多个空行为一个空行 echo 命令 echo 在英文中译为回声，用于在终端输出字符串或提取后的变量值。 1echo [参数] 字符串或$&#123;变量名&#125; 常用参数： 参数 解释 -E 禁止转义字符 -e 启动转义字符的解释 -n 不输出结尾的换行符 示例： 打印两行话到终端： 1echo -e &quot;Hello\\nWorld!&quot; 打印环境变量 PATH ： 1echo $&#123;PATH&#125; 显示当前系统的运行时间和当前系统负载的信息： 1echo $(uptime) rm 命令 rm 命令来自英文单词 \"remove\" 的缩写，用来删除文件或目录。 1rm [参数] 文件名 常用参数： 参数 解释 -d 删除无子文件的空目录 -f 强制删除文件不询问 -i 删除文件前询问用户是否删除 -r 递归删除目录及其全部子文件 -v 显示执行过程详细信息 示例： 强制删除当前工作目录下所有 .txt 后缀的文件： 1rm -f *.txt 强制删除目录 dir 以及其所有子文件： 1rm -rf dir grep 命令 grep 命令来自英文 \"Global search regular expression and print out the line\" 的缩写，是一个强大的文本搜索工具。 1grep [参数] 文件名 常用参数： 参数 解释 -b 显示匹配行距文件头部的偏移量 -c 只显示匹配的行数 -E 支持拓展正则表达式 -F 匹配固定字符串的内容 -h 搜索多文件时不显示文件名 -i 忽略关键词大小写 -l 只显示符合匹配条件的文件名 -n 显示所有匹配行及其行号 -o 显示匹配词距文件头部的偏移量 -q 静默执行模式 -r 递归搜索模式 -s 不显示没有匹配文本的错误信息 -v 显示不包括匹配文本的所有行 -w 精准匹配整词 -x 精准匹配整行 示例： 查找文件 OS.md 中所有包含 process 的行，并且显示其行号： 1grep -n process OS.md 搜索当前工作目录中包含关键词 Java 的文件： 1grep -lrs Java * tail 命令 顾名思义，tail 命令用于查看文件尾部内容。 1tail [参数] 文件名 常用参数： 参数 解释 -c 设置显示文件尾部的字符数 -f 持续显示文件尾部的最新内容 -n 设置显示文件尾部的行数 示例： 显示 demo.txt 最后 15 行： 1tail -n 15 demo.txt 显示 demo.txt 最后 20 个字符： 1tail -c 20 demo.txt rmdir 命令 rmdir 命令来自于英文中的 \"Remove directory\" 的缩写，用于删除空目录文件。 1rmdir [参数] 目录名 常用参数： 参数 解释 -p 递归处理所有子文件 -v 显示执行过程详细信息 系统管理 find 命令 find 命令的功能是用于根据给定的路径和条件查找相关文件或目录，参数灵活方便，且支持正则表达式。 1find [路径] [条件] 文件名 常用参数： 参数 解释 -name 匹配文件名 -perm 匹配文件权限 -user 匹配文件所属主 -group 匹配文件所属组 -mtime 匹配最后修改文件内容的时间 -atime 匹配最后读取文件内容的时间 -ctime 匹配最后修改文件属性的时间 -type 匹配文件类型 -size 匹配文件大小 -exec ... &#123;&#125; \\ 进一步执行语句 示例： 查找当前目录下所有 zip 压缩包： 1find ./ -name *.zip 查找当前目录下 demo_dir 文件夹下所有大于 1M 的文件： 1find ./demo_dir -size +1M 查找工作目录最近 3 天被修改过的文件并且打印其长格式： 1find ./ -mtime +3 -exec ls -l &#123;&#125; \\; ps 命令 ps 命令是 \"process\" 的缩写，用于显示进程信息。 1ps [参数] 如果 ps 不添加任何参数，则会显示当前 Shell 的进程。 常用参数： 参数 解释 -a 显示当前终端会话的所有进程 -x 显示没有控制终端的进程 -e 显示系统所有进程 -f 显示详细的进程信息 -l 以长格式显示进程信息 aux 也是显示系统所有进程，但输出格式更加详细 -u 显示与指定用户标识符（UID）相关的进程 -d 显示指定用户正在运行的进程 -p 显示特定 PID 的进程 -o 自定义输出进程格式 -t 显示在特定终端运行的进程 -H 显示进程的层次结构，包括父进程和子进程 示例： 显示系统所有进程，展示其 PID 和控制终端： 1ps -eo pid,tty 显示 PID 为 100 的进程信息： 1ps -p 100 pstree 命令 pstree 命令是一个用于显示进程树的实用程序。它以一种层次结构的方式展示正在运行的进程，显示进程之间的父子关系。 1pstree [参数] 常用参数： 参数 解释 -u 显示与指定用户标识符（UID）相关的进程 -p 显示特定 PID 的进程 -h 以水平格式显示进程树 pgrep 命令 pgrep 命令来自英文词组 \"process global regular expression print\" 的缩写，其功能是用于检索进程 PID 号码。pgrep 命令通过正则表达式进行检索，因此用户只需要输入服务名称中的一部分即可进行搜索操作，对于不记得全名的服务程序特别好用。 1pgrep [参数] 服务器名 常用参数： 参数 解释 -f 匹配进程名 -g 匹配进程组 ID -u 匹配有效用户 ID -t 匹配终端号 -c 显示进程数量 kill 命令 kill 命令用于向单个进程发送一个信号，以请求其终止。 1kill [参数] PID 常用参数： 参数 解释 -a 不限制命令行与进程号的对应关系 -l 显示系统支持的信号列表 -p 不发送任何信号 -s 设置向进程发送的信号 pkill 命令 pkill 命令用于根据进程名或其他进程属性来终止进程。它可以一次终止多个匹配的进程。 1pkill [参数] 进程名称 常用参数： 参数 解释 -c 匹配进程 ID -g 匹配进程组 -u 匹配用户 ID -n 匹配最近生成的进程 -o 匹配最早生成的进程 top 命令 top 是一个非常常用的命令行工具，用于实时监视和显示正在运行的进程的系统性能信息。它在类 Unix 系统（如Linux、MacOS）上非常有用，可以让用户实时查看 CPU 使用率、内存利用率、进程列表和其他系统性能指标。 1top 操作： 使用键盘上的箭头键可以在进程列表中滚动。 按下 q 键可退出 top。 按下 k 键可终止选定的进程。 按下 F 键可调整排序顺序或显示的字段。 按下 h 键可查看帮助和快捷键列表。 一般情况下，top 显示的信息包括： 进程ID（PID）：每个进程的唯一标识符。 用户（USER）：运行该进程的用户。 调度优先级（PR）：表示进程的调度优先级（Priority）。 Niceness（NI）：表示进程的 Niceness 值。 虚拟内存使用量（VIRT）：VIRT 表示进程的虚拟内存（Virtual Memory）使用量 物理占用内存（RES）：RES 表示进程的实际物理内存占用（Resident Set Size），也就是实际分配给进程并存储在物理内存中的内存量。 共享内存大小（SHR）：SHR 表示进程共享的内存大小（Shared Memory），也就是多个进程之间共享的内存量。这包括进程使用的共享库和共享的内存段。 状态（S）：进程的状态（如运行、休眠、停止等）。 CPU% （CPU%）：进程占用的CPU百分比。 内存% （MEM%）：进程占用的内存百分比。 累计时间（TIME+）：TIME+ 列表示自进程启动以来的累积 CPU 时间。这个值以小时、分钟和秒的格式表示，显示了进程占用 CPU 的时间量。 命令 （COMMAND）：启动进程的命令行。 uname 命令 uname 命令来自英文中的 \"Unix name\"，用于查看系统主机名、内核及硬件架构等信息。 1uname [参数] 常用参数： 参数 说明 -s 显示内核名称（默认） -a 显示系统所有相关信息 -i 显示硬件平台 -m 显示计算机硬件架构 -n 显示主机名称 -o 显示操作系统名称 -p 显示主机处理器类型 -r 显示内核发行版本号 -v 显示内核版本 磁盘管理 df 命令 df 命令是 \"Report file system disk space usage\" 的缩写，用于显示磁盘空间的使用情况。 1df [参数] 磁盘分区 常用参数： 参数 解释 -a 显示所有文件系统 -h 以更易读的方式显示 -H 以 1 KB = 1000 Byte 为换算单位 -i 显示索引字节信息 -k 设置显示时块的大小 -l 只显示本地文件系统 示例： 以容量单位显示系统全部磁盘的使用量情况： 1df -h 指定具体分区： 1df -h /boot 网络通讯 ssh 命令 ssh 命令可以让我们轻松地基于 SSH 加密协议进行远程主机访问，从而实现对远程服务器的管理工‍作。 1ssh [参数] 域名|IP 常用参数： 参数 解释 -1 使用 SSH 协议版本 1 -2 使用 SSH 协议版本 2 -4 基于 IPv4 网络协议 -6 基于 IPv6 网络协议 -l 设置登录用户名 -f 后台执行 SSH 命令 -p 设置远程服务器的端口号 示例： 基于 SSH 指令访问远程主机： 1ssh 192.168.10.10 制定登录用户： 1ssh -l linuxprobe 192.168.10.10 netstat 命令 netstat 命令来自英文词组 “Network statistics” 的缩写，其功能是显示各种网络相关信息，例如网络连接状态、路由表信息、接口状态、NAT、多播成员等。 1netstat [参数] 常用参数： 参数 解释 -a 显示所有连接中的接口信息 -c 持续显示网络状态 -C 显示路由配置信息 -F 显示路由缓存信息 -n 直接使用 IP 地址 -p 显示正在使用接口的程序识别码和名称 -r 显示路由表信息 -i 显示网络界面信息表单 -t 显示 TCP 传输协议的连接状态 -u 显示 UDP 传输协议的连接状态 示例： 显示网络所有连接信息： 1netstat -a 显示系统网络状态中的 UDP 连接信息： 1netstat -nu 显示网卡当前状态： 1netstat -i 常用工具 bc 命令 bc 是一个用于进行任意精度计算的命令行计算器。它的名称是 \"Basic Calculator\" 的缩写，它允许你进行大数运算，包括整数和浮点数，而不受标准计算器或编程语言中固定精度的限制。bc 是一个非常强大的工具，特别适用于需要高精度计算的数学任务。 bc 支持的运算如下： 基本算术运算： 加法：+ 减法：- 乘法：* 除法：/ 模运算：% 幂运算：^ 自增运算：++ 自减运算：-- 逻辑运算： 逻辑非（取反）：! 逻辑与：&amp;&amp; 逻辑或：|| 比较运算： 等于：== 不等于：!= 大于：&gt; 小于：&lt; 大于等于：&gt;= 小于等于：&lt;= 数学函数： bc 支持许多数学函数，包括但不限于以下几种： 平方根：sqrt(x) 指数函数：e(x) 自然对数：l(x) 正弦函数：s(x) 余弦函数：c(x) 正切函数：a(x) 对数函数：l(x) 阶乘函数：factorial(x) 取整函数：floor(x) 绝对值函数：abs(x) 四舍五入函数：scale(n) 控制结构： if 语句：if (condition) &#123; ... &#125; else &#123; ... &#125; for 循环：for (init; condition; update) &#123; ... &#125; while 循环：while (condition) &#123; ... &#125; 变量和函数： 定义变量：var_name = value 自定义函数：define function_name(parameters) &#123; ... &#125; 位运算： bc 也支持位运算，包括按位与、按位或、按位异或等位运算操作符。 管道表达式 在 Linux Shell 中，管道表达式是一种非常有用的工具，它允许将一个命令的输出直接传递给另一个命令的输入，以便进行数据处理和流水线操作。管道操作符是 |。 基本语法： 管道操作符 | 用于连接两个或多个命令。它的一般语法如下： 1command1 | command2 | command3 这将使 command1 的输出成为 command2 的输入，而 command2 的输出成为 command3 的输入，依此类推。 用途： 管道表达式在 Shell 中广泛用于以下情况： 数据筛选：通过将数据传递给 grep、awk 或 sed 等工具，可以筛选、搜索和处理文本数据。 数据排序：使用 sort 命令对数据进行排序。 数据计算：使用工具如 awk 和 bc 进行数学计算。 数据统计：使用 wc 命令进行行、单词和字符的统计。 数据转换：将数据从一种格式转换为另一种格式，例如将文本数据转换为 CSV 格式。 示例： 以下是一些使用管道表达式的示例： 使用 ls 列出当前目录的文件，然后使用 grep 过滤文件名中包含 \"txt\" 的文件名： 1ls | grep &quot;txt&quot; 统计一个文件中的行数、单词数和字符数： 1cat myfile.txt | wc 从一个文本文件中读取数据，然后使用 awk 对数据进行处理： 1cat data.txt | awk &#x27;&#123;print $2, $1&#125;&#x27; | sort 使用管道连接多个命令以完成一系列复杂的任务。 错误处理： 管道中的每个命令都运行在自己的子 Shell 中，因此如果其中一个命令失败，管道可能会终止。您可以使用 set -o pipefail 来使管道在任何命令失败时终止整个管道。 例如： 12set -o pipefailcommand1 | command2 | command3 这将确保如果 command1、command2 或 command3 中的任何一个失败，整个管道将失败。 管道表达式是 Linux Shell 中非常强大和有用的功能，它允许将多个命令组合在一起，以便以更有效的方式处理和操作数据。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://example.com/tags/shell/"}]},{"title":"表达式树","slug":"表达式树","date":"2023-09-18T01:23:12.000Z","updated":"2023-09-20T07:59:16.656Z","comments":true,"path":"2023/09/18/表达式树/","link":"","permalink":"http://example.com/2023/09/18/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%91/","excerpt":"","text":"三种表达式 在计算机做数值运算时，我们有三种常见的表达式，分别是中缀表达式、前缀表达式、后缀表达式。 中缀表达式 中缀表达式是我们通常在数学中使用的表达式表示方法，操作符位于两个操作数之间。例如，加法操作 3 + 4 通常表示为 \"3 + 4\"。中缀表达式具有运算符优先级规则，需要考虑括号来明确运算顺序。中缀表达式可以通过算法（如递归解析或运算符优先级解析器）转换为其他表达式形式，如前缀或后缀表达式。 示例： \\[ (a + b) \\times c \\] 前缀表达式 前缀表达式，也被称为波兰记法（Polish Notation）。在前缀表达式中，运算符位于操作数之前，例如，加法操作 3 + 4 可以表示为\"+ 3 4\"。前缀表达式没有优先级问题，因为每个运算符都在其操作数之前，而计算前缀表达式通常需要使用栈数据结构来执行。 示例： \\[ \\times +\\ a\\ b\\ c \\] 后缀表达式 后缀表达式，也被称为逆波兰记法（Reverse Polish Notation，RPN）。在后缀表达式中，运算符位于操作数之后，例如，加法操作 3 + 4 可以表示为\"3 4 +\"。后缀表达式也不涉及运算符优先级，因此计算顺序是十分明确的，计算后缀表达式通常使用栈数据结构来执行。 示例： \\[ a\\ b\\ + c\\ \\times \\] 表达式树 以上三种表达式都可以相互转化并且使用特定的方法求值，我们在此不做赘述，那么我们是否可以将三种表达式统一为某种适合计算机运算的数据结构呢？我们在此引入表达式树（Expression Tree）。 表达式树是一种数据结构，用于表示数学表达式的层次结构，其中每个节点表示操作数或运算符，而边表示它们之间的关系。表达式树可以用来表示前缀、中缀或后缀表达式，并提供了一种有效的方式来表示和计算复杂的数学表达式。 以 \\((a + b) \\times c\\) 为例，我们可以构造如下表达式树： 不难发现，表达式树有如下性质： 叶节点只能是操作数，非叶节点只能是运算符； 表达式树的非叶节点的度数只能是 2。 表达式 \\(\\to\\) 表达式树 在这里我们以后缀表达式为例，展示一下表达式树的构建过程。 事实上，我们只需要创建一个栈，然后从左至右遍历表达式并重复以下步骤即可： 如果遇到操作数，创建操作数节点，并压入栈内； 如果遇到运算符，创建运算符节点，从栈内弹出两个元素分别做运算符节点的右节点和左节点； ... 如此重复，最后栈内会剩下唯一的节点，该节点就是表达式树的根节点。 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;stack&gt;namespace __expression_tree &#123; enum node_type &#123; // 节点类型 OPEROTOR, NUMBER &#125;; struct ExpTreeNode &#123; node_type type; union &#123; char op; int val; &#125;; ExpTreeNode* left; ExpTreeNode* right; ExpTreeNode(node_type _type, int _val, ExpTreeNode* l = nullptr, ExpTreeNode* r = nullptr): type(_type), left(l), right(r) &#123; if (type == OPEROTOR) &#123; op = _val; &#125; else &#123; val = _val; &#125; &#125; &#125;; ExpTreeNode* suffix2tree(std::vector&lt;std::string&gt;&amp; ex) &#123; // 后缀表达式转化为表达式树 std::stack&lt;ExpTreeNode*&gt; st; for (const auto&amp; ele : ex) &#123; ExpTreeNode* rt = nullptr; if (ele == &quot;+&quot; || ele == &quot;-&quot; || ele == &quot;*&quot; || ele == &quot;/&quot;) &#123; ExpTreeNode* r = st.top(); st.pop(); ExpTreeNode* l = st.top(); st.pop(); rt = new ExpTreeNode(OPEROTOR, ele[0], l, r); &#125; else &#123; rt = new ExpTreeNode(NUMBER, stoi(ele)); &#125; st.push(rt); &#125; return st.top(); &#125; int compute(ExpTreeNode* root) &#123; // 计算以 root 为根节点的表达式树的值 if (root-&gt;type == NUMBER) return root-&gt;val; int l_val = compute(root-&gt;left), r_val = compute(root-&gt;right); switch (root-&gt;op) &#123; case &#x27;+&#x27;: return l_val + r_val; case &#x27;-&#x27;: return l_val - r_val; case &#x27;*&#x27;: return l_val * r_val; case &#x27;/&#x27;: return l_val / r_val; &#125; exit(1); // error &#125;&#125;using namespace __expression_tree;int main() &#123; std::vector&lt;std::string&gt; ex&#123;&quot;9&quot;, &quot;8&quot;, &quot;+&quot;, &quot;2&quot;, &quot;*&quot;, &quot;8&quot;, &quot;4&quot;, &quot;/&quot;, &quot;-&quot;&#125;; ExpTreeNode* rt = suffix2tree(ex); std::cout &lt;&lt; compute(rt) &lt;&lt; &#x27;\\n&#x27;; // (9 + 8) * 2 - 8 / 4 == 32 return 0;&#125; 如果是前缀表达式，则只需从右往左遍历表达式，然后采取相同的步骤即可（左右子树的顺序上会有差异）。 如果是中缀表达式，可以考虑使用递归构造表达式树，也可以先将前缀表达式转化为后缀表达式，然后再转化为表达式树。 表达式树 \\(\\to\\) 表达式 事实上，中缀表达式、前缀表达式、后缀表达式，本质上就是表达式树的中序遍历、前序遍历与后续遍历。 代码实现： 123456789101112131415161718192021222324std::string tree2prefix(ExpTreeNode* root) &#123; // 表达式树 -&gt; 前缀表达式 if (root-&gt;type == NUMBER) return std::to_string(root-&gt;val); return std::string(1, root-&gt;op) + &quot; &quot; + tree2prefix(root-&gt;left) + &quot; &quot; + tree2prefix(root-&gt;right);&#125;std::string tree2infix(ExpTreeNode* root, char pre_op = 0) &#123; // 表达式树 -&gt; 中缀表达式 if (root-&gt;type == NUMBER) return std::to_string(root-&gt;val); if ((root-&gt;op == &#x27;+&#x27; || root-&gt;op == &#x27;-&#x27;) &amp;&amp; (pre_op == &#x27;*&#x27; || pre_op == &#x27;/&#x27;)) &#123; return &quot;(&quot; + tree2infix(root-&gt;left, root-&gt;op) + &quot; &quot; + std::string(1, root-&gt;op) + &quot; &quot; + tree2infix(root-&gt;right, root-&gt;op) + &quot;)&quot;; &#125; return tree2infix(root-&gt;left, root-&gt;op) + &quot; &quot; + std::string(1, root-&gt;op) + &quot; &quot; + tree2infix(root-&gt;right, root-&gt;op);&#125;std::string tree2sufix(ExpTreeNode* root) &#123; // 表达式树 -&gt; 后缀表达式 if (root-&gt;type == NUMBER) return std::to_string(root-&gt;val); return tree2sufix(root-&gt;left) + &quot; &quot; + tree2sufix(root-&gt;right) + &quot; &quot; + std::string(1, root-&gt;op);&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"表达式树","slug":"表达式树","permalink":"http://example.com/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%91/"},{"name":"波兰记法","slug":"波兰记法","permalink":"http://example.com/tags/%E6%B3%A2%E5%85%B0%E8%AE%B0%E6%B3%95/"},{"name":"逆波兰记法","slug":"逆波兰记法","permalink":"http://example.com/tags/%E9%80%86%E6%B3%A2%E5%85%B0%E8%AE%B0%E6%B3%95/"}]},{"title":"线性神经网络","slug":"线性神经网络","date":"2023-09-12T11:41:25.000Z","updated":"2023-11-12T04:50:26.826Z","comments":true,"path":"2023/09/12/线性神经网络/","link":"","permalink":"http://example.com/2023/09/12/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"线性回归 回归（Regression）是能为一个或多个自变量与因变量之间的关系建模的方法。 而线性回归（Linear regression）则是基于自变量与因变量的关系是线性的假设： \\[ \\hat{y} = X w + b \\] 损失函数 \\[ L(w, b) = \\frac{1}{2 N} \\sum_{i} (x ^ {(i)} w + b - y ^ {(i)}) ^ 2 \\] 我们可以将参数 \\(b\\) 并入 \\(w\\) 中，则损失函数用向量可以表示为： \\[ L(w, b) = \\frac{1}{2 N} ||y - X w|| ^ 2 \\] 对损失函数求导，可以得到极小值点点解析解（Analytical solution）如下： \\[ w ^ * = (X ^ T X) ^ {-1} X ^ T y \\] 我们注意到，解析解不一定存在，因为按照上式，\\(X ^ T X\\) 满秩才存在逆矩阵。 随机梯度下降 每次迭代中，我们从所有样本随机抽取一个小批量集合 \\(B\\) ，进行如下迭代： \\[ w := w - \\frac{\\eta}{|B|} \\frac{\\partial}{\\partial w} \\sum_{i \\in B} l(w, x ^ {(i)}) \\] 生成数据集 我们设置一个符合正态分布且期望为 0 的噪声项 \\(\\epsilon\\) 来生成数据集： \\[ \\hat y = X w + b + \\epsilon \\] 1234567891011121314151617181920212223242526import torchimport matplotlib.pyplot as pltdef synthetic_data(w, b, num_examples): #@save X = torch.normal(0, 1, (num_examples, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 1, y.shape) return X, y.reshape((1, -1))def main(): w = torch.tensor([1.8]) b = torch.tensor([-0.5]) num_examples = 1000 X, y = synthetic_data(w, b, num_examples=num_examples) plt.scatter(X.flatten(), y.flatten(), s=10) plt.show() torch.save(X, &#x27;training dataset/X_data.pt&#x27;) torch.save(y, &#x27;training dataset/y_data.pt&#x27;)if __name__ == &#x27;__main__&#x27;: main() 训练模型 基于此，我们可以实现一个简单的线性回归神经网络： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import torchimport numpy as npclass LinearNN: def __init__(self, dim=1, mean=0, std=1): self.w = torch.normal(mean=mean, std=std, size=(dim, 1), requires_grad=True) self.b = torch.normal(mean=mean, std=std, size=(1, 1), requires_grad=True) def predict(self, X: torch.tensor) -&gt; torch.tensor: return torch.matmul(X, self.w) + self.b def loss(self, X: torch.tensor, y: torch.tensor) -&gt; torch.float64: return 0.5 * torch.sum((y - self.predict(X)) ** 2) / X.shape[0] def sgd(self, params, batch_size, lr): with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() def train(self, X: torch.tensor, y: torch.tensor, batch_size, num_epoches, lr=0.03): data_size = y.shape[0] iter_num = (data_size + batch_size - 1) // batch_size for epoch in range(num_epoches): for i in range(iter_num): batch_mask = np.random.choice(data_size, batch_size) l = self.loss(X[batch_mask, :], y[batch_mask, :]) l.backward() self.sgd([self.w, self.b], batch_size, lr) with torch.no_grad(): l = self.loss(X, y) print(f&#x27;epoch &#123;epoch + 1&#125; is over, loss = &#123;l&#125;&#x27;) print(f&#x27;w = &#123;self.w.data&#125;, b = &#123;self.b.data&#125;&#x27;)def main(): X = torch.load(&#x27;training dataset/X_data.pt&#x27;) y = torch.load(&#x27;training dataset/y_data.pt&#x27;).T model = LinearNN(dim=1) model.train(X, y, batch_size=100, num_epoches=200, lr=0.5) if __name__ == &#x27;__main__&#x27;: main() 终端输出： 最终 \\(w\\) 和 \\(b\\) 大约收敛于 1.8 和 -0.5，这与我们预设的参数是基本一致的，损失函数则收敛于 0.5，约等于 \\(\\frac{\\sigma ^ 2}{2}\\)，符合数学原理。 更简单的实现方式 123456789101112131415161718192021222324252627282930313233343536import torchimport numpy as npdef main(): net = torch.nn.Sequential(torch.nn.Linear(1, 1)) net[0].weight.data.normal_(0, 1) net[0].bias.data.normal_(0, 1) # 重写参数 loss = torch.nn.MSELoss() # 定义损失函数 trainer = torch.optim.SGD(net.parameters(), lr=0.5) # 定义优化算法，这里选择 SGD X = torch.load(&#x27;training dataset/X_data.pt&#x27;) y = torch.load(&#x27;training dataset/y_data.pt&#x27;).T num_epoches = 20 sz = X.shape[0] batch_size = 100 iter_num = (sz + batch_size - 1) // batch_size print(iter_num) for epoch in range(num_epoches): for i in range(iter_num): batch_mask = np.random.choice(sz, batch_size) l = loss(net(X[batch_mask, :]), y[batch_mask, :]) trainer.zero_grad() l.backward() # 反向传播 trainer.step() # 更新参数 print(f&#x27;epoch &#123;epoch + 1&#125; is over, loss = &#123;loss(net(X), y)&#125;&#x27;) w = net[0].weight.data b = net[0].bias.data print(f&#x27;w = &#123;w&#125;, b = &#123;b&#125;&#x27;)if __name__ == &#x27;__main__&#x27;: main() torch.nn.Sequential torch.nn.Sequential 是 PyTorch 中的一个容器模块，它允许你按顺序将一系列神经网络层组合在一起，以构建神经网络模型。Sequential 可以用于定义一个前馈神经网络，其中每个层的输出都成为下一层的输入。这使得创建和管理深度神经网络模型变得更加方便。 示例： 12345678910111213import torchfrom torch import nnmodel = nn.Sequential( nn.Linear(128, 64), # 输入层，输入维度为 128，输出维度为 64 nn.ReLU(), # ReLU 激活函数 nn.Linear(64, 32), # 隐藏层，输入维度为 64，输出维度为 32 nn.ReLU(), nn.Linear(32, 10) # 输出层，输入维度为 32，输出维度为 10)# 打印模型的结构print(model) Softmax 回归 Softmax 运算 线性神经网络输出为 \\(o\\)（多个输出），则 Softmax 运算可以描述如下： \\[ \\hat y = softmax(o) \\] 其中： \\[ \\hat y_i = \\frac{exp(o_i)}{\\sum_{k} exp(o_k)} \\] 一个简单的线性神经网络分类模型可以归纳如下： \\[ O = XW + b \\] \\[ \\hat Y = softmax(O) \\] 对于数据 \\(\\hat y\\) 而言，预测最可能类别是：\\(\\underset{i}{argmax\\ \\hat y_i}\\) 交叉熵损失 \\[ L(y, \\hat y) = -\\sum_{j} y_j log(\\hat y_j) \\] 基于线性 Softmax 回归的 PyTorch 实现 在这里我们以 MNIST 的手写数字为例，给出 Softmax 回归的代码实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from keras.datasets import mnistimport numpy as npimport torchfrom torch import nndef get_data(): (x_train, l_train), (x_test, l_test) = mnist.load_data() x_train = torch.from_numpy(x_train) x_test = torch.from_numpy(x_test) x_train = x_train / 255.0 x_test = x_test / 255.0 y_train = torch.zeros(size=(l_train.shape[0], 10)) for i in range(l_train.shape[0]): y_train[i, l_train[i]] = 1 y_test = torch.zeros(size=(l_test.shape[0], 10)) for i in range(l_test.shape[0]): y_test[i, l_test[i]] = 1 return (x_train, y_train), (x_test, y_test)def main(): dataset = &#123;&#125; (dataset[&#x27;x_train&#x27;], dataset[&#x27;y_train&#x27;]), (dataset[&#x27;x_test&#x27;], dataset[&#x27;y_test&#x27;]) = get_data() model = nn.Sequential( nn.Flatten(), nn.Linear(784, 10), nn.Softmax() ) with torch.no_grad(): model[1].weight.normal_(0, 0.01) model[1].bias.normal_(0, 0.01) trainer = torch.optim.SGD(model.parameters(), lr=0.25) loss = nn.CrossEntropyLoss() num_epoches = 1000 batch_size = 6000 sz = dataset[&#x27;x_train&#x27;].shape[0] sz_test = dataset[&#x27;x_test&#x27;].shape[0] iter_num = (sz + batch_size - 1) // batch_size for epoch in range(num_epoches): for i in range(iter_num): batch_mask = np.random.choice(sz, batch_size) l = loss(model(dataset[&#x27;x_train&#x27;][batch_mask]), dataset[&#x27;y_train&#x27;][batch_mask]) trainer.zero_grad() l.backward() trainer.step() with torch.no_grad(): print(f&#x27;epoch &#123;epoch + 1&#125; is over, loss = &#123;loss(model(dataset[&quot;x_test&quot;]), dataset[&quot;y_test&quot;])&#125;, &#x27;, end=&#x27;&#x27;) print(f&#x27;acc = &#123;torch.sum(torch.argmax(model(dataset[&quot;x_test&quot;]), dim=1) == torch.argmax(dataset[&quot;y_test&quot;], dim=1)) / sz_test&#125;&#x27;) torch.save(model.state_dict(), &#x27;./net/mnist_flatten_weights.pth&#x27;)if __name__ == &#x27;__main__&#x27;: main() 终端输出： 在使用 SGD 训练 1000 个 epoch 之后，识别正确率维持在 92% 左右。 线性分类器的可视化 在上述 MNIST 手写数字的例子中，输入层的 10 个神经元实际上就是 10 个线性分类器，即我们认为，若 \\(W_i x + b_i\\) （\\(i = 0、1、2、...、9\\)）在所有神经元的输出值中最大，则数字是 \\(i\\) 的可能性越大。 我们可以将每个神经元的参数二维展开来观察其具体形态： 12345678910import matplotlib.pyplot as plt# ...for i in range(10): img = (model[1].weight[i].reshape(28, 28) * 255).byte() plt.figure() plt.imshow(img, cmap=&#x27;gray&#x27;, interpolation=&#x27;nearest&#x27;) plt.colorbar() plt.savefig(&#x27;./img/&#x27; + str(i) + &#x27;.png&#x27;) 我们发现，训练后的神经网络的参数在可视化后竟然可以隐约看到数字的形状！尽管由于样本数量过多，可能在部分数字的参数可视化上会呈现出模糊化抽象化的特征，但在特征少的数字上我们依然可以明显看出来其代表的数字。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://example.com/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"}]},{"title":"Pandas 库学习笔记","slug":"Pandas 库学习笔记","date":"2023-09-07T16:19:56.000Z","updated":"2023-11-23T10:01:15.389Z","comments":true,"path":"2023/09/08/Pandas 库学习笔记/","link":"","permalink":"http://example.com/2023/09/08/Pandas%20%E5%BA%93%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"简介 pandas 是一个用于数据分析和处理的强大 Python 库。它提供了高性能、易于使用的数据结构和数据分析工具，使数据科学家、分析师和工程师能够更轻松地进行数据处理和探索性数据分析。以下是一些 pandas 库的主要特点和功能： 数据结构： Series：类似于一维数组的数据结构，是构建 DataFrame 的基本组成部分。 DataFrame：pandas 最重要的数据结构之一，它类似于表格或电子表格，可以包含多种数据类型的列。DataFrame 是处理和分析数据的主要工具，支持标签和位置索引。 数据导入和导出： 支持从多种数据源导入数据，包括 Excel、CSV、SQL 数据库、JSON 等。 可以将数据导出为各种格式的文件。 数据清洗和处理： 支持缺失数据的处理，包括填充、删除等。 提供强大的数据过滤、排序、切片和选择功能。 可以进行数据合并和连接，以及数据的重塑和透视操作。 数据分析和探索： 支持基本统计分析，如均值、中位数、标准差等。 提供强大的分组和聚合功能，可以进行分组统计。 可以进行时间序列数据分析和处理。 数据可视化： pandas 可以与其他数据可视化库（如 Matplotlib 和 Seaborn ）集成，用于创建各种图表和图形。 高性能： pandas 经过优化，可以处理大规模数据集，提供快速的数据操作和计算。 多级索引： 允许在 DataFrame 中创建多级索引，使数据的层次化表示更容易。 时间序列分析： pandas 具有强大的时间序列功能，支持日期和时间的操作、分组和重采样。 互动式数据分析： 在 Jupyter Notebook 等互动式环境中，pandas 非常适合用于数据探索和分析。 开源和社区支持： pandas 是一个开源项目，拥有庞大的社区支持，有大量文档、教程和示例可供学习和参考。 pandas 是数据科学工作流程中不可或缺的工具之一，可以帮助你加载、处理、分析和可视化数据，从而更好地理解数据并做出决策。无论是进行数据探索性分析、数据清洗、数据预处理还是建模，pandas 都是一个强大而灵活的工具。 重要数据结构 Series Series 类似于一维数组，但可以自定义索引，这方面又有些像 Python 中的字典。 示例： 12arr = pd.Series([1, 2, 3], index = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;])# 或者 arr = pd.Series(&#123;&#x27;one&#x27;: 1, &#x27;two&#x27;: 2, &#x27;three&#x27;: 3&#125;) 如果不定义 index ，就是默认的数组索引（0 ～ 数组长度 - 1） pandas 具有强大的数据对齐功能，具体体现在两个数据结构在相加时，可以将相同键值对应的值进行相加，Eg： 1234s1 = pd.Series(&#123;&#x27;高等数学&#x27;: 98, &#x27;大学物理&#x27;: 90, &#x27;C++&#x27;: 100&#125;)s2 = pd.Series(&#123;&#x27;高等数学&#x27;: 100, &#x27;大学物理&#x27;: 93, &#x27;C++&#x27;: 91&#125;)print((s1 + s2) / 2) 输出结果： 1234高等数学 99.0大学物理 91.5C++ 95.5dtype: float64 但是，如果两组数据中出现不同的标签，对于标签不相同的数据，运算后结果是 NaN ，此时可以使用 Pandas 自己提供的 add() 方法。 12print(s1.add(s2, fill_value = 0))# fill_value 表示缺省情况的默认值 除 add() 方法对应加法外，数学中的减、乘、除在 pandas 中也有对应的方法，分别是 sub()、mul() 和 div() 。 DataFrame DataFrame 是一个表格，有行和列两个维度，其中每一行或者每一列都是一个 Series 。 示例： 123456789101112import pandas as pdpd.set_option(&#x27;display.unicode.ambiguous_as_wide&#x27;, True)pd.set_option(&#x27;display.unicode.east_asian_width&#x27;, True)# 将中文对齐def main(): s = pd.DataFrame(&#123;&#x27;高等数学&#x27;: [100, 98], &#x27;大学物理&#x27;: [90, 93], &#x27;C++&#x27;: [100, 91]&#125;) print(s)if __name__ == &#x27;__main__&#x27;: main() 输出结果： 123 高等数学 大学物理 C++0 100 90 1001 98 93 91 一般来说一个 DataFrame 对象通过一个字典和 index 参数来设置： 123dat = &#123;&#x27;高等数学&#x27;: [100, 98], &#x27;大学物理&#x27;: [90, 93], &#x27;C++&#x27;: [100, 91]&#125;s = pd.DataFrame(data = dat, index = [&#x27;Carl&#x27;, &#x27;Tony&#x27;])print(s) 输出结果： 123 高等数学 大学物理 C++Carl 100 90 100Tony 98 93 91 导入、导出表格文件 很多情况下，我们需要读取表格文件，Pandas 提供了多种函数来读取和输出表格文件。 导入 导出 .csv 表格 read_csv(file_path) to_csv(file_path, index) Excel 文件 read_excel(file_path) to_excel(file_path, index) index 的值表示是否将最左侧的索引保存到文件中。 忽略无关数据 在读取表格的时候，有些行是无关紧要的，我们可以通过相关参数进行控制，比如我们忽略某个表格前 40 行，且只读取 40 行，可以考虑添加 skiprows 参数和 nrows 参数： 12# 读取 Excel 文件，跳过前 40 行，并且只读取接下来 40 行df = pd.read_excel(&#x27;data.xlsx&#x27;, skiprows = range(40), nrows = 40) 成功读取表格后，我们就可以进行对应的操作了。 假设我们成功读取工作目录下的表格 scores.csv ： 12345678910import pandas as pdpd.set_option(&#x27;display.unicode.ambiguous_as_wide&#x27;, True)pd.set_option(&#x27;display.unicode.east_asian_width&#x27;, True)def main(): sc = pd.read_csv(&#x27;./scores.csv&#x27;)if __name__ == &#x27;__main__&#x27;: main() 列操作 查看列 例如，我需要查看每个人的高数成绩： 1print(sc[&#x27;高等数学&#x27;]) 输出结果： 12340 1001 922 94Name: 高等数学, dtype: int64 修改列 直接采用赋值修改即可： 1sc[&#x27;大学物理&#x27;] = [96, 94, 99] 此时，三个人的大物成绩就分别修改成了 96、94、99。 新增列 比如现在我需要新增「数据结构」这门课，可以考虑以下方式： 12sc[&#x27;数据结构&#x27;] = [100, 90, 90]print(sc) 输出结果： 1234 姓名 高等数学 大学物理 C++ 数据结构0 Carl 100 93 91 1001 Jack 92 94 93 902 Jennie 94 98 89 90 删除列 删除列考虑使用 drop() 方法： 1sc.drop(&#x27;大学物理&#x27;, axis = 1, inplace = True) 这样，我们就成功删除了「大学物理」这一列，参数 axis 表示行或列，行为 0，列为 1，默认值为 0，inplace 参数表示删除后是否替换原表格还是只返回删除后的表格，默认值为 False 。 行操作 行是通过最左边的索引来获取的，再不指定的情况下，索引值默认从 0 开始依次递增，可以使用 loc 基于索引进行表格行的操作。 查看行 1print(sc.loc[0]) # 查看第一行学生的成绩 如果指定了表格的索引列，则通过相应的索引来查找行： 12sc = pd.read_csv(&#x27;./scores.csv&#x27;, index_col = &#x27;姓名&#x27;)print(sc.loc[&#x27;Carl&#x27;]) 运行结果： 12345性别 M高等数学 100大学物理 93C++ 91Name: Carl, dtype: object 除了第一个参数外，还支持第二个参数列名，同时基于行和列获取指定数据： 1print(sc.loc[&#x27;Carl&#x27;, &#x27;高等数学&#x27;]) # 100 注：loc 方法也支持切片和传入条件判断，但对于切片 l : r 而言左右都是闭区间。 修改行、新增行、删除行和列操作是类似的，故此处不加以赘述。 排序 考虑使用 sort_values() 方法，第一个参数表示排序所依靠的键值。在如下示例中，我们按照高等数学的成绩降序排列学生： 12sc.sort_values(&#x27;高等数学&#x27;, ascending = False, inplace = True)print(sc) 输出结果： 1234 姓名 高等数学 大学物理 C++0 Carl 100 93 912 Jennie 94 98 891 Jack 92 94 93 分组 分组是个很有用的功能，熟悉 SQL 语句的同学应该不会陌生，在 Pandas 库中的分组功能也是差不多的。例如，接下来我们需要统计以下表格中男女生高等数学和 C++ 的平均分： 1print(sc.groupby(&#x27;性别&#x27;)[[&#x27;高等数学&#x27;, &#x27;C++&#x27;]].mean()) 输出结果： 1234 高等数学 C++性别 F 94.0 89.0M 96.0 92.0 类似的和分组功能一同使用的函数还有：max() 、min() 、sum() 等。 筛选数据 与 Numpy 一样，可以传入筛选条件来返回所有符合条件的数据，例如查找所有 C++ 分数不少于 90 的同学： 1print(sc[sc[&#x27;C++&#x27;] &gt;= 90][&#x27;姓名&#x27;]) 输出结果： 1230 Carl1 JackName: 姓名, dtype: object 注：索引中条件的分隔符如下： 或：| 且：&amp; 数据标签 Pandas 提供了 cut() 方法用于给数据添加标签并分类。 例如： 1csc = pd.cut(sc[&#x27;高等数学&#x27;], bins = [0, 59, 79, 89, 100], labels = [&#x27;不及格&#x27;, &#x27;及格&#x27;, &#x27;良好&#x27;, &#x27;优秀&#x27;]) 第一个参数表示需要分类的键，第二个表示分类区间，默认为左开右闭，第三个参数表示每个区间对应的标签。 表格合并 纵向合并 1df = pd.concat([df_1, df_2, df_3]) 横向合并 1df = pd.merge(df_1, df_2)","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"数据科学","slug":"数据科学","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}]},{"title":"Z 函数","slug":"Z 函数","date":"2023-09-07T11:44:46.000Z","updated":"2023-09-09T13:36:47.750Z","comments":true,"path":"2023/09/07/Z 函数/","link":"","permalink":"http://example.com/2023/09/07/Z%20%E5%87%BD%E6%95%B0/","excerpt":"","text":"介绍 Z 函数是字符串算法中的一个重要函数，对于一个字符串 \\(s\\) 而言，\\(z[i]\\) 描述了以 \\(s[i]\\) 开始的后缀与 \\(s\\) 的最长公共前缀。 在此约定 \\(z[0] = 0\\) 。 示例：对于字符串 aabaabc 而言，其 Z 函数为：\\(\\{ 0, 1, 0, 3, 1, 0, 0 \\}\\) 。 Z 函数有很多应用，比如字符串匹配等，等会我们会一一介绍。 线性时间复杂度计算 Z 函数 假设要计算 \\(s\\) 的 Z 函数，考虑对于任意 \\(i \\in [0, |s| - 1]\\) ，都计算后缀 \\(s[i :]\\) 和 \\(s\\) 的最长公共前缀，则时间复杂度为 \\(O(|s| ^ 2)\\) 。 所以在这里我们给出一种线性计算 Z 函数的方法： 我们在这里使用两个变量：\\(l\\) 和 \\(r\\) ，初始化均为 0，\\(r\\) 维护当前已经计算过的最大的 \\(i + z[i] - 1\\) ，即目前计算的过的 \\(s[i :]\\) 公共前缀最长延续的下标，\\(l\\) 则表示取最大值时 \\(i\\) 的索引，即 \\(r = l + z[l] - 1\\) 。 接下来从 1 开始便利字符串下标 \\(i\\) 即可： 若 \\(i \\leq r\\) ： 根据定义有 \\(s[i : r] = s[i - l : r - l]\\) ，因此： 若 \\(z[i - l] &lt; r - i + 1\\) ，则 \\(z[i] = z[i - l]\\) ； 若 \\(z[i - l] \\geq r - i + 1\\) ，则 \\(z[i] = r - i + 1\\) ，然后按照 Z 函数的定义继续扩展。 若 \\(i &gt; r\\) ： 我们只需令 \\(z[i] = 0\\) ，然后按照 Z 函数的定义继续拓展即可。 每一轮循环结束后对 \\(l\\) 和 \\(r\\) 进行更新。 代码实现： 12345678910111213141516171819std::vector&lt;int&gt; z_function(const std::string&amp; pat) &#123; int n = pat.size(); std::vector&lt;int&gt; z(n); for (int i = 1, l = 0, r = 0; i &lt; n; i++) &#123; if (i &lt;= r &amp;&amp; z[i - l] &lt; r - i + 1) &#123; z[i] = z[i - l]; &#125; else &#123; z[i] = std::max(0, r - i + 1); while (i + z[i] &lt; n &amp;&amp; pat[z[i]] == pat[i + z[i]]) z[i]++; &#125; if (i + z[i] - 1 &gt; r) &#123; l = i; r = i + z[i] - 1; &#125; &#125; return z;&#125; 注意到，内层 while 循环每一轮都会使得 r 加 1，而外层循环只有一次遍历，因此时间复杂度为 \\(O(n)\\) 。 Z 函数的应用 线性时间复杂度匹配子串 众所周知，KMP 算法可以实现线性时间复杂度内查找字符串 \\(s\\) 中是否存在子串 \\(p\\) ，使用 Z 函数则可以更为简洁地实现同样的效果： 我们构造一个新字符串 \\(sp = p + \\Delta + s\\) ，\\(\\Delta\\) 表示一个分割字符，其不在 \\(p\\) 和 \\(s\\) 中出现，接下来计算 \\(sp\\) 的 Z 函数，若 \\(sp\\) 的 Z 函数存在某个值等于 \\(|p|\\) ，则说明 \\(p\\) 是 \\(s\\) 的子串，反之则说明不是。 示例代码（ haystack 为文本串，needle 为模式串）： 时间复杂度：\\(O(|s| + |p|)\\) 123456789101112131415161718192021222324class Solution &#123;public: int strStr(std::string&amp; haystack, std::string&amp; needle) &#123; std::string str = needle + &#x27;&amp;&#x27; + haystack; int n = str.size(), p = needle.size(); std::vector&lt;int&gt; z(n); for (int i = 1, l = 0, r = 0; i &lt; n; i++) &#123; if (i &lt;= r &amp;&amp; z[i - l] &lt; r - i + 1) &#123; z[i] = z[i - l]; &#125; else &#123; z[i] = std::max(0, r - i + 1); while (i + z[i] &lt; n &amp;&amp; str[z[i]] == str[i + z[i]]) z[i]++; &#125; if (z[i] == p) return i - p - 1; if (i + z[i] - 1 &gt; r) &#123; l = i; r = i + z[i] - 1; &#125; &#125; return -1; &#125;&#125;;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"杜教筛与莫比乌斯反演","slug":"杜教筛与莫比乌斯反演","date":"2023-08-30T12:20:09.000Z","updated":"2023-09-10T07:06:45.333Z","comments":true,"path":"2023/08/30/杜教筛与莫比乌斯反演/","link":"","permalink":"http://example.com/2023/08/30/%E6%9D%9C%E6%95%99%E7%AD%9B%E4%B8%8E%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E5%8F%8D%E6%BC%94/","excerpt":"","text":"此篇文章是笔者参考 OI-wiki 写的一份简单的学习笔记。 杜教筛 简介 杜教筛，是一种用于快速求形如 \\(\\sum_{i = 1} ^ n f(i)\\) 这样前缀和形式的算法，最高效时可以达到 \\(O(n ^ {\\frac{2}{3}})\\) 的时间复杂度。 算法思想 对于 \\(S(n) = \\sum_{i = 1} ^ n f(i)\\) 想办法构造一个 \\(S(n)\\) 关于 \\(S([\\frac{n}{k}])\\) 的递推式。 考虑一个辅助函数 \\(g(i)\\) ，考虑 \\(f\\) 和 \\(g\\) 的狄利克雷卷积之和： \\[ \\sum_{i = 1} ^ n (f * g)(i) = \\sum_{i = 1} ^ n \\sum_{d | i} g(d)f(\\frac{i}{d}) \\\\ = \\sum_{d = 1} ^ n g(d) \\sum_{d | i} f(\\frac{i}{d}) \\\\ = \\sum_{d = 1} ^ n g(d) \\sum_{k = 1} ^ {[\\frac{n}{d}]} f(k) \\\\ = \\sum_{d = 1} ^ n g(d) S([\\frac{n}{d}]) \\] \\[ \\implies g(1)S(n) = \\sum_{i = 1} ^ n (f * g)(i) - \\sum_{d = 2} ^ n g(d) S([\\frac{n}{d}]) \\] 若 \\(\\sum_{i = 1} ^ n (f * g)(i)\\) 可以在 \\(O(1)\\) 之内算出，且 \\(\\sum_{d = 2} ^ n g(d) S([\\frac{n}{d}])\\) 可以分块计算，则总时间复杂度为：\\(O(n ^ {\\frac{3}{4}})\\) 如果线性预处理 \\(S(1)\\) 到 \\(S([n ^ {\\frac{2}{3}}])\\) 的值，则时间复杂度为：\\(O(n ^ {\\frac{2}{3}})\\) 。 模板题，求莫比乌斯函数和欧拉函数的前缀和 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;namespace Solution &#123; using i64 = long long; const int MAX_N = 2000000; std::vector&lt;int&gt; mu(MAX_N + 1); std::vector&lt;i64&gt; phi(MAX_N + 1); void init() &#123; // 预处理 std::vector&lt;int&gt; pri; std::vector&lt;bool&gt; notPrime(MAX_N + 1, false); mu[1] = phi[1] = 1; for (int i = 2; i &lt;= MAX_N; i++) &#123; if (!notPrime[i]) &#123; pri.push_back(i); mu[i] = -1; phi[i] = i - 1; &#125; for (int p : pri) &#123; if (i * p &gt; MAX_N) break; notPrime[i * p] = true; if (i % p == 0) &#123; mu[i * p] = 0; phi[i * p] = phi[i] * p; break; &#125; mu[i * p] = -mu[i]; phi[i * p] = phi[i] * (p - 1); &#125; &#125; for (int i = 2; i &lt;= MAX_N; i++) &#123; mu[i] += mu[i - 1]; phi[i] += phi[i - 1]; &#125; &#125; std::unordered_map&lt;int, int&gt; mob_res; int mobius_sum(int n) &#123; if (mob_res.find(n) != mob_res.end()) return mob_res[n]; if (n &lt;= MAX_N) return mu[n]; i64 res = 1; i64 left = 2, right; while (left &lt;= n) &#123; right = n / (n / left); res -= (right - left + 1) * mobius_sum(n / left); left = right + 1; &#125; return mob_res[n] = res; &#125; std::unordered_map&lt;int, i64&gt; phi_res; i64 phi_sum(i64 n) &#123; if (phi_res.find(n) != phi_res.end()) return phi_res[n]; if (n &lt;= MAX_N) return phi[n]; i64 res = (i64)n * (n + 1) / 2; i64 left = 2, right; while (left &lt;= n) &#123; right = n / (n / left); res -= (right - left + 1) * phi_sum(n / left); left = right + 1; &#125; return phi_res[n] = res; &#125; void solve() &#123; int n; std::cin &gt;&gt; n; std::cout &lt;&lt; phi_sum(n) &lt;&lt; &#x27; &#x27; &lt;&lt; mobius_sum(n) &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); Solution::init(); int numTest; std::cin &gt;&gt; numTest; while (numTest--) Solution::solve(); return 0;&#125; 莫比乌斯反演 莫比乌斯函数 \\[ \\begin{equation} \\mu(n) = \\begin{cases} 1 &amp; n = 1 \\\\ 0 &amp; n \\ 存在平方因子 \\\\ (-1) ^ k &amp; n = \\prod_{i = 1} ^ k p_i \\end{cases} \\end{equation} \\] 莫比乌斯函数常用性质 \\(\\mu\\) 函数为积性函数，若 \\(gcd(x, y) = 1\\) ，则有 \\(\\mu (xy) = \\mu (x) \\mu( y)\\) \\(\\sum_{d | n} \\mu(d) = \\epsilon (n) = [n = 1]\\) 因为莫比乌斯函数是积性函数，所以可以用线性筛筛选： 12345678910111213141516171819202122int mu[MAX_N];int pri[MAX_N];int tot = 0;bool notPrime[MAX_N];void getMU(int n) &#123; mu[1] = 1; for (int i = 2; i &lt;= n; i++) &#123; if (!notPrime[i]) &#123; pri[tot++] = i; mu[i] = -1; &#125; for (int j = 0; j &lt; tot &amp;&amp; i * pri[j] &lt;= n; j++) &#123; notPrime[i * pri[j]] = true; if (i % pri[j] == 0) &#123; mu[i * pri[j]] = 0; break; &#125; mu[i * pri[j]] = -mu[i]; &#125; &#125;&#125; 莫比乌斯变换 设 \\(g(n)\\) 和 \\(f(n)\\) 是两个数论函数，如果有： \\[ f(n) = \\sum_{d | n} g(d) \\] 则有： \\[ g(n) = \\sum_{d | n} \\mu (d) f(\\frac{n}{d}) \\] 这里称 \\(f(n)\\) 为 \\(g(n)\\) 的莫比乌斯变换，\\(g(n)\\) 为 \\(f(n)\\) 的莫比乌斯反演。 反演结论 根据以上结论，我们不难得到 \\([gcd(i, j) = 1] = \\sum_{d | gcd(i, j)} \\mu(d)\\)（事实上就是将 \\(\\sum_{d | n} \\mu(d) = \\epsilon (n) = [n = 1]\\) 中的 \\(n\\) 替换为了 \\(gcd(i, j)\\)），这种替换有时候可以给我们带来意想不到的便利。 接下来我们给出一个例题：题目链接 题意大概就是说有 \\(n\\) 组查询，每组查询有 5 个数字 \\(a, b, c, d\\ (a \\leq b, c \\leq d)\\) 以及 \\(k\\)，然后求解 \\(\\sum_{x = a} ^ b \\sum_{y = c} ^ d [gcd(x, y) = k]\\) 。 不妨设 \\(f(m, n) = \\sum_{x = 1} ^ m \\sum_{y = 1} ^ n[gcd(x, y) = k]\\) ，根据容斥原理，题目的答案为： \\[ f(b, d) - f(b, c - 1) - f(a - 1, d) - f(a - 1, c - 1) \\] 因此我们只需要求解 \\(f(m, n)\\) 的表达式即可。 \\[ \\begin{array}{} f(m, n) = \\sum_{x = 1} ^ m \\sum_{y = 1} ^ n[gcd(x, y) = k] \\\\ = \\sum_{x = 1} ^ {[\\frac{m}{k}]} \\sum_{y = 1} ^ {[\\frac{n}{k}]} [gcd(x, y) = 1] \\\\ \\end{array} \\] 接下来使用莫比乌斯反演，上式可化简为： \\[ \\sum_{x = 1} ^ {[\\frac{m}{k}]} \\sum_{y = 1} ^ {[\\frac{n}{k}]} \\sum_{d | gcd(x, y)} \\mu(d) = \\sum_{x = 1} ^ {[\\frac{m}{k}]} \\sum_{y = 1} ^ {[\\frac{n}{k}]} \\sum_{d | x \\land d | y} \\mu(d) \\] 交换求和顺序，先枚举 \\(d\\) ，原式可进一步化简，最终可得： \\[ f(m, n) = \\sum_{d = 1} ^ {min\\{[\\frac{m}{k}], [\\frac{n}{k}]\\}} \\mu(d) [\\frac{m}{kd}][\\frac{n}{kd}] \\] 接下来使用分块除法即可在 \\(O(\\sqrt{min\\{[\\frac{m}{k}], [\\frac{n}{k}]\\}}\\) 的时间复杂度内求解答案。 参考代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;vector&gt;const int MAX_N = 5e4 + 5;int mu[MAX_N];bool notPrime[MAX_N];void init() &#123; mu[1] = 1; std::vector&lt;int&gt; pri; for (int i = 2; i &lt; MAX_N; i++) &#123; if (!notPrime[i]) &#123; mu[i] = -1; pri.push_back(i); &#125; for (int p : pri) &#123; if (i * p &gt;= MAX_N) break; notPrime[i * p] = true; if (i % p == 0) &#123; mu[i * p] = 0; break; &#125; mu[i * p] = -mu[i]; &#125; &#125; for (int i = 1; i &lt; MAX_N; i++) mu[i] += mu[i - 1];&#125;int solve(int m, int n) &#123; int res = 0; for (int l = 1, r, b = std::min(m, n); l &lt;= b; l = r + 1) &#123; r = std::min(m / (m / l), n / (n / l)); res += (mu[r] - mu[l - 1]) * (m / l) * (n / l); &#125; return res;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); init(); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; int a, b, c, d, k; std::cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d &gt;&gt; k; int res = solve(b / k, d / k) - solve(b / k, (c - 1) / k) - solve((a - 1) / k, d / k) + solve((a - 1) / k, (c - 1) / k); std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;; &#125; return 0;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数论","slug":"数论","permalink":"http://example.com/tags/%E6%95%B0%E8%AE%BA/"},{"name":"杜教筛","slug":"杜教筛","permalink":"http://example.com/tags/%E6%9D%9C%E6%95%99%E7%AD%9B/"},{"name":"莫比乌斯反演","slug":"莫比乌斯反演","permalink":"http://example.com/tags/%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E5%8F%8D%E6%BC%94/"}]},{"title":"Vim 编辑器入门","slug":"Vim 编辑器入门","date":"2023-08-15T16:51:02.000Z","updated":"2024-01-18T06:01:28.287Z","comments":true,"path":"2023/08/16/Vim 编辑器入门/","link":"","permalink":"http://example.com/2023/08/16/Vim%20%E7%BC%96%E8%BE%91%E5%99%A8%E5%85%A5%E9%97%A8/","excerpt":"","text":"简介 Vim（Vi IMproved）是一款强大、高度可定制且广泛使用的文本编辑器。它是 Unix 系统下的一个经典编辑器，也可以在其他操作系统上运行，包括 Linux、macOS 和 Windows。Vim 是从 Vi 编辑器发展而来的，但在功能和特性上进行了扩展和改进，成为了一个强大的文本编辑工具。尽管 Vim 具有很多功能，但它的学习曲线可能较陡峭，需要一些时间来适应和掌握。许多程序员选择学习和使用 Vim，因为一旦熟练掌握，它可以成为一个高效的文本编辑工具，适用于各种编程和文本处理任务。 基本使用 Vim 编辑器在使用的过程中有三种模式，即正常模式、编辑模式以及命令行模式，以下将一一介绍。 使用 Vim 编辑器打开或者新建文本文件 1vim filename 使用 vim 指令后会进入正常模式 ，此刻还不能编辑文本，只能预览文本。 进入编辑模式 此刻按下 i 键即可进入编辑模式。 此时终端下方会显示 -- INSERT -- ： 如何退出编辑模式进入正常模式呢？ 直接按下 esc 键即可。 进入命令行模式 在正常模式下，直接输入冒号 : ，则可进入命令行模式，此时可在底部输入命令： 一些常用命令： 保存退出： 1:wq 不保存退出： 1:q! 导航与编辑 KJHL 导航 在正常模式下，光标的移动由 4 个键组成，即： H ：左 L ：右 K ：上 J ：下 不同编辑方式 在将光标移动到合适的位置我们就可以开始编辑了，此时有几种选择： I ：如果键入 I ，表示插入，在光标的左边添加文本。 A ：如果键入 A ，表示追加，在光标的右边添加文本。 如果要在最前面添加文本，输入 Shift + I ，同理，若要在文本最后面添加文本，输入 Shift + A 。 O ：如果键入 O ，则向下另起一行，进入编辑模式。 键入 shift + O ，则增加上一行。 行数导航 如果想要让 Vim 编辑器显示文本行数，则需要我们自行在 .vimrc 文本中加入配置： 1set number 如何查找到 .vimrc 文本的位置呢？使用 vim --version 的指令即可显示其位置。 .vimrc 文本用于设置许多 Vim 编辑器的配置，后续还会经常提及。 如果想让 Vim 编辑器显示相对行数，则需要在 .vimrc 中添加配置： 1set relativenumber 行的跳转： 将光标跳转至第一行： 键入 Shift + G 。 将光标跳转至最后一行： 连续 2 次键入 G 。 向上跳转 n 行： 键入 数字 n + K 。 向下跳转 n 行： 键入 数字 n + J 。 复制行与删除行 连续两次键入 Y ，即可复制当前行，然后再键入 P ，就可以将复制的文本进行粘贴。 如若想删除行，可以连续两次键入 D ，则可将该行删除。 重复最近操作和撤销操作 键入 . ，则可重复最近一次的操作。 键入 U ，则可撤销最近一次操作。 键入 crtl + r ，恢复前一次操作。 修改单词 键入 W ，光标跳转到下一个字母的首部。 键入 E ，光标跳转到下一个字母的尾部。 键入 B ，光标移动到上一个字母的首部。 键入 D + W ，可删除单词。 键入 C + W ，可改变单词。 键入 Y + W ，可复制单词。 删除括号内的内容 键入 C + I + 括号（&#123; 、[ 、(）即可删除光标所在括号的内容。 搜索与替换 搜索 进入命令行模式，输入 / + 变量名或函数名，即可将光标跳转到该函数。 命名全局替换 在命令行模式下输入 %s/旧命名/新命名/g ，可将所有旧命名全局替换。 可视化块和可视化行 键入 ctrl + V 可进入可视化块，可自己选择代码块进行相应的操作。 键入 shift + V 可进入可视化行，可自己选择代码行进行相应的操作。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://example.com/tags/Vim/"}]},{"title":"暑假集训 杭电多校 Round 6","slug":"暑假集训 杭电多校 Round 6","date":"2023-08-03T14:06:42.000Z","updated":"2023-08-14T02:48:14.265Z","comments":true,"path":"2023/08/03/暑假集训 杭电多校 Round 6/","link":"","permalink":"http://example.com/2023/08/03/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1%20Round%206/","excerpt":"","text":"比赛链接 补题链接 「1004」 Count 签到题，\\(n \\not= k\\) 时答案为 \\(m ^ {n - k}\\) ，\\(n = k\\) 时答案为 \\(m ^ n\\)。 时间复杂度：\\(O(logn)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920212223242526#include &lt;iostream&gt;const int mod = 998244353;using i64 = long long;void solve() &#123; i64 n, m, k; std::cin &gt;&gt; n &gt;&gt; m &gt;&gt; k; i64 t = n - k ? n - k : n; i64 res = 1; while (t) &#123; if (t &amp; 1) res = (__int128_t)res * m % mod; m = (__int128_t)m * m % mod; t &gt;&gt;= 1; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1002」 Pair Sum and Perfect Square 先枚举所有满足题意的 \\(i、j\\) 使得 \\(p_i + p_j\\) 为完全平方数，由于 \\(P\\) 在这里是 \\(1\\) 到 \\(n\\) 的排列，所以合法的 \\((i, j)\\) 只有 \\(O(n ^ {\\frac{3}{2}})\\) 种可能，接下来就是一个二维数点的问题了，即对于每次查询的区间 \\((L, R)\\) ，需找到多少点 \\((i, j)\\) 落在 \\((L, L)\\) 和 \\((R, R)\\) 组成的正方形内。 时间复杂度：\\(O(n ^ {\\frac{3}{2}} + q(logq + logn))\\) 空间复杂度：\\(O(n + k)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;const int MAX_N = 5e5 + 5;const int MAX_Q = 5e5 + 5;int n;int per[MAX_N];int id[MAX_N];int q;struct Query &#123; int x; int y; int id;&#125; query[4 * MAX_Q];int res[4 * MAX_Q];namespace __BIT &#123; int tree[MAX_N]; inline int lowbit(int x) &#123; return x &amp; -x; &#125; int prefix(int idx) &#123; int res = 0; while (idx) &#123; res += tree[idx]; idx -= lowbit(idx); &#125; return res; &#125; void add(int idx, int val = 1) &#123; while (idx &lt;= n) &#123; tree[idx] += val; idx += lowbit(idx); &#125; &#125;&#125;using namespace __BIT;void solve() &#123; std::cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) &#123; std::cin &gt;&gt; per[i]; id[per[i]] = i; &#125; std::cin &gt;&gt; q; int all = 4 * q; for (int i = 0, l, r; i &lt; all; i += 4) &#123; std::cin &gt;&gt; l &gt;&gt; r; query[i] = &#123;r, r, i&#125;; query[i + 1] = &#123;l - 1, r, i + 1&#125;; query[i + 2] = &#123;r, l - 1, i + 2&#125;; query[i + 3] = &#123;l - 1, l - 1, i + 3&#125;; &#125; std::sort(query, query + all, [](const Query&amp; q1, const Query&amp; q2) &#123; return q1.x &lt; q2.x; &#125;); int j = 0; for (int i = 1; i &lt;= n; i++) &#123; for (int t = 2; ; t++) &#123; int pf = t * t - per[i]; if (pf &lt;= 0) continue; if (pf &gt;= per[i]) break; while (j &lt; all &amp;&amp; i &gt; query[j].x) &#123; // 当前区间已经统计完成 res[query[j].id] = prefix(query[j].y); j++; &#125; add(id[pf]); &#125; &#125; while (j &lt; all) &#123; res[query[j].id] = prefix(query[j].y); j++; &#125; for (int i = 0; i &lt; all; i += 4) &#123; std::cout &lt;&lt; res[i] - res[i + 1] - res[i + 2] + res[i + 3] &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1006」 Perfect square number 使用一个数组动态维护所有跨越 \\(a_i\\) 的序列中增加 \\(k \\ (-300 \\leq k \\leq 300)\\) 后序列和为完全平方数的个数。当迭代次数从 \\(i - 1\\) 转移到 \\(i\\) 时，我们只需要考虑更新以 \\(a_i\\) 开头的序列，同时减去以 \\(a_{i - 1}\\) 结尾的序列中计算过的冗余即可。 时间复杂度：\\(O(n ^ 2 \\sqrt{k})\\) 空间复杂度：\\(O(n + k)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;#include &lt;cstring&gt;const int MAX_N = 300, MAX_K = 300;int a[MAX_N + 5];int s[MAX_N + 5];inline int sum(int l, int r) &#123; return s[r] - s[l - 1];&#125;int lp[MAX_N + 5], rp[MAX_N + 5];int plus[2 * MAX_K + 5];inline int&amp; get_plus(int k) &#123; // 记录跨越当前 a[i] 的序列中有多少个序列增加 k 后为完全平方数 return plus[k + MAX_K];&#125;int ub(int x) &#123; int t = std::sqrt(x); while (t * t &lt; x) t++; return t;&#125;bool check(int s) &#123; int b = ub(s); return b * b == s;&#125;void solve() &#123; memset(plus, 0x00, sizeof(plus)); memset(lp, 0x00, sizeof(lp)); memset(rp, 0x00, sizeof(rp)); int n; std::cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) std::cin &gt;&gt; a[i]; for (int i = 1; i &lt;= n; i++) s[i] = s[i - 1] + a[i]; for (int i = 1; i &lt;= n; i++) &#123; lp[i] += lp[i - 1]; for (int j = 1; j &lt;= i; j++) &#123; if (check(sum(j, i))) lp[i]++; &#125; &#125; for (int i = n; i &gt;= 1; i--) &#123; rp[i] += rp[i + 1]; for (int j = i; j &lt;= n; j++) &#123; if (check(sum(i, j))) rp[i]++; &#125; &#125; int res = 0; for (int i = 1; i &lt;= n; i++) &#123; for (int j = i; j &lt;= n; j++) &#123; int ds = sum(i, j); int b = ub(ds); for (int ib = b; ib * ib - ds &lt;= MAX_K; ib++) &#123; get_plus(ib * ib - ds)++; &#125; for (int ib = b - 1; ib &gt; 0 &amp;&amp; ib * ib - ds &gt;= -MAX_K; ib--) &#123; get_plus(ib * ib - ds)++; &#125; &#125; for (int j = i - 1; j &gt;= 1; j--) &#123; int ds = sum(j, i - 1); int b = ub(ds); for (int ib = b; ib * ib - ds &lt;= MAX_K; ib++) &#123; get_plus(ib * ib - ds)--; &#125; for (int ib = b - 1; ib &gt; 0 &amp;&amp; ib * ib - ds &gt;= -MAX_K; ib--) &#123; get_plus(ib * ib - ds)--; &#125; &#125; int p = 0; for (int k = -a[i] + 1; k &lt;= MAX_K - a[i]; k++) p = std::max(p, get_plus(k)); res = std::max(res, p + lp[i - 1] + rp[i + 1]); &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1003」 Vector 若三个向量线性无关，则只需要判断 \\(A_4\\) 是否落在向量 \\(A_1\\) ，\\(A_2\\) ，\\(A_3\\) 的张集里面即可（由于相关系数只能是非负数，所以这里的张集是一个无穷大的三棱锥）；若三个向量线性相关，则其张集一定可以在一个平面内表示，此时用类似的方式判断 \\(A_4\\) 是否属于该集合即可。 这里要注意零向量的情况。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#include &lt;iostream&gt;namespace __3dvector &#123; using i64 = long long; struct Vec &#123; i64 x, y, z; Vec(i64 _x = 0, i64 _y = 0, i64 _z = 0): x(_x), y(_y), z(_z) &#123;&#125; &#125;; Vec zero(0, 0, 0); bool operator==(const Vec&amp; v1, const Vec&amp; v2) &#123; return v1.x == v2.x &amp;&amp; v1.y == v2.y &amp;&amp; v1.z == v2.z; &#125; bool operator!=(const Vec&amp; v1, const Vec&amp; v2) &#123; return v1.x != v2.x || v1.y != v2.y || v1.z != v2.z; &#125; Vec operator+(const Vec&amp; v1, const Vec&amp; v2) &#123; return Vec(v1.x + v2.x, v1.y + v2.y, v1.z + v2.z); &#125; i64 dot(const Vec&amp; v1, const Vec&amp; v2) &#123; return v1.x * v2.x + v1.y * v2.y + v1.z * v2.z; &#125; Vec cross(const Vec&amp; v1, const Vec&amp; v2) &#123; return Vec( v1.y * v2.z - v1.z * v2.y, - v1.x * v2.z + v1.z * v2.x, v1.x * v2.y - v1.y * v2.x ); &#125;&#125;using namespace __3dvector;inline int sgn(i64 x) &#123; return (x &gt; 0) - (x &lt; 0);&#125;bool judge(const Vec&amp; v1, const Vec&amp; v2) &#123; return sgn(v1.x) * sgn(v2.x) &gt;= 0 &amp;&amp; sgn(v1.y) * sgn(v2.y) &gt;= 0 &amp;&amp; sgn(v1.z) * sgn(v2.z) &gt;= 0;&#125;void solve() &#123; Vec v[4]; for (int i = 0; i &lt; 4; i++) std::cin &gt;&gt; v[i].x &gt;&gt; v[i].y &gt;&gt; v[i].z; i64 x1 = v[0].x, x2 = v[1].x, x3 = v[2].x; i64 y1 = v[0].y, y2 = v[1].y, y3 = v[2].y; i64 z1 = v[0].z, z2 = v[1].z, z3 = v[2].z; i64 det = x1 * y2 * z3 + x2 * y3 * z1 + x3 * y1 * z2 - x3 * y2 * z1 - x2 * y1 * z3 - x1 * y3 * z2; // 计算行列式 if (det) &#123; Vec cr1 = cross(v[0], v[1]), cr2 = cross(v[1], v[2]), cr3 = cross(v[2], v[0]); // 3 个平面的法向量 Vec vt = v[0] + v[1] + v[2]; i64 dt1 = dot(vt, cr1); i64 d1 = dot(v[3], cr1), d2 = dot(v[3], cr2), d3 = dot(v[3], cr3); if (sgn(d1) * sgn(dt1) &gt;= 0 &amp;&amp; sgn(d2) * sgn(dt1) &gt;= 0 &amp;&amp; sgn(d3) * sgn(dt1) &gt;= 0) &#123; std::cout &lt;&lt; &quot;YES\\n&quot;; return; &#125; &#125; else &#123; // rank &lt;= 2 for (int i = 0; i &lt; 3; i++) &#123; for (int j = i + 1; j &lt; 3; j++) &#123; Vec cr = cross(v[i], v[j]); if (cr == zero) &#123; // v[i] 与 v[j] 平行 if (cross(v[3], v[i]) == zero &amp;&amp; cross(v[3], v[j]) == zero &amp;&amp; (v[i] != zero &amp;&amp; judge(v[3], v[i]) || v[j] != zero &amp;&amp; judge(v[3], v[j]))) &#123; std::cout &lt;&lt; &quot;YES\\n&quot;; return; &#125; else if (v[i] == zero &amp;&amp; v[j] == zero) &#123; if (v[3] == zero) &#123; std::cout &lt;&lt; &quot;YES\\n&quot;; return; &#125; &#125; &#125; else &#123; // v[i] 与 v[j] 不平行 if (dot(v[3], cr) == 0) &#123; // 则 v[3] 必须与两个向量共面 Vec cri = cross(v[3], v[i]), crj = cross(v[3], v[j]); Vec vt = v[i] + v[j]; Vec crit = cross(vt, v[i]), crjt = cross(vt, v[j]); if (judge(cri, crit) &amp;&amp; judge(crj, crjt)) &#123; std::cout &lt;&lt; &quot;YES\\n&quot;; return; &#125; &#125; &#125; &#125; &#125; &#125; std::cout &lt;&lt; &quot;NO\\n&quot;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"}]},{"title":"暑假集训 杭电多校 Round 5","slug":"暑假集训 杭电多校 Round 5","date":"2023-08-01T11:49:00.000Z","updated":"2023-09-01T16:21:23.858Z","comments":true,"path":"2023/08/01/暑假集训 杭电多校 Round 5/","link":"","permalink":"http://example.com/2023/08/01/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1%20Round%205/","excerpt":"","text":"题目链接 补题链接 「1001」 Typhoon 签到题，遍历每条线段到每个点的最小距离即可。 时间复杂度：\\(O(mn)\\) 空间复杂度：\\(O(m)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cmath&gt;struct Point &#123; double x, y;&#125;;inline double dist2(const Point&amp; p1, const Point&amp; p2) &#123; double dx = (p1.x - p2.x); double dy = (p1.y - p2.y); return dx * dx + dy * dy;&#125;double dist2line(const Point&amp; p0, const Point&amp; p1, const Point&amp; p2) &#123; double vx = p2.x - p1.x, vy = p2.y - p1.y; double d1 = vx * (p1.x - p0.x) + vy * (p1.y - p0.y); double d2 = vx * (p2.x - p0.x) + vy * (p2.y - p0.y); if (d1 * d2 &lt; 0) &#123; double f1 = (p2.x - p1.x) * (p0.y - p1.y) - (p2.y - p1.y) * (p0.x - p1.x); double f2 = (p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y); return f1 * f1 / f2; &#125; else &#123; return std::min(dist2(p0, p1), dist2(p0, p2)); &#125;&#125;#define MAX_N 10005Point pos[MAX_N];void solve() &#123; int m, n; std::cin &gt;&gt; m &gt;&gt; n; for (int i = 0; i &lt; m; i++) &#123; std::cin &gt;&gt; pos[i].x &gt;&gt; pos[i].y; &#125; Point p0; // 庇护所 for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; p0.x &gt;&gt; p0.y; double res = INFINITY; for (int i = 1; i &lt; m; i++) &#123; res = std::min(res, dist2line(p0, pos[i - 1], pos[i])); &#125; printf(&quot;%.4lf\\n&quot;, std::sqrt(res)); &#125;&#125;int main() &#123; solve(); return 0;&#125; 「1002」 GCD Magic 首先，显然有 \\(gcd(2 ^ i - 1, 2 ^ j - 1)\\) = \\(2 ^ {gcd(i, j)} - 1\\) ，所以原表达式只与 \\(gcd(i, j)\\) 有关，所以我们只用枚举全部 \\(i\\) 和 \\(j\\) 的最大公约数的数量即可。 对于 \\(i、j\\) 满足 \\(1 \\leq i、j \\leq n\\) 而言，满足 \\(gcd(i, j) = t\\) 的数量为： \\[ \\begin{array}{} \\sum_{i = 1} ^ n \\sum_{j = 1} ^ n [gcd(i, j) = t] \\\\ = \\sum_{i = 1} ^ {[\\frac{n}{t}]} \\sum_{j = 1} ^ {[\\frac{n}{t}]} [gcd(i, j) = 1] \\\\ = \\sum_{i = 1} ^ {[\\frac{n}{t}]} \\sum_{j = 1} ^ {[\\frac{n}{t}]} \\sum_{d | gcd(i, j)} \\mu(d) \\\\ = \\sum_{d = 1} ^ {[\\frac{n}{t}]} \\mu(d) \\sum_{i = 1} ^ {[\\frac{n}{t}]} \\sum_{j = 1} ^ {[\\frac{n}{t}]} [d | gcd(i, j)] \\\\ = \\sum_{d = 1} ^ {[\\frac{n}{t}]} \\mu(d) [\\frac{n}{td}] ^ 2 \\end{array} \\] 要计算的表达式可化为 \\(f(t) = (2 ^ t - 1) ^ k\\) ，因此最终要求的表达式如下所示： \\[ \\sum_{t = 1} ^ n f(t) \\sum_{d = 1} ^ {[\\frac{n}{t}]} \\mu(d) [\\frac{n}{td}] ^ 2 \\] 令 \\(T = dt\\) ，交换求和顺序，先枚举 \\(T\\) ，上式可转化为： \\[ \\sum_{T = 1} ^ n [\\frac{n}{T}] ^ 2 \\sum_{d | T} f(d) \\mu(\\frac{T}{d}) \\] 由于题目中的 \\(n\\) 很大，所以这里考虑使用杜教筛来计算 \\(\\sum_{d | T} f(d)\\mu(\\frac{T}{d})\\) 的前缀和，然后使用分块除法来快速求出上式的值。 考虑狄利克雷卷积，\\(f * \\mu * 1 = f * \\epsilon = f(T)\\) ，设 \\(S(n) = \\sum_{T = 1} ^ n \\sum_{d | T} f(d) \\mu(\\frac{T}{d})\\) 则有： \\[ S(n) = \\sum_{T = 1} ^ n f(T) - \\sum_{d = 2} ^ n S([\\frac{n}{d}]) \\] \\[ f(T) = (2 ^ T - 1) ^ K = \\sum_{i = 0} ^ K C_{K} ^ i 2 ^ {Ti} (-1) ^ {K - i} \\] 此处就是一个等比数列求和。 时间复杂度：\\(O(K \\sqrt n)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include &lt;cmath&gt;#include &lt;cstdio&gt;#include &lt;unordered_map&gt;using namespace std;using LL = long long;const int maxs = 1000001, maxk = 10, MOD = 998244353;int te, K;LL n;int u[maxs + 5], p[maxs + 5];bool pri[maxs + 5];int C[maxk + 5][maxk + 5], val[maxk + 5];int lim, G[maxs + 5];unordered_map&lt;LL, int&gt; f;int ans;inline int ADD(int x, int y) &#123; return x + y &gt;= MOD ? x + y - MOD : x + y; &#125;inline int MUL(int x, int y) &#123; return (LL)x * y % MOD; &#125;int Pow(int w, int b) &#123; int s; for (s = 1; b; b &gt;&gt;= 1, w = MUL(w, w)) if (b &amp; 1) s = MUL(s, w); return s;&#125;void Make() &#123; for (int i = 0; i &lt;= maxk; i++) &#123; C[i][0] = 1; for (int j = 1; j &lt;= i; j++) C[i][j] = ADD(C[i - 1][j - 1], C[i - 1][j]); &#125; for (int i = 1; i &lt;= maxk; i++) val[i] = MUL(1 &lt;&lt; i, Pow((1 &lt;&lt; i) - 1, MOD - 2)); u[1] = 1; for (int i = 2; i &lt;= maxs; i++) &#123; if (!pri[i]) p[++p[0]] = i, u[i] = MOD - 1; for (int j = 1, t; j &lt;= p[0] &amp;&amp; (t = i * p[j]) &lt;= maxs; j++) &#123; pri[t] = true; if (i % p[j]) u[t] = (MOD - u[i]) % MOD; else &#123; u[t] = 0; break; &#125; &#125; &#125;&#125;int SumF(LL n) &#123; int ans = MUL(K &amp; 1 ? MOD - 1 : 1, n % MOD); int BA = Pow(2, n % (MOD - 1)), pw = BA; for (int j = 1; j &lt;= K; j++) &#123; int now = MUL(C[K][j], K - j &amp; 1 ? MOD - 1 : 1); now = MUL(now, MUL(val[j], ADD(pw, MOD - 1))); ans = ADD(ans, now); pw = MUL(pw, BA); &#125; return ans;&#125;int Sum(LL n) &#123; if (n &lt;= lim) return G[n]; if (f.count(n)) return f[n]; int ans = SumF(n); for (LL l = 2, r; l &lt;= n; l = r + 1) &#123; r = n / (n / l); ans = ADD(ans, MOD - MUL(Sum(n / l), (r - l + 1) % MOD)); &#125; return f[n] = ans;&#125;int main() &#123; Make(); for (scanf(&quot;%d&quot;, &amp;te); te; te--) &#123; scanf(&quot;%lld%d&quot;, &amp;n, &amp;K); lim = pow(n, 2.0 / 3) + 1; for (int i = 1; i &lt;= lim; i++) G[i] = 0; for (int i = 1, pw = 2; i &lt;= lim; i++, pw = MUL(pw, 2)) &#123; int F = Pow(pw - 1, K); for (int j = i, k = 1; j &lt;= lim; j += i, k++) G[j] = ADD(G[j], MUL(u[k], F)); &#125; for (int i = 1; i &lt;= lim; i++) G[i] = ADD(G[i], G[i - 1]); f.clear(); ans = 0; for (LL l = 1, r; l &lt;= n; l = r + 1) &#123; r = n / (n / l); ans = ADD(ans, MUL(ADD(Sum(r), MOD - Sum(l - 1)), MUL(n / l % MOD, n / l % MOD))); &#125; printf(&quot;%d\\n&quot;, ans); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"}]},{"title":"暑假集训 Nowcoder 多校 Round 4","slug":"暑假集训 Nowcoder 多校 Round 4","date":"2023-07-28T13:17:47.000Z","updated":"2023-07-29T14:07:17.245Z","comments":true,"path":"2023/07/28/暑假集训 Nowcoder 多校 Round 4/","link":"","permalink":"http://example.com/2023/07/28/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20Nowcoder%20%E5%A4%9A%E6%A0%A1%20Round%204/","excerpt":"","text":"比赛链接 F 「Election of the King」 签到题，每次淘汰的候选人要么是最左的，要么是最右的，因此用两个变量维护两端的索引，逐步向中间移动。 每一轮选举使用二分查找来得到两人的票数，将得票高的一方淘汰即可。 时间复杂度：\\(O(nlogn)\\) 空间复杂度：\\(O(n)\\) 每一轮循环也可以只看中间的人来判断谁被淘汰，可以将时间复杂度优化到 \\(O(n)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;algorithm&gt;#define MAX_N 1000005using i64 = long long;struct &#123; i64 v; int idx;&#125; a[MAX_N];void solve() &#123; int n; std::cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; a[i].v; a[i].idx = i; &#125; std::sort(a, a + n, [](auto&amp; a1, auto&amp; a2) &#123; return a1.v &lt; a2.v; &#125;); int left = 0, right = n - 1; while (left &lt; right) &#123; int l = left, r = right; // 2 * a[l].v &lt;= a[left].v + a[right].v // 2 * a[r].v &gt; a[left].v + a[right].v i64 x = a[left].v + a[right].v; if (2 * a[r].v &lt;= x) &#123; right--; continue; &#125; while (r - l &gt; 1) &#123; int mid = (l + r) / 2; if (2 * a[mid].v &lt;= x) &#123; l = mid; &#125; else &#123; r = mid; &#125; &#125; if (right - r + 1 &gt; r - left) &#123; left++; &#125; else &#123; right--; &#125; &#125; std::cout &lt;&lt; a[left].idx + 1 &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125; L 「We are the Lights」 因为后续的操作会覆盖之前的操作，所以从后往前遍历所有操作，操作过的行和列会被锁住且后续无法再修改，同时用两个变量 r 、c 分别维护未被锁住的行数和列数，若当前操作为 row x on 且 x 行未上锁，则当前开灯总数增加 c ，r 自减 1，对于其他三种情况，同理分析即可。 时间复杂度：\\(O(q)\\) 空间复杂度：\\(O(m + n + q)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#define MAX_NUM 1000005using i64 = long long;struct &#123; std::string pos; int val; std::string kind;&#125; op[MAX_NUM];bool lockRow[MAX_NUM];bool lockCol[MAX_NUM];void solve() &#123; int n, m, q; std::cin &gt;&gt; n &gt;&gt; m &gt;&gt; q; for (int i = 0; i &lt; q; i++) &#123; std::cin &gt;&gt; op[i].pos &gt;&gt; op[i].val &gt;&gt; op[i].kind; &#125; int r = n, c = m; // 未被锁住的行列数 i64 res = 0; for (int i = q - 1; i &gt;= 0; i--) &#123; if (op[i].kind == &quot;on&quot;) &#123; if (op[i].pos == &quot;row&quot;) &#123; if (lockRow[op[i].val]) continue; res += c; r--; lockRow[op[i].val] = true; &#125; else &#123; if (lockCol[op[i].val]) continue; res += r; c--; lockCol[op[i].val] = true; &#125; &#125; else &#123; if (op[i].pos == &quot;row&quot;) &#123; if (lockRow[op[i].val]) continue; r--; lockRow[op[i].val] = true; &#125; else &#123; if (lockCol[op[i].val]) continue; c--; lockCol[op[i].val] = true; &#125; &#125; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125; J 「Qu'est-ce Que C'est?」 假设 \\(dp[i][s]\\) 表示 \\([0, i]\\) 序列中最小后缀和为 \\(s\\) 的合法情况有多少种，可以得到状态转移方程： \\[ \\begin{equation} dp[i][s] = \\begin{cases} \\ \\sum_{k = s - m} ^ m dp[i - 1][k] &amp; s \\geq 0 \\\\ \\\\ \\ \\sum_{k = - s} ^ m dp[i - 1][k] &amp; s &lt; 0 \\end{cases} \\end{equation} \\] 根据状态转移方程，我们需要定义一个后缀数组来维护后缀和来优化时间，同时注意到 \\(dp[i]\\) 只与 \\(dp[i - 1]\\) 有关，所以可以使用滚动数组优化空间。 时间复杂度：\\(O(nm)\\) 空间复杂度：\\(O(m)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#define MAX_M 5005using i64 = long long;const int mod = 998244353;i64 dp[2][2 * MAX_M];i64 sum[2][2 * MAX_M];void solve() &#123; int n, m; std::cin &gt;&gt; n &gt;&gt; m; for (int s = m; s &gt;= -m; s--) &#123; dp[0][m + s] = 1; sum[0][m + s] = (sum[0][m + s + 1] + dp[0][m + s]) % mod; &#125; for (int i = 1; i &lt; n; i++) &#123; for (int s = m; s &gt;= -m; s--) &#123; if (s &gt;= 0) &#123; dp[i &amp; 1][m + s] = sum[(i - 1) &amp; 1][m + s - m]; &#125; else &#123; dp[i &amp; 1][m + s] = sum[(i - 1) &amp; 1][m - s]; &#125; sum[i &amp; 1][m + s] = (sum[i &amp; 1][m + s + 1] + dp[i &amp; 1][m + s]) % mod; &#125; &#125; std::cout &lt;&lt; sum[(n - 1) &amp; 1][0] &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125; H 「Merge the squares!」 对于任意一个 \\(n \\times n\\) 的正方形，如果 \\(n &lt; 8\\) ，则可以一次性合并，若 \\(n \\geq 8\\) ，我们考虑如下分割方式： 即将一个正方形分割为两个正方形与两个矩形，两个正方形的边长分别为 \\(j\\) 和 \\(n - j\\) ，通过枚举 \\(j\\) ，若两个 \\((n - j) \\times j\\) 的矩形可以分割为不超过 24 个正方形，则总的正方形合并数不超过 50。经计算，发现对任意 \\(n\\) 满足 \\(8 \\leq n \\leq 1000\\) 都可以找到合法的 \\(j\\) 满足题意。 我们使用一个数组来维护每一个 \\(n\\) 的合法分割方案，然后使用递归来记录答案即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;iostream&gt;#include &lt;functional&gt;#include &lt;vector&gt;#include &lt;array&gt;int splitGrid[1001];void init() &#123; // 得到所有可行的分割方案 for (int i = 8; i &lt;= 1000; i++) &#123; for (int j = (i + 1) / 2; j &lt; i; j++) &#123; int a = j, b = i - j; int cnt = 0; while (b) &#123; cnt += (a / b); a %= b; std::swap(a, b); &#125; if (cnt &lt;= 24) &#123; splitGrid[i] = j; break; &#125; &#125; assert(splitGrid[i] &gt; 0); &#125;&#125;void solve() &#123; int n; std::cin &gt;&gt; n; std::vector&lt;std::array&lt;int, 3&gt;&gt; ans; std::function&lt;void(int, int, int, int)&gt; merge = [&amp;merge, &amp;ans](int x1, int y1, int x2, int y2) -&gt; void &#123; if (x2 - x1 == y2 - y1) &#123; int len = x2 - x1 + 1; if (len == 1) return; if (len &lt;= 7) &#123; ans.push_back(&#123;x1, y1, len&#125;); return; &#125; int k = splitGrid[len]; merge(x1, y1, x1 + k - 1, y1 + k - 1); merge(x1 + k, y1 + k, x2, y2); merge(x1, y1 + k, x1 + k - 1, y2); merge(x1 + k, y1, x2, y1 + k - 1); ans.push_back(&#123;x1, y1, len&#125;); &#125; else &#123; int len1 = x2 - x1 + 1, len2 = y2 - y1 + 1; if (len1 &gt; len2) &#123; merge(x1, y1, x1 + len2 - 1, y1 + len2 - 1); x1 += len2; &#125; else &#123; merge(x1, y1, x1 + len1 - 1, y1 + len1 - 1); y1 += len1; &#125; merge(x1, y1, x2, y2); &#125; &#125;; merge(1, 1, n, n); std::cout &lt;&lt; ans.size() &lt;&lt; &#x27;\\n&#x27;; for (const auto&amp; [x, y, len] : ans) &#123; std::cout &lt;&lt; x &lt;&lt; &#x27; &#x27; &lt;&lt; y &lt;&lt; &#x27; &#x27; &lt;&lt; len &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); init(); solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Nowcoder","slug":"Nowcoder","permalink":"http://example.com/tags/Nowcoder/"}]},{"title":"暑假集训 杭电多校 Round 4","slug":"暑假集训 杭电多校 Round 4","date":"2023-07-28T02:56:11.000Z","updated":"2023-07-29T11:25:59.857Z","comments":true,"path":"2023/07/28/暑假集训 杭电多校 Round 4/","link":"","permalink":"http://example.com/2023/07/28/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1%20Round%204/","excerpt":"","text":"补题链接 「1007」 Guess 结论题，证明得当 \\(n\\) 为素数的幂即 \\(n = p ^ c\\) 时 \\(S(n) = ln\\ \\!p\\) ，否则 \\(S(n) = 0\\) 。 然后使用 Pollard-Rho 算法进行质因数分解即可。 时间复杂度：\\(O(n ^ {\\frac{1}{4}})\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include &lt;iostream&gt;#include &lt;unordered_map&gt;#include &lt;functional&gt;using i64 = long long;const int mod = 998244353;i64 quickPow(i64 x, i64 n, i64 mod) &#123; i64 res = 1; while (n) &#123; if (n &amp; 1) res = (__int128_t)res * x % mod; x = (__int128_t)x * x % mod; n &gt;&gt;= 1; &#125; return res;&#125;bool millerRabin(i64 n, int test_times = 8) &#123; if (n &lt; 3 || n % 2 == 0) return n == 2; i64 u = n - 1; int t = 0; while (!(u &amp; 1)) &#123; u &gt;&gt;= 1; t++; &#125; for (int i = 0; i &lt; test_times; i++) &#123; i64 a = std::rand() % (n - 2) + 2; i64 v = quickPow(a, u, n); if (v == 1) continue; int s; for (s = 0; s &lt; t; s++) &#123; if (v == n - 1) break; v = (__int128_t)v * v % n; &#125; if (s == t) return false; &#125; return true;&#125;i64 gcd(i64 x, i64 y) &#123; return y == 0 ? x : gcd(y, x % y);&#125;i64 Pollard_Rho(i64 x) &#123; i64 s = 0, t = 0; i64 c = (i64)std::rand() % (x - 1) + 1; int step = 0, goal = 1; i64 val = 1; for (goal = 1; ; goal &lt;&lt;= 1, s = t, val = 1) &#123; for (step = 1; step &lt;= goal; step++) &#123; t = ((__int128_t)t * t + c) % x; val = (__int128_t)val * std::abs(t - s) % x; if (step % 127 == 0) &#123; i64 d = gcd(val, x); if (d &gt; 1) return d; &#125; &#125; i64 d = gcd(val, x); if (d &gt; 1) return d; &#125;&#125;i64 solve() &#123; i64 x; std::cin &gt;&gt; x; std::unordered_map&lt;i64, int&gt; res; std::function&lt;void(i64)&gt; fac = [&amp;res, &amp;fac](i64 n) &#123; if (n &lt; 2) return; if (millerRabin(n)) &#123; res[n]++; return; &#125; i64 p = n; while (p &gt;= n) p = Pollard_Rho(n); fac(p), fac(n / p); &#125;; fac(x); if (res.size() == 1) &#123; return res.begin()-&gt;first; &#125; else &#123; return 1; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; for (int i = 0; i &lt; numTest; i++) &#123; std::cout &lt;&lt; solve() % mod &lt;&lt; &quot; \\n&quot;[i == numTest - 1]; &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"}]},{"title":"暑假集训 Nowcoder 多校 Round 2","slug":"暑假集训 Nowcoder 多校 Round 2","date":"2023-07-24T15:35:44.000Z","updated":"2023-07-29T06:28:31.930Z","comments":true,"path":"2023/07/24/暑假集训 Nowcoder 多校 Round 2/","link":"","permalink":"http://example.com/2023/07/24/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20Nowcoder%20%E5%A4%9A%E6%A0%A1%20Round%202/","excerpt":"","text":"比赛链接 E 「Square」 枚举 \\(k\\) ，然后二分查找即可。 时间复杂度：\\(O(logn)\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using i64 = long long;i64 pow10[19];void init() &#123; pow10[0] = 1; for (int i = 1; i &lt; 19; i++) pow10[i] = 10ll * pow10[i - 1];&#125;void solve() &#123; i64 x; std::cin &gt;&gt; x; for (int k = 0; k &lt; 19; k++) &#123; i64 left = 0, right = 1000000000ll; while (left &lt;= right) &#123; i64 mid = (left + right) / 2; i64 prefix = mid * mid / pow10[k]; if (prefix &lt; x) &#123; left = mid + 1; &#125; else if (prefix &gt; x) &#123; right = mid - 1; &#125; else &#123; std::cout &lt;&lt; mid &lt;&lt; &#x27;\\n&#x27;; return; &#125; &#125; &#125; std::cout &lt;&lt; -1 &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); init(); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; F 「Link with Chess Game」 这是一道典型的二分图博弈问题，对于三元组 \\((r, b, g)\\) ，我们可以看成边长为 \\(n\\) 的立方体的坐标，对于 \\(n\\) 为偶数的情况，任意一个初始状态都是最大匹配的必要点，若 \\(n\\) 为奇数，则只要 \\(r_0 + b_0 + g_0\\) 为偶数，则该初始状态为最大匹配点必要点。 综上所示，\\(n\\) 为偶数或者 \\(r_0 + b_0 + g_0\\) 为偶数时，先手必胜。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920#include &lt;iostream&gt;void solve() &#123; int n, r, b, g; std::cin &gt;&gt; n &gt;&gt; r &gt;&gt; b &gt;&gt; g; if (n % 2 == 0 || (r + b + g) % 2 == 0) &#123; std::cout &lt;&lt; &quot;Alice\\n&quot;; &#125; else &#123; std::cout &lt;&lt; &quot;Bob\\n&quot;; &#125;&#125;int main() &#123; int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; G 「Link with Centrally Symmetric Strings」 这题需要一些前置知识：Manacher 算法","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Nowcoder","slug":"Nowcoder","permalink":"http://example.com/tags/Nowcoder/"},{"name":"Manacher","slug":"Manacher","permalink":"http://example.com/tags/Manacher/"}]},{"title":"最优终止策略 —— 为什么是 37%？","slug":"最优终止策略","date":"2023-07-20T16:01:03.000Z","updated":"2023-07-22T08:48:05.022Z","comments":true,"path":"2023/07/21/最优终止策略/","link":"","permalink":"http://example.com/2023/07/21/%E6%9C%80%E4%BC%98%E7%BB%88%E6%AD%A2%E7%AD%96%E7%95%A5/","excerpt":"","text":"见好就收。 描述 考虑一个问题：假设现在有若干件同类型商品，每件商品的质量都不一样且商品质量等可能分布，我们在看到商品前不知道商品的质量，且在看商品时无法回退到上一个商品，接下来要从这些商品中挑选一件商品。现在考虑如下策略： 如果有 \\(n\\) 件商品，我们先依次看前 \\(k\\ (k \\leq n)\\) 件商品，不论商品质量如何，都将其舍弃，在随后的 \\(n - k\\) 件商品中如果出现了质量比前 \\(k\\) 件商品质量更好的商品，那就选择该商品，请问选择 \\(k\\) 为多少，可以最大化我们选择到质量最好的商品的概率呢？ 假设第 \\(i\\) 件商品的质量最高，则要选择该商品，则需要保证前 \\(i - 1\\) 个商品的质量最大值在前 \\(k\\) 件商品，所以若该商品被选中的概率为 \\(\\frac{k}{i - 1}\\)， 因此，第 \\(i\\) 件商品被选择的概率为 \\(\\frac{k}{i - 1}\\) ，又由于商品质量分布是均匀的，所有质量最高的商品等可能出现在每一个 \\(i\\ (1 \\leq i \\leq n)\\)。综上所述，选择到最高质量 \\(P_k\\) 的商品的概率为： \\[ P_k = \\sum_{i = k + 1} ^ n \\frac{k}{i - 1} \\frac{1}{n} \\] 当 \\(n\\) 足够大时，\\(\\sum_{i = k + 1} ^ n \\frac{1}{i - 1}\\) 可以近似看作 \\(ln(n) - ln(k)\\) ，所以有： \\[ P_k \\approx \\frac{k}{n} (ln(n) - ln(k)) \\] 对 \\(k\\) 求导，可得： \\[ \\frac{\\partial P_k}{\\partial k} = \\frac{ln(\\frac{n}{e}) - ln(k)}{n} \\] 可知，当 \\(k \\approx [\\frac{n}{e}]\\) 时，\\(P_k\\) 取得最大值。 换言之，当 \\(\\frac{k}{n}\\) 近似等于自然常数 \\(\\frac{1}{e}\\) 的时候 \\(P_k\\) 取得最大值。事实上，\\(\\frac{1}{e}\\) 在数值上约等于 0.36787944117144233，近似等于 0.37，这也是我们经常说的 37% 法则。 历史 这个问题可以追溯到到上世纪 60 年代，当时美国杂志《科学美国人》提出了几个趣味数学问题，其中之一是秘书问题。假如你需要聘请一个秘书，你依次面试多个候选人，每面试一个人后，你要立刻决定是否聘用她，如果放弃她，她就会去其他公司工作，可能她是最优人选，但是你错过了她，如果录用她，你就不会再面试后面的人选，可能会错过后面更好的人选。那么什么时候停止，才能选到最佳人选呢？ 目前已知的第一个提出 37% 法则的是数学家弗拉德。他发现 37% 是最佳选择的一个分割点，当有 N 个候选人时，前 37% 的人面试时，不做决策，找出最优的一位，后面每面试一位，就和前面最优的这位比较，如果劣于她，就面试下一位，如果优于，就选择当前人选，停止面试。 37% 法则在生活中十分常见，它经常出现在各式各样的统计学问题和决策问题上，其描述了一种选择策略上的最优化理论，可以帮我们解决一些日常的决策纠结，37% 法则让我们在面对不确定时，尽可能获取到一个较好的结果。","categories":[{"name":"数学","slug":"数学","permalink":"http://example.com/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"http://example.com/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"37% 法则","slug":"37-法则","permalink":"http://example.com/tags/37-%E6%B3%95%E5%88%99/"}]},{"title":"暑假集训 杭电多校 Round 2","slug":"暑假集训 杭电多校 Round 2","date":"2023-07-20T11:30:32.000Z","updated":"2023-09-02T10:45:33.978Z","comments":true,"path":"2023/07/20/暑假集训 杭电多校 Round 2/","link":"","permalink":"http://example.com/2023/07/20/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1%20Round%202/","excerpt":"","text":"比赛链接 补题链接 「1009」 String Problem 签到题，求出连续段字符的数量，字符串长度减去该数量就是答案。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 123456789101112131415161718192021222324#include &lt;iostream&gt;void solve() &#123; std::string str; std::cin &gt;&gt; str; int dn = 1; for (int i = 1, len = str.size(); i &lt; len; i++) &#123; if (str[i] != str[i - 1]) dn++; &#125; std::cout &lt;&lt; str.size() - dn &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1002」 Binary Number 签到题，简单分类讨论即可。但要注意细节，各种情况都需要考虑到。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using i64 = long long;void solve() &#123; int n; i64 k; std::string str; std::cin &gt;&gt; n &gt;&gt; k &gt;&gt; str; int p = 0; i64 k0 = k; while (k) &#123; while (p &lt; n &amp;&amp; str[p] == &#x27;1&#x27;) p++; if (p == n) &#123; if (k &amp; 1) &#123; if ((n == 1 &amp;&amp; str[0] == &#x27;1&#x27;) || (k == k0 &amp;&amp; k == 1)) &#123; str[n - 1] = &#x27;0&#x27;; &#125; break; &#125; break; &#125; else &#123; int i; for (i = p; i &lt; n &amp;&amp; str[i] == &#x27;0&#x27;; i++) str[i] = &#x27;1&#x27;; // str[i] == &#x27;0&#x27; p = i; k--; &#125; &#125; std::cout &lt;&lt; str &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1004」 Card Game 数学题，由题意可得 \\(f(n) = 2 f(n - 1) + 1\\) ，又因为 \\(f(1) = 0\\) ，所以有： \\[ f(n) = 2 ^ {n - 1} - 1 \\] 使用快速幂求出答案即可。 时间复杂度：\\(O(logn)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;const int mod = 998244353;int quickPow(int x, int n) &#123; int res = 1; while (n) &#123; if (n &amp; 1) res = 1ll * res * x % mod; x = 1ll * x * x % mod; n &gt;&gt;= 1; &#125; return res;&#125;void solve() &#123; int n; std::cin &gt;&gt; n; std::cout &lt;&lt; quickPow(2, n - 1) - 1 &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1007 」 foreverlasting and fried-chicken 有一说一，比赛的时候这题给我看饿了（正好碰上疯狂星期四）。 枚举全部不同的两个节点，一个作为炸鸡的头，一个作为炸鸡的尾，假设两个节点共同一步可达的节点数为 \\(cnt\\)，则炸鸡的躯干一共有 \\(C_{cnt} ^ 4\\) 种取法，对于炸鸡尾部的两个节点，将从与尾部节点相邻的其余节点中选取，一共 \\(C_{x - 4} ^ 2\\) 中取法（\\(x\\) 在这里表示与尾部节点相邻且不为头节点的节点数），最后枚举求和即可，时间复杂度为 \\(O(n ^ 3)\\) ，对于题目的数据量而言是会超时的，所以这里考虑 bitset 优化。 时间复杂度：\\(O(\\frac{n ^ 3}{w})\\) 空间复杂度：\\(O(n ^ 2)\\) bitset 讲解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;#include &lt;bitset&gt;#define MAX_N 1005using i64 = long long;const int mod = 1000000007;inline int c2(int n) &#123; if (n &lt; 2) return 0; return (i64)n * (n - 1) / 2 % mod;&#125;inline int c4(int n) &#123; if (n &lt; 4) return 0; return (i64)n * (n - 1) * (n - 2) * (n - 3) / 24 % mod;&#125;std::bitset&lt;MAX_N&gt; g[MAX_N];void solve() &#123; int n, m; std::cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) g[i].reset(); for (int i = 0, x, y; i &lt; m; i++) &#123; std::cin &gt;&gt; x &gt;&gt; y; x--, y--; g[x][y] = g[y][x] = 1; &#125; int res = 0; for (int i = 0; i &lt; n - 1; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; int cnt_i = g[i].count(); int cnt_j = g[j].count(); int cnt_and = (g[i] &amp; g[j]).count(); if (g[i][j]) &#123; cnt_i--, cnt_j--; &#125; res = (res + (i64)c4(cnt_and) * (c2(cnt_i - 4) + c2(cnt_j - 4))) % mod; &#125; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1011」SPY finding NPY 典中典结论，若前 \\(k\\) 个不选择，则选择到 IQ 最高的对象的概率为 \\(\\sum_{i = k + 1} ^ n \\frac{1}{i - 1} \\frac{k}{n}\\) 。当 \\(n\\) 足够大的的时候，\\(k\\) 大概等于 \\([\\frac{n}{e}]\\) ，考虑到可能会存在误差，所以还需要在此基础上将 \\(k\\) 左右微调。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 在这里时间和空间的开销主要都在预处理上。 最优终止策略讲解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;cmath&gt;#define MAX_N 10005double div_num[MAX_N];const double e = exp(1);void preProcess() &#123; for (int i = 2; i &lt; MAX_N; i++) &#123; div_num[i] = 1.0 / (i - 1); &#125; for (int i = 1; i &lt; MAX_N - 1; i++) &#123; div_num[i] += div_num[i - 1]; &#125;&#125;inline double prob(int n, int k) &#123; if (k == 0) &#123; return 1.0 / n; &#125; return (div_num[n] - div_num[k]) * k / n;&#125;void solve() &#123; int n; std::cin &gt;&gt; n; int k = (int)((n + 0.5) / e); while (k &gt; 0 &amp;&amp; prob(n, k - 1) &gt; prob(n, k)) k--; while (k &lt; n &amp;&amp; prob(n, k + 1) &gt; prob(n, k)) k++; std::cout &lt;&lt; k &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); preProcess(); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 「1001」Alice Game 我们假设一段长度为 \\(x\\) 的序列的 \\(SG\\) 值为 \\(sg(x)\\) ，若 \\(x &lt;= k\\) ，则先手可以且只能一次将序列全部删除，此时，\\(sg(x) = 1\\) ，若 \\(x &gt; k\\) ，删除长度为 \\(k\\) 的序列后还剩两段不相连的序列，且两段序列互不影响，这事实上就是一种 Nim 游戏，此时有 \\(sg(x) = \\underset{i &gt; 0\\ \\land\\ n - k - i &gt; 0}{mex} \\{ sg(i) \\oplus sg(n - k - i) \\}\\) ，这里的 \\(\\oplus\\) 表示异或。 这样我们就可以求出 \\(sg(n)\\) 的值来判断先手是必胜还是必败了，但对于每一个 \\(k\\) 和 \\(n\\) 都求一次 \\(sg(n)\\) 的话时间开销过大，所以我们考虑打表找规律： 123k = 2: 0 3 13 23 33 43 ...k = 3: 0 4 18 32 46 60 ...k = 4: 0 5 23 41 59 77 ... 以上为不同的 \\(k\\) 满足 \\(sg(n) = 0\\) 的 \\(n\\) 的取值。 不难发现，必败点 \\(n\\) 在 \\(n &gt; 0\\) 的时候构成首项为 \\(k + 1\\) ，公差为 \\(4k + 2\\) 的等差数列。 因此可以大胆估计，当且仅当 \\(n = 0\\) 或者 \\(n \\equiv k + 1\\ (mod\\ 4k + 2)\\) 的时候先手必败，否则先手必胜。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021#include &lt;iostream&gt;void solve() &#123; int k, n; std::cin &gt;&gt; k &gt;&gt; n; bool ans = (n != 0 ? n % (4 * k + 2) != k + 1 : false); std::cout &lt;&lt; (ans ? &quot;Alice&quot; : &quot;Bob&quot;) &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; 至于这个结论怎么证明，就不得而知了（ACM 要什么证明）。 如果读者感兴趣可以自己试试。","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"},{"name":"bitset","slug":"bitset","permalink":"http://example.com/tags/bitset/"}]},{"title":"暑假集训 杭电多校 Round 1","slug":"暑假集训 杭电多校 Round 1","date":"2023-07-18T13:03:26.000Z","updated":"2023-07-26T15:18:10.514Z","comments":true,"path":"2023/07/18/暑假集训 杭电多校 Round 1/","link":"","permalink":"http://example.com/2023/07/18/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1%20Round%201/","excerpt":"","text":"暑假集训第一次杭电多校。 题目链接 I 「Assertion」 签到题，知道抽屉原理就行了。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021222324#include &lt;iostream&gt;void solve() &#123; int n, m, d; std::cin &gt;&gt; n &gt;&gt; m &gt;&gt; d; if (d &lt;= (m + n - 1) / n) &#123; std::cout &lt;&lt; &quot;Yes\\n&quot;; &#125; else &#123; std::cout &lt;&lt; &quot;No\\n&quot;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; E 「Cyclically Isomorphic」 判断两个字符串 str1 和 str2 是否符合 \"Cyclically Isomarphic\" 的性质，只需要判断 str2 是否是 str1 + str1 的子串即可。 时间复杂度：\\(O(Qm)\\)（重复的查询不计入） 空间复杂度：\\(O(nm)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;map&gt;void solve() &#123; int n, m, q; std::cin &gt;&gt; n &gt;&gt; m; std::vector&lt;std::string&gt; arr(n); std::vector&lt;std::string&gt; pat(n); for (int i = 0; i &lt; n; i++) &#123; std::string str; std::cin &gt;&gt; str; arr[i] = str; pat[i] = str + str; &#125; std::map&lt;std::pair&lt;int, int&gt;, bool&gt; res; std::cin &gt;&gt; q; for (int i = 0, x, y; i &lt; q; i++) &#123; std::cin &gt;&gt; x &gt;&gt; y; x--; y--; if (x &gt; y) &#123; int tmp = x; x = y; y = tmp; &#125; if (res.find(&#123;x, y&#125;) == res.end()) &#123; res[&#123;x, y&#125;] = pat[x].find(arr[y]) != std::string::npos; &#125; std::cout &lt;&lt; (res[&#123;x, y&#125;] ? &quot;Yes\\n&quot; : &quot;No\\n&quot;); &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; B 「City Upgrading」 树上 DP，选定一个根节点，从叶节点向上 DP，状态转移方程还是比较好想的，如果父节点没有被选取，则至少要有一个子节点被选取。 若父节点被选取，则子节点的子树必须都被覆盖。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using i64 = long long;const i64 inf = 0x7f7f7f7f7f7fll;class Solution &#123;private: std::vector&lt;int&gt; cost; std::vector&lt;std::vector&lt;int&gt;&gt; g; std::vector&lt;std::vector&lt;i64&gt;&gt; dp; // dp[i] 表示 i 以及其子树覆盖的最小花费 // dp[i][0] 表示不选择 i // dp[i][1] 表示选择 i void dfs(int x, int fa) &#123; dp[x][1] = cost[x]; for (int v : g[x]) &#123; if (v != fa) &#123; dfs(v, x); // 只需要一个子树选择父节点即可 dp[x][0] += std::min(dp[v][0], dp[v][1]); i64 res_1 = std::min(dp[v][0], dp[v][1]); // 选择儿子节点 i64 res_2 = 0; for (int sv : g[v]) &#123; if (sv != x) &#123; res_2 += std::min(dp[sv][0], dp[sv][1]); &#125; &#125; // 不选择儿子节点，则需要覆盖该儿子节点的所有孙子子树 dp[x][1] += std::min(res_1, res_2); &#125; &#125; i64 res = dp[x][0]; dp[x][0] = inf; for (int v : g[x]) &#123; // 至少一个子树选择父节点 if (v != fa) &#123; dp[x][0] = std::min(dp[x][0], res - std::min(dp[v][0], dp[v][1]) + dp[v][1]); &#125; &#125; &#125;public: void solve() &#123; int n; std::cin &gt;&gt; n; cost.resize(n); for (int i = 0; i &lt; n; i++) std::cin &gt;&gt; cost[i]; g.resize(n); for (int i = 0, x, y; i &lt; n - 1; i++) &#123; std::cin &gt;&gt; x &gt;&gt; y; x--; y--; g[x].push_back(y); g[y].push_back(x); &#125; dp.resize(n, std::vector&lt;i64&gt;(2, 0)); dfs(0, -1); std::cout &lt;&lt; std::min(dp[0][0], dp[0][1]) &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) Solution().solve(); return 0;&#125; L 「Play on Tree」 给定一颗树，两人轮流删掉一个子树，删掉最后一个节点的人输掉比赛。则叶节点的 SG 值为 0，非叶节点的 SG 值为其所有子节点的 (SG 值 + 1) 的异或和。 对于不同的根节点，可以考虑换根 DP，从而得到每一个节点作为根节点的 SG 值。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;iostream&gt;#include &lt;cstring&gt;using i64 = long long;const int MAX_N = 2e5 + 5;int first[MAX_N];struct &#123; int to; int next;&#125; edges[2 * MAX_N];int cnt = 0;void addEdge(int x, int y) &#123; edges[cnt] = &#123;y, first[x]&#125;; first[x] = cnt++;&#125;int sg1[MAX_N];int sg2[MAX_N];void dfs1(int v, int fa) &#123; sg1[v] = 0; for (int e = first[v]; e != -1; e = edges[e].next) &#123; int x = edges[e].to; if (x == fa) continue; dfs1(x, v); sg1[v] ^= (sg1[x] + 1); &#125;&#125;void dfs2(int v, int fa) &#123; // 换根 for (int e = first[v]; e != -1; e = edges[e].next) &#123; int x = edges[e].to; if (x == fa) continue; sg2[x] = ((sg2[v] ^ (sg1[x] + 1)) + 1) ^ sg1[x]; dfs2(x, v); &#125;&#125;const int mod = 1e9 + 7;int quickPow(int x, int n) &#123; int res = 1; while (n) &#123; if (n &amp; 1) res = (i64)res * x % mod; x = (i64)x * x % mod; n &gt;&gt;= 1; &#125; return res;&#125;void solve() &#123; cnt = 0; memset(first, 0xff, sizeof(first)); int n; std::cin &gt;&gt; n; for (int i = 0, x, y; i &lt; n - 1; i++) &#123; std::cin &gt;&gt; x &gt;&gt; y; x--, y--; addEdge(x, y); addEdge(y, x); &#125; dfs1(0, -1); sg2[0] = sg1[0]; dfs2(0, -1); int res = 0; for (int i = 0; i &lt; n; i++) res += sg2[i] != 0; std::cout &lt;&lt; (i64)res * quickPow(n, mod - 2) % mod &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"}]},{"title":"暑假集训 Nowcoder 多校 Round 1","slug":"暑假集训 Nowcoder 多校 Round 1","date":"2023-07-17T12:34:55.000Z","updated":"2023-07-26T15:16:19.325Z","comments":true,"path":"2023/07/17/暑假集训 Nowcoder 多校 Round 1/","link":"","permalink":"http://example.com/2023/07/17/%E6%9A%91%E5%81%87%E9%9B%86%E8%AE%AD%20Nowcoder%20%E5%A4%9A%E6%A0%A1%20Round%201/","excerpt":"","text":"第一次参加暑假集训的牛客多校，感觉还是挺难的。 比赛链接 D 「Chocolate」 签到题，只有 1 × 1 的时候 Walk Alone 会赢，其余情况均是 Kelin 赢。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 12345678910111213141516171819#include &lt;iostream&gt;void solve() &#123; int n, m; std::cin &gt;&gt; n &gt;&gt; m; if (n == 1 &amp;&amp; m == 1) &#123; std::cout &lt;&lt; &quot;Walk Alone\\n&quot;; &#125; else &#123; std::cout &lt;&lt; &quot;Kelin\\n&quot;; &#125;&#125;int main() &#123; solve(); return 0;&#125; J 「Roulette」 以 ”输-输-输-输-...-输-赢“ 为一个周期，Walk Alone 的钱只会增加 1 块，且接下来重新从 1 块开始下注。 假设有 x 块钱，且从 1 开始下注的胜率为 \\(p_x\\)，可得： \\[ p_x = (1 - \\frac{1}{2 ^ k}) p_{x + 1} \\] 其中 \\(k\\) 满足：\\(x \\in [2 ^ r - 1, 2 ^ {r + 1} - 1)\\)，接下来只要枚举区间然后使用快速幂即可。 时间复杂度：\\(O(log^2n)\\) 空间复杂度：\\(O(1)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;algorithm&gt;using i64 = long long;const i64 mod = 998244353ll;i64 quickPow(i64 x, i64 n) &#123; i64 res = 1; while (n) &#123; if (n &amp; 1) &#123; res = res * x % mod; &#125; x = x * x % mod; n &gt;&gt;= 1; &#125; return res;&#125;i64 inverse(i64 x) &#123; return quickPow(x, mod - 2);&#125;void solve() &#123; i64 n, m; std::cin &gt;&gt; n &gt;&gt; m; int k = 1; while (n &gt;= (1ll &lt;&lt; (k + 1)) - 1ll) k++; i64 res = 1ll; i64 l = n, r = std::min((1ll &lt;&lt; (k + 1)) - 1ll, n + m); i64 i2 = inverse(2); while (l &lt; n + m) &#123; i64 x = (1 - quickPow(i2, k) + mod) % mod; res = res * quickPow(x, r - l) % mod; l = r; r = std::min(((r + 1ll) &lt;&lt; 1) - 1, n + m); k++; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; solve(); return 0;&#125; K 「Subdivision」 先从从顶点 1 出发构造 BFS 树（只延伸 k 步），接下来新增顶点无非有以下两种类型： 加在非树边上的点： 对于非树边而言，无论加多少点，都不会影响到最终结果，假设在非树边 \\(&lt;x, y&gt;\\) 上加入尽可能多的点，则新增到顶点 1 的距离不超过 k 的点有 \\(2 \\times k - dist[x] - dist[y]\\) ，其中 \\(dist[v]\\) 表示 \\(v\\) 到顶点 1 的距离。 加在树边上的点： 假设存在末端节点 \\(v\\) 不与其他非树边相连，则可以延长末端节点，可新增 \\(k - dist[v]\\) 个点。 时间复杂度：\\(O(n + m)\\) 空间复杂度：\\(O(n + m)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;vector&gt;using i64 = long long;void solve() &#123; int n, m, k; std::cin &gt;&gt; n &gt;&gt; m &gt;&gt; k; std::vector&lt;std::vector&lt;int&gt;&gt; g(n); for (int i = 0, x, y; i &lt; m; i++) &#123; std::cin &gt;&gt; x &gt;&gt; y; x--; y--; g[x].push_back(y); g[y].push_back(x); &#125; std::vector&lt;int&gt; dist(n, -1); dist[0] = 0; std::queue&lt;int&gt; q; q.push(0); i64 cnt = 1ll; // 初始状态有多少距离不超过 k 的点数 std::vector&lt;int&gt; tree(n, -1); // 构造 BFS 树 tree[0] = 0; std::vector&lt;int&gt; endVertex; // BFS 树的末端节点 while (!q.empty()) &#123; int v = q.front(); q.pop(); int d = dist[v] + 1; if (d &gt; k) continue; bool tag = false; for (int x : g[v]) &#123; if (dist[x] == -1) &#123; // 未发现的点 dist[x] = d; q.push(x); cnt++; // d &lt;= k tree[x] = v; tag = true; &#125; &#125; if (!tag) endVertex.push_back(v); // 树的末端 &#125; // 加在非树边上的点 for (int i = 0; i &lt; n; i++) &#123; for (int j : g[i]) &#123; if (i &lt; j &amp;&amp; dist[i] != -1 &amp;&amp; dist[j] != -1 &amp;&amp; tree[i] != j &amp;&amp; tree[j] != i) &#123; cnt += 2ll * k - dist[i] - dist[j]; &#125; &#125; &#125; // 加在树边上的点（树的末端） for (int i : endVertex) &#123; bool tag = false; for (int j : g[i]) &#123; if (dist[i] != -1 &amp;&amp; tree[i] != j) &#123; tag = true; break; &#125; &#125; // 不存在非树边与末端连接 if (!tag &amp;&amp; i != 0) cnt += 1ll * k - dist[i]; &#125; std::cout &lt;&lt; cnt &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125; H 「Matches」 假设交换两个下标 \\(i\\) 和 \\(j\\) ，则 \\(\\sum_{k = 1} ^ n |a_k - b_k|\\) 在原来的基础上减小 \\(|a_i - b_i| + |a_j - b_j| - |a_i - b_j| - |a_j - b_i|\\) ，换言之，我们只要能最大化 \\(|a_i - b_i| + |a_j - b_j| - |a_i - b_j| - |a_j - b_i|\\) 即可。 我们将每一对 \\((a_i， b_i)\\) 划分为两类区间： \\([a_i, b_i]\\)，\\((a_i \\leq b_i)\\) \\([b_i, a_i]\\)，\\((a_i &gt; b_i)\\) 问题就转化为我们要找到两个不同的区间，使得 \\(f(i, j) = |a_i - b_i| + |a_j - b_j| - |a_i - b_j| - |a_j - b_i|\\) 的值最大。 事实上，很容易证明当区间属于同一类的时候 \\(f(i, j) \\leq 0\\) ，因此选取的两个区间只能来自不同的类，简单计算可得 \\(f(i, j)\\) 就等于两个区间相交部分的值。 所以我们只需要找到两类区间相交部分的最大值即可。 具体算法实现时可以考虑先枚举两类区间，存储到两个数组，然后分别按照区间左端点大小进行排序，同时使用两个新数组维护两类区间右端点前缀最大值，然后对任意一个区间 \\(r = [x, y]\\) ，在另一类区间数组中使用二分查找找到左区间不超过 \\(x\\) 的最大区间下标，根据前面定义的前缀数组，于是我们就得到了左区间端点不超过 \\(x\\) 的区间里右区间的最大值，通过此方式，我们可以枚举所有可能的最大区间交集。 时间复杂度：\\(O(nlogn)\\) 空间复杂度：\\(O(n)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;cmath&gt;using i64 = long long;int binary_search(const std::vector&lt;std::pair&lt;int, int&gt;&gt;&amp; r, int d) &#123; // 找到区间 r[i] 左端点不超过 d 最大 i if (r.empty()) return -1; int left = 0, right = r.size() - 1; // r[left].first &lt;= d &lt; r[right].first if (r[left].first &gt; d) return -1; if (r[right].second &lt;= d) return right; while (right - left &gt; 1) &#123; int mid = (left + right) / 2; if (r[mid].first &lt;= d) &#123; left = mid; &#125; else &#123; right = mid; &#125; &#125; return left;&#125;void solve() &#123; int n; std::cin &gt;&gt; n; std::vector&lt;int&gt; a(n); std::vector&lt;int&gt; b(n); for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; a[i]; &#125; for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; b[i]; &#125; std::vector&lt;std::pair&lt;int, int&gt;&gt; r1; std::vector&lt;std::pair&lt;int, int&gt;&gt; r2; for (int i = 0; i &lt; n; i++) &#123; if (a[i] &lt;= b[i]) &#123; r1.push_back(std::make_pair(a[i], b[i])); &#125; else &#123; r2.push_back(std::make_pair(b[i], a[i])); &#125; &#125; int n1 = r1.size(), n2 = r2.size(); std::sort(r1.begin(), r1.end()); std::sort(r2.begin(), r2.end()); std::vector&lt;int&gt; maxrb_1(n1); if (n1 &gt; 0) maxrb_1[0] = r1[0].second; for (int i = 1; i &lt; n1; i++) &#123; maxrb_1[i] = std::max(maxrb_1[i - 1], r1[i].second); &#125; std::vector&lt;int&gt; maxrb_2(n2); if (n2 &gt; 0) maxrb_2[0] = r2[0].second; for (int i = 1; i &lt; n2; i++) &#123; maxrb_2[i] = std::max(maxrb_2[i - 1], r2[i].second); &#125; i64 res = 0; for (int i = 0; i &lt; n1; i++) &#123; int j = binary_search(r2, r1[i].first); if (j == -1) continue; int l = r1[i].first; int r = std::min(r1[i].second, maxrb_2[j]); if (r &gt; l) res = std::max(res, (i64)r - l); &#125; for (int i = 0; i &lt; n2; i++) &#123; int j = binary_search(r1, r2[i].first); if (j == -1) continue; int l = r2[i].first; int r = std::min(r2[i].second, maxrb_1[j]); if (r &gt; l) res = std::max(res, (i64)r - l); &#125; i64 sum = 0; for (int i = 0; i &lt; n; i++) &#123; sum += abs((i64)a[i] - b[i]); &#125; std::cout &lt;&lt; sum - 2 * res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125; M 「Water」 一个比较典型的问题，假设存在解（\\(r\\), \\(s\\)）使得 \\(rA + sB = x\\) 则可以实现 Walk Alone 的需求，使用 exgcd 判断即可。 若不定方程存在解 \\((r, s)\\)，则答案为：\\(max\\{2(r + s), 2|r - s| - 1\\}\\) 。只需要找到使得该式最小的整数解 \\((r, s)\\) 即可。 时间复杂度：\\(O(logn)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;iostream&gt;#include &lt;climits&gt;#include &lt;cmath&gt;using i64 = long long;i64 exgcd(i64 a, i64 b, i64&amp; x, i64&amp; y) &#123; if (b == 0) &#123; x = 1, y = 0; return a; &#125; i64 g = exgcd(b, a % b, y, x); y -= (a / b) * x; return g;&#125;void solve() &#123; i64 a, b, x; std::cin &gt;&gt; a &gt;&gt; b &gt;&gt; x; i64 r, s; i64 g = exgcd(a, b, r, s); if (x % g != 0) &#123; std::cout &lt;&lt; -1 &lt;&lt; &#x27;\\n&#x27;; return; &#125; i64 c = x / g; r *= c, s *= c; // ar + bs = x i64 k1 = b / g, k2 = - a / g; auto minOp = [r, s, k1, k2](i64 t) -&gt; i64 &#123; i64 r0 = r + k1 * t; i64 s0 = s + k2 * t; if (r0 &gt;= 0 &amp;&amp; s0 &gt;= 0) &#123; return 2 * (r0 + s0); &#125; else &#123; return 2 * std::abs(r0 - s0) - 1; &#125; &#125;; i64 res = INT64_MAX; const int ran = 3; for (i64 t0 : &#123;-r / k1, -s / k2&#125;) &#123; for (i64 t = t0 - ran; t &lt;= t0 + ran; t++) &#123; res = std::min(res, minOp(t)); &#125; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Nowcoder","slug":"Nowcoder","permalink":"http://example.com/tags/Nowcoder/"}]},{"title":"深度学习鱼书学习笔记","slug":"深度学习鱼书学习笔记","date":"2023-07-10T12:55:04.000Z","updated":"2023-12-21T12:42:47.147Z","comments":true,"path":"2023/07/10/深度学习鱼书学习笔记/","link":"","permalink":"http://example.com/2023/07/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%B1%BC%E4%B9%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"如题，主要记录笔者有关于 Deep Learning 的学习笔记。","text":"神经网络介绍 从感知机到神经网络 感知机（perceptron）是美国学者 Frank Rosenblatt 在 1957 年提出的概念。 感知机可以理解成某个节点，接受一个或者多个信号，输出一个信号。在数字电路中常讨论的各种逻辑门，都可以看成感知机。 以下就是一个简单的感知机的例子： \\[ \\begin{equation} y = \\begin{cases} 0 &amp; (w_1 x_1 + w_2 x_2 \\leq 0) \\\\ 1 &amp; (w_1 x_1 + w_2 x_2 &gt; 0) \\end{cases} \\end{equation} \\] 而神经网络就是由很多层复杂的感知机组合而成的。 一般而言，神经网络由三个主要部分组成： 输入层（Input Layer） 隐藏层（Hidden Layer） 输出层（Output Layer） 一般而言，一个 \\(k\\) 层神经网络有 \\(k - 1\\) 个隐藏层。 Affine 函数 Affine 函数即对上一层节点传输数值作仿射变换，一般是所有数值的线性组合加上一个常量。 \\[ y_i = \\sum_{k = 1} ^ m w_{k, i} x_k + b_i \\] 矩阵乘法表示为： \\[ y = X W + b \\] 激活函数 激活函数（activation function）就是将输入信号转化为输出信号的函数。激活函数的作用在于决定如何来激活输入信号的总和。 下面是几种常见的激活函数： 阶跃函数 \\[ \\begin{equation} h(x) = \\begin{cases} 1 &amp; (x &gt; 0) \\\\ 0 &amp; (x \\leq 0) \\end{cases} \\end{equation} \\] 跃阶函数非常简单，输入值大于 0 时输出 1，否则输出 0。 代码实现： 123def step_function(x): return (x &gt; 0).astype(np.int) Sigmoid 函数 \\[ h(x) = \\frac{1}{1 + exp(-x)} \\] Sigmoid 函数可以将全体实数平滑映射到 \\((0, 1)\\)，在神经网络中被广泛使用。 代码实现： 123def sigmoid(x): return 1 / (1 + np.exp(-x)) 以上提及的两种激活函数都属于非线性函数，神经网络的激活函数必须使用非线性函数，如果激活函数都是线性的，那么不论神经网络有多少层，最后的激活值都是输入值的线性组合，无法发挥神经网络的作用。 ReLU 函数 \\[ \\begin{equation} h(x) = \\begin{cases} x &amp; (x &gt; 0) \\\\ 0 &amp; (x \\leq 0) \\end{cases} \\end{equation} \\] ReLU（Rectified Linear Unit）函数，即线性修正单元函数，当输入值大于 0 时输出输入值本身，否则输出 0。 代码实现： 123def relu(x): return np.maximum(0, x) 输出层设计 神经网络可以用在预测问题和分类问题上，根据我们要解决的问题可以改变输出层的激活函数。 一般而言，预测问题用恒等函数，分类问题用 Softmax 函数。 恒等函数 恒等函数会原样输出信息，不加以任何改动。一般用于像回归这样的预测问题上。 Softmax 函数 \\[ y_k = \\frac{exp(x_k)}{\\sum_{i = 1}^n exp(x_i)} \\] 不难发现，Softmax 函数处理后的向量元素和为 1，由于指数函数爆炸式增长的性质，不同元素的差异会被放大。一般用于分类问题上，使用 Softmax 函数激活输出节点后某个节点的值越大，说明输入输入该类的可能性越大。 代码实现： 1234def softmax(x): exp_x = np.exp(x) return exp_x / np.sum(exp_x) 神经网络代码实现 综上，以下给出一个简单的二层神经网络的实现： 12345678910111213141516class TwoLayersNetWork: def __init__(self, input_size, hidden_size, output_size, init_std = 0.01): self.params = &#123;&#125; self.params[&#x27;W1&#x27;] = init_std * np.random.randn(input_size, hidden_size) self.params[&#x27;b1&#x27;] = init_std * np.random.randn(hidden_size) self.params[&#x27;W2&#x27;] = init_std * np.random.randn(hidden_size, output_size) self.params[&#x27;b2&#x27;] = init_std * np.random.randn(output_size) def forward(self, x): x1 = np.dot(x, self.params[&#x27;W1&#x27;]) + self.params[&#x27;b1&#x27;] x1 = sigmoid(x1) x2 = np.dot(x1, self.params[&#x27;W2&#x27;]) + self.params[&#x27;b2&#x27;] x2 = softmax(x2) return x2 神经网络的学习 神经网络的特征就是可以从数据中学习。所谓从数据中学习，就是根据数据自动决定权重参数的值。 机器学习中，一般将数据分为训练数据和测试数据两部分来进行学习和实验，训练数据也称为监督数据，用来评价模型的泛化能力。 损失函数 损失函数（Loss Function）是用来评判神经网络性能的指标，损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等。 均方误差 均方误差（Mean Squared Error）是非常著名的损失函数，其表达式如下： \\[ E = \\frac{1}{2}\\sum_{k = 1} ^ m (y_k - t_k) ^ 2 \\] 这里 \\(y_k\\) 和 \\(t_k\\) 分别表示神经网络的输出以及正确数据，\\(m\\) 表示数据的维度。 代码实现： 123def mean_squared_error(y, t): return 1 / 2 * np.sum((y - t) ** 2) 交叉熵误差 除了均方误差之外，交叉熵误差（Cross Entropy Error）也经常被用作损失函数。交叉熵误差如下式所示： \\[ E = -\\sum_{k = 1} ^ m t_k\\ ln\\ y_k \\] 这里 \\(y_k\\) 和 \\(t_k\\) 分别表示神经网络的输出以及正确解标签，\\(m\\) 表示数据的维度。对于 \\(t_k\\) 而言，只有正确索引的值为 1，其余都为 0。交叉熵误差一般用作分类问题的损失函数。 代码实现： 1234def cross_entropy_error(y, t): delta = 1e-7 return -np.sum(t * np.log(y + delta)) 这里 delta 是一个微小量，防止出现 log(0) 的情况发生。 Mini-batch 学习 机器学习使用训练数据进行学习，其目标就是找出参数使得损失函数的值尽可能地小。因此，计算损失函数时必须把所有的训练数据作为对象。 假设有 \\(N\\) 个数据数据，那么我们就要求所有训练的损失函数的平均值： \\[ E = \\frac{1}{N} \\sum_{i = 1} ^ N loss(y ^ {(i)}, t ^ {(i)}) \\] 但如果数据量过大，会导致每轮学习的时间开销过大。所以我们考虑 mini-batch 学习，即每次从所有数据集中随机选取批量数据进行学习，每次计算该批次的数据的损失函数的平均值即可。 在具体的代码实现中，我们可以使用 NumPy 中的 np.random.choice() 来随机选取下标。 123batch_mask = np.random.choice(train_size, batch_size)x_batch = x_train[batch_mask]t_batch = t_train[batch_mask] np.random.choice(train_size, batch_size) 返回一个长度为 batch_size ，数据取值范围为 [0, train_size) 的随机正整数数组。 梯度下降法 机器学习的主要任务是在学习时寻找能使损失函数值最小的最优参数。一般而言，损失函数很复杂，参数空间庞大，很难用常规方式求解最小值。 这里我们给出梯度下降法（Gradient Descent Method）： 从数学的角度出发，函数的梯度的方向代表函数增加最快的方向，其反方向就是函数减小的最快方向，极值点梯度为 0，所以我们可以在每一轮迭代中让参数往梯度方向减小，从而找到极小值点。 123456789101112131415def numerical_gradient(f, x): &#x27;&#x27;&#x27; 数值法求解梯度下降法 &#x27;&#x27;&#x27; delta = 1e-5 grads = np.zeros_like(x) for idx, val in np.ndenumerate(x): x[idx] = val + delta f1 = f(x) x[idx] = val - delta f2 = f(x) grads[idx] = (f1 - f2) / (2 * delta) x[idx] = val return grads 每轮迭代的数学表示如下： \\[ x_i := x_i - \\eta \\frac{\\partial f}{\\partial x_i} \\] 其中，\\(\\eta\\) 称为学习率（Learning Rate），学习率决定在一次学习中，在多大程度更新参数。 如果我们采用 mini-batch 学习法每次随机选取一批次数据量，并对其损失函数平均值采用梯度下降法，这样的梯度下降我们就称为随机梯度下降（Stochastic Gradient Descent），简称 SGD。 误差反向传播法 数值法求解梯度是严格按照偏导数的定义来的，这样求解固然正确，但对于参数很大的情况下效率过低。其实有一种高效的梯度求解方法，就是误差反向传播法。 计算图 书上花了很多篇幅去讲解什么是计算图以及起作用，笔者认为计算图就是将求导的链式法则进行了一个可视化。 计算图就是通过节点和箭头表示计算过程，如下图： 链式法则和反向传播 以上面的图为例，假设我们知道了 \\(\\frac{\\partial L}{\\partial z}\\) ，根据链式法则可知： \\[ \\begin{array}{} \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\frac{\\partial z}{\\partial x} \\\\ \\frac{\\partial L}{\\partial y} = \\frac{\\partial L}{\\partial z} \\frac{\\partial z}{\\partial y} \\end{array} \\] 不难发现，对于一个计算图而言，其数值是正向传播的，而其导数则是反向传播的。 而神经网络不就恰好是一个这样层层传递的计算图吗？ 所以我们可以利用链式法则的性质快速计算梯度。 各种层的实现 下面给出各种层的反向传播的实现。 ReLU 层 通过 ReLU 激活函数的表达式，不难得出： \\[ \\begin{equation} \\frac{\\partial y}{\\partial x} = \\begin{cases} 1 &amp; (x &gt; 0) \\\\ 0 &amp; (x \\leq 0) \\end{cases} \\end{equation} \\] 代码实现： 12345678910111213141516class Relu: def __init__(self): self.mask = None def forward(self, x): self.mask = (x &lt;= 0) out = x.copy() out[self.mask] = 0 return out def backward(self, dout): dout[self.mask] = 0 dx = dout return dx Sigmoid 层 同理，我们对原式求导： \\[ \\begin{array}{} y = \\frac{1}{1 + exp(-x)} \\\\ \\frac{\\partial y}{\\partial x} = \\frac{exp(x)}{(exp(x) + 1) ^ 2} = y (1 - y) \\end{array} \\] 代码实现： 12345678910111213class Sigmoid: def __init__(self): self.out = None def forward(self, x): out = sigmoid(x) self.out = out return out def backward(self, dout): dx = dout * (1.0 - self.out) * self.out return dx Affine 层 \\[ Y = XW + b \\] 这里涉及到矩阵求导，采用分子布局，若已知 \\(\\frac{\\partial L}{\\partial y}\\)，根据链式求导法则，有： \\[ \\frac{\\partial L}{\\partial w_{i, j}} = \\sum_k \\frac{\\partial L}{\\partial y_{k, j}} \\frac{\\partial y_{k, j}}{\\partial w_{i, j}} \\] 代入： \\[ y_{k, j} = \\sum_{t} w_{t, j} x_{k, t} + b_j \\] 可得： \\[ \\frac{\\partial L}{\\partial w_{i, j}} = \\sum_k \\frac{\\partial L}{\\partial y_{k, j}} x_{k, i} \\] \\[ \\implies \\frac{\\partial L}{\\partial W} = X ^ T \\frac{\\partial L}{\\partial Y} \\] 同理，有：\\(\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} W ^ T\\) 而对于 \\(b\\) 而言，我们采取同样的方法： \\[ \\frac{\\partial L}{\\partial b_i} = \\sum_k \\frac{\\partial L}{\\partial y_{k, i}} \\frac{\\partial y_{k, i}}{\\partial b_i} = \\sum_k \\frac{\\partial L}{\\partial y_{k, i}} \\] 这说明 \\(\\frac{\\partial L}{\\partial b}\\) 就等于 \\(\\frac{\\partial L}{\\partial Y}\\) 沿列求和。 基于以上的数学证明，我们不难写出 Affine 层的代码实现： 1234567891011121314151617181920212223242526class Affine: def __init__(self, W, b): self.W = W self.b = b self.x = None self.dW = None self.db = None def forward(self, x): if x.ndim == 1: self.x = x.reshape((1, x.size)) else: self.x = x out = np.dot(self.x, self.W) + self.b return out def backward(self, dout): if dout.ndim == 1: dout = dout.reshape((1, dout.size)) dx = np.dot(dout, self.W.T) self.dW = np.dot(self.x.T, dout) self.db = np.sum(dout, axis = 0) return dx Softmax-with-Loss 层 顾名思义，Softmax-with-Loss 层就是将 Softmax 层和 Loss 函数层结合在一起，以交叉熵分析为例： 事实上，对于一个用于分类的神经网络，softmax 函数只有在学习的过程中会使用，如果只用于判断某个数据的类别，只需要找到最后一层输出层的最大值即可。而如果是在学习的过程中使用了 softmax 函数，那就意味着马上需要计算其损失函数，于是在这里我们直接将 Softmax 层和 Lost 层看成一个整体。 有意思的是将两层看做一个整体后，其偏导数相当简洁： \\[ \\frac{\\partial E}{\\partial x_i} = - \\frac{\\partial}{\\partial x_i} \\sum_k t_k\\ ln\\ \\frac{exp(x_i)}{\\sum_j exp(x_j)} = \\frac{exp(x_i)}{\\sum_j exp(x_j)} \\sum_k t_k - t_i = y_i - t_i \\] 代码实现： 1234567891011121314151617class SoftmaxWithLoss: def __init__ (self): self.y = None self.t = None def forward(self, x, t): self.t = t self.y = softmax(x) out = cross_entropy_error(self.y, t) return out def backward(self, dout = 1): batch_size = self.t.shape[0] dx = (self.y - self.t) / batch_size return dx MNIST 示例 接下来我们以 MNIST 数据集为例，展示一次完整的机器学习过程。 MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology（NIST）。训练集（training set）由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局的工作人员。测试集（test set）也是同样比例的手写数字数据。 下载 MNIST 训练集与数据预处理 123456789101112131415161718from keras.datasets import mnistfrom PIL import Imageimport numpy as npdef show_img(img): pil_img = Image.fromarray(np.uint8(img)) pil_img.show()def main(): (x_train, t_train), (x_test, t_test) = mnist.load_data() idx = 0 # 打印第一个数据的图形 show_img(x_train[idx]) print(t_train[idx]) # 5if __name__ == &#x27;__main__&#x27;: main() 直接下载的训练数据 x_train 是 (60000, 28, 28) 的三维数组，且元素是 [0, 256) 的正整数，我们要将其降维以及正规化，同时还要将监督数据转化为 one-hot 形式，因此在训练前要对数据进行预处理： 12345678def pre_process(x, t): shape = x.shape x_pro = x.reshape(shape[0], shape[1] * shape[2]) / float(255) t_pro = np.zeros((t.size, 10), dtype = np.float64) for i in range(t.size): t_pro[i, t[i]] = 1 return x_pro, t_pro 1234567(x_train, t_train), (x_test, t_test) = mnist.load_data()# 数据预处理x_train, t_train = pre_process(x_train, t_train)x_test, t_test = pre_process(x_test, t_test)print(x_train.shape) # (60000, 784)print(t_train.shape) # (60000, 10) 基于反向传播的二层神经网络实现 基于先前得到的理论，我们在此处实现一个简单的神经网络： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class TwoLayerNetWork: def __init__(self, input_size, hidden_size, output_size, init_std = 0.01): self.params = &#123;&#125; self.params[&#x27;W1&#x27;] = init_std * np.random.randn(input_size, hidden_size) self.params[&#x27;b1&#x27;] = init_std * np.random.randn(hidden_size) self.params[&#x27;W2&#x27;] = init_std * np.random.randn(hidden_size, output_size) self.params[&#x27;b2&#x27;] = init_std * np.random.randn(output_size) self.layers = OrderedDict() self.layers[&#x27;Affine1&#x27;] = Affine(self.params[&#x27;W1&#x27;], self.params[&#x27;b1&#x27;]) self.layers[&#x27;Relu1&#x27;] = Relu() self.layers[&#x27;Affine2&#x27;] = Affine(self.params[&#x27;W2&#x27;], self.params[&#x27;b2&#x27;]) self.last_layer = SoftmaxWithLoss() def predict(self, x): for layer in self.layers.values(): x = layer.forward(x) return x def loss(self, x, t): y = self.predict(x) return self.last_layer.forward(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis = 1 if y.ndim == 2 else 0) t = np.argmax(t, axis = 1 if t.ndim == 2 else 0) return np.sum(y == t) / float(y.size) def numerical_gradient(self, x, t): grads = &#123;&#125; f = lambda w : self.loss(x, t) for key in (&#x27;W1&#x27;, &#x27;b1&#x27;, &#x27;W2&#x27;, &#x27;b2&#x27;): grads[key] = numerical_gradient(f, self.params[key]) return grads def gradient(self, x, t): # forward self.loss(x, t) # backward dout = self.last_layer.backward(1) layers = list(self.layers.values()) layers.reverse() for layer in layers: dout = layer.backward(dout) grads = &#123;&#125; grads[&#x27;W1&#x27;] = self.layers[&#x27;Affine1&#x27;].dW grads[&#x27;b1&#x27;] = self.layers[&#x27;Affine1&#x27;].db grads[&#x27;W2&#x27;] = self.layers[&#x27;Affine2&#x27;].dW grads[&#x27;b2&#x27;] = self.layers[&#x27;Affine2&#x27;].db return grads 这里保留了 numerical_gradient() 方法，主要用于在训练前检测反向传播所求解的梯度是否足够准确。 以 MNIST 数据集为例，我们取前 10 个数据，计算两种梯度求法结果的平均差值： 1234567891011# gradient checkingbatch_size = 10x_batch = x_train[: batch_size]t_batch = t_train[: batch_size]nw = TwoLayerNetWork(input_size = 784, hidden_size = 50, output_size = 10)g1 = nw.gradient(x_batch, t_batch)g2 = nw.numerical_gradient(x_batch, t_batch)for key in g1.keys(): diff = np.average(np.abs(g1[key] - g2[key])) print(key + &#x27;:&#x27; + str(diff)) 控制台输出： 1234W1:3.0029986781580274e-10b1:1.889068461072459e-09W2:3.764107002402314e-09b2:6.041247907677899e-08 误差很小，说明反向传播求解梯度是可行的。 神经网络的学习与测试 我们采取 SGD 对神经网络进行训练，batch_size 设置为 100，迭代数设置为 10000，学习率设置为 0.1，同时我们记录每轮学习的损失函数以及对测试数据预测的准确率。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738def train(x_train, t_train, x_test, t_test): nw = TwoLayerNetWork(input_size = 784, hidden_size = 50, output_size = 10) train_size = x_train.shape[0] batch_size = 100 iter_num = 10000 lr = 0.1 loss_list = [] acc_list = [] for i in range(iter_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] grads = nw.gradient(x_batch, t_batch) for key in nw.params.keys(): nw.params[key] -= lr * grads[key] loss = nw.loss(x_batch, t_batch) acc = nw.accuracy(x_test, t_test) print(&#x27;iter %d, loss = %lf, acc = %lf&#x27; % (i, loss, acc)) loss_list.append(loss) acc_list.append(acc) plt.subplot(121) plt.xlabel(&#x27;iter_num&#x27;) plt.ylabel(&#x27;loss&#x27;) plt.title(&#x27;iter_num-loss&#x27;) plt.plot(np.arange(0, len(loss_list)), loss_list) plt.subplot(122) plt.xlabel(&#x27;iter_num&#x27;) plt.ylabel(&#x27;acc&#x27;) plt.title(&#x27;iter_num-acc&#x27;) plt.plot(np.arange(0, len(acc_list)), acc_list) plt.show() 结果如下图： 学习的效果总体呈现为先快后慢的趋势，损失函数逐渐趋于 0，预测准确率逐渐趋于 1。在一万次迭代后，预测准确率可以达到约 \\(97 \\%\\) 。这样，我们就完成了 MINIST 数据集的学习过程了。 神经网络学习技巧 更优的梯度下降策略 神经网络的学习目的可以概括为找到使损失函数的值尽可能小的参数。这个过程被称为最优化（Optimization）。 前几章我们讨论了随机梯度下降法（Stochastic Gradient Descent），即 SGD。 本章我们将讨论其他优化的梯度下降法。 SGD 的缺点 如果函数的形状非均向（anisotropic），收敛会很慢。 以函数 \\(f(x, y) = \\frac{1}{100} x^2 + y^2\\) 为例子，我们采取 SGD 方法求其最小值，假设初始值为 \\((-5, 2)\\)。 1234dat = np.array([-5, 2], dtype = np.float64)fun = lambda dat : 1 / 100 * dat[0] ** 2 + dat[1] ** 2for i in range(iter_num): dat -= lr * numerical_grad(fun, dat) 结果如下： 如上图所示，在 100 次迭代后仍然离极小值点 \\((0, 0)\\) 有一定距离，最后参数的移动路径近似于 Z 字形，收敛十分缓慢。 可见，随机梯度下降在本例中效率很低。从数学的层面理解，可以认为是 x 的梯度分量过小导致的。 Momentum Momentum，即动量，相当于我们给梯度下降引入了物理规则，具体算法如下： \\[ \\begin{array}{} v := \\alpha v - \\eta \\frac{\\partial L}{\\partial W} \\\\ W := W + v \\end{array} \\] \\(W\\) 表示参数，\\(v\\) 在这里是一个新的变量，用于表示速度。 \\(\\eta\\) 表示学习率，\\(\\alpha\\) 表示衰减率。不同于常规的梯度下降，动量梯度下降使用速度对参数进行更新，可以使得目标更快朝极小值点移动。 还是以刚才我们讨论的函数为例： 1234567891011121314151617class Momentum: def __init__(self, lr = 0.1, mom = 0.9): self.lr = lr self.mom = mom self.v = None def update(self, params, grads): if self.v is None: self.v = np.zeros_like(params) self.v = self.mom * self.v - self.lr * grads params += self.vfun = lambda dat : 1 / 100 * dat[0] ** 2 + dat[1] ** 2momen = Momentum(lr = 0.2)for i in range(iter_num): momen.update(dat, numerical_grad(fun, dat)) 可见，动量梯度下降路径更为平缓，且在有限次迭代中更快收敛至极小值点。 相较于 SGD，动量梯度下降为何能做到更快收敛呢？ 笔者对此是这样理解的，动量梯度下降是有记忆性的，其引入了一个变量记录参数更新速度，即使函数某个点的梯度在 x 分量上的值很小，但其在 x 分量上的速度始终是增加的，也就是在最后其依然能在 x 分量上快速收敛。而 SGD 是无记忆的，这也就意味着其更新速度只取决于当前的梯度，就容易导致收敛过慢的情况。 AdaGrad 在神经网络的学习中，学习率的选取非常重要。学习率过小，可能导致学习花费时长过多，学习率过大，可能导致学习过程无法收敛。所以我们给出 AdaGrad，即适应性调整学习率的梯度下降。 我们引入学习衰减率（Learning Rate Decay）\\(h\\) ，使得随着学习进行，学习率逐渐减小。 数学表示如下： \\[ \\begin{array}{} h := h + \\frac{\\partial L}{\\partial W} \\odot \\frac{\\partial L}{\\partial W} \\\\ W := W - \\eta \\frac{1}{\\sqrt h} \\frac{\\partial L}{\\partial W} \\end{array} \\] 还是以上述函数为例： 1234567891011121314151617class AdaGrad: def __init__(self, lr = 0.1): self.lr = lr self.h = None def update(self, params, grads): if self.h is None: self.h = np.zeros_like(params) delta = 1e-7 self.h = self.h + grads * grads params -= self.lr / np.sqrt(self.h + delta) * gradsfun = lambda dat : 1 / 100 * dat[0] ** 2 + dat[1] ** 2ada = AdaGrad(lr = 1)for i in range(iter_num): ada.update(dat, numerical_grad(fun, dat)) AdaGrad 的思路其实就是将更新过程中变化较大的参数的学习率降低，从而调整学习的尺寸。整体而言都是先快后慢，但如果无止境地学习，更新速度就会变成 0。为了改善这个问题，可以使用 RMSProp 方法。 关于权重的初始值 权重初始值是否可以设置为 0 ？ 答案是否定的，假设初始状态权重为 0，则第二层神经元会被传递相同的值，第二层神经元全部输入相同的值，这意味着反向传播时第二层的权重会进行相同的更新。这样一来，权重将会维持均一化，为了防止这种情况发生，必须随机生成初始值。 卷积神经网络 整体结构 卷积神经网络（Convolutional Nerual Network），简称 CNN 神经网络，相比于全连接神经网络，CNN 神经网络新出现了卷积（Convolution）层和池化（Pooling）层。 卷积层 卷积运算 卷积层进行的处理就是卷积运算。卷积运算相当于图像处理中的 “滤波器运算”。 如上图，卷积运算以一定间隔滑动滤波器的窗口，每次将滤波器的元素和输入的对应元素相乘然后求和，将这个结果保存到输出的对应位置，就可以得到卷积的结果。 对于 CNN 神经网络而言，卷积运算结束后一般会加上一个偏置，如下图： 填充 在进行卷积运算的处理之前，有时要向输入数据的周围填入固定的数据，比如 0 等，这就称为填充（padding）。通过合适的填充，可以保证卷积运算后的结果相对于输入空间大小不变。 步幅 应用滤波器的位置间隔称为步幅（stride），前面的例子中，滤波器的步幅都为 1，若步幅设置为 2，则滤波器每次移动 2 个像素。 假设输入大小为 \\((H, W)\\)，填充为 \\(P\\) ，步幅为 \\(S\\) ，滤波器大小为 \\((FH, FW)\\) 。 设输出大小为 \\((OH, OW)\\) ，则有： \\[ OH = \\frac{H + 2P - FH}{S} + 1 \\] \\[ OW = \\frac{W + 2P - FW}{S} + 1 \\] 三维数据的卷积运算 相对于二维数据的卷积运算，三维卷积运算除了处理长、宽之外还要处理通道方向。通道方向有多个特征图时，会按照通道进行数据和滤波器的卷积运算，然后相加。 输入数据和滤波器的通道数必须相等，输出数据会得到一张特征图，即通道数为 1 的输出数据。如果要在通道方向也拥有多个卷积运算的输出，就需要多个滤波器。 假设输入数据大小为 \\((C, H, W)\\) ，即通道数为 \\(C\\) ，高为 \\(H\\) ，宽为 \\(W\\) ；滤波器数据大小为 \\((FN, C, FH, FW)\\) ，即滤波器个数为 \\(FN\\) 个，通道数为 \\(C\\) ，高为 \\(FH\\) ，宽为 \\(FW\\) ；则输出数据的大小可以表示为 \\((FN, OH, OW)\\) ，即输出数据的通道数为滤波器的数量 \\(FN\\) 。 池化层 池化是缩小高、宽方向上空间的操作。常见的池化有 Max 池化和 Average 池化。 对于一个 \\(n \\times n\\) 的 Max 池化操作，每次选取一个 \\(n \\times n\\) 的区域，从该区域中取出最大值并记录到最终答案。一般而言，步幅和池化窗口大小会设置为同样的值。 下图演示了一个 \\(2 \\times 2\\) 的池化操作： 池化层具有以下特征： 没有需要学习的参数； 通道数不发生变化； 对微小的位置变化具有鲁棒性。 若输入数据发生微小变化时，池化仍然会返回相同的结果。例如 Max 池化，只要在池化区域内的最大值不发生变化，那么池化就可以吸收数据的偏差，仍然返回相同的结果。 卷积层和池化层的代码实现 4 维数组 由于 CNN 各层间传递的是 4 维数据，所以我们需要用 4 维数组来存储参数： 12x = np.random.rand(n, c, h, w)# 生成 n * c * h * w 的 4 维数组 im2col 技巧 如果只是按照平常的卷积运算，则会出现好几层 for 循环，十分不利于代码的书写，我们可以考虑 im2col 技巧，把输入数据按照滤波器的作用区域进行展开： 此后就可以将卷积运算汇总为一个大的矩阵乘积，而在 Numpy 库中，矩阵计算都进行过高度优化，因此我们可以实现更高效的计算。 代码实现： 1234567891011121314151617181920212223242526272829def im2col(input_data, filter_h, filter_w, stride = 1, pad = 0): &quot;&quot;&quot; Parameters ---------- input_data : 由(数据量, 通道, 高, 长)的4维数组构成的输入数据 filter_h : 滤波器的高 filter_w : 滤波器的长 stride : 步幅 pad : 填充 Returns ------- col : 2维数组 &quot;&quot;&quot; N, C, H, W = input_data.shape out_h = (H + 2 * pad - filter_h) // stride + 1 out_w = (W + 2 * pad - filter_w) // stride + 1 img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], &quot;constant&quot;) col = np.zeros((N, C, filter_h, filter_w, out_h, out_w)) for y in range(filter_h): y_max = y + stride * out_h for x in range(filter_w): x_max = x + stride * out_w col[:, :, y, x, :, :] = img[:, :, y : y_max : stride, x : x_max : stride] col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1) return col 卷积层实现 利用上述 im2col 技巧，我们就可以实现卷积层了： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Convolution: def __init__(self, W, b, stride = 1, pad = 0): self.W = W self.b = b self.stride = stride self.pad = pad # 中间数据（backward时使用） self.x = None self.col = None self.col_W = None # 权重和偏置参数的梯度 self.dW = None self.db = None def forward(self, x): FN, C, FH, FW = self.W.shape N, C, H, W = x.shape out_h = 1 + int((H + 2 * self.pad - FH) / self.stride) out_w = 1 + int((W + 2 * self.pad - FW) / self.stride) col = im2col(x, FH, FW, self.stride, self.pad) col_W = self.W.reshape(FN, -1).T out = np.dot(col, col_W) + self.b out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) self.x = x self.col = col self.col_W = col_W return out def backward(self, dout): FN, C, FH, FW = self.W.shape dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN) self.db = np.sum(dout, axis=0) self.dW = np.dot(self.col.T, dout) self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW) dcol = np.dot(dout, self.col_W.T) dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad) return dx 事实上使用 im2col 后的卷积层与 Affine 层的实现是差不多的，这里在反向传播的时候需要使用 im2col 的逆操作 col2im 来恢复数组。 池化层实现 123456789101112131415161718192021222324252627282930313233343536373839class Pooling: def __init__(self, pool_h, pool_w, stride=1, pad=0): self.pool_h = pool_h self.pool_w = pool_w self.stride = stride self.pad = pad self.x = None self.arg_max = None def forward(self, x): N, C, H, W = x.shape out_h = int(1 + (H - self.pool_h) / self.stride) out_w = int(1 + (W - self.pool_w) / self.stride) col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad) col = col.reshape(-1, self.pool_h * self.pool_w) arg_max = np.argmax(col, axis=1) out = np.max(col, axis=1) out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2) self.x = x self.arg_max = arg_max return out def backward(self, dout): dout = dout.transpose(0, 2, 3, 1) pool_size = self.pool_h * self.pool_w dmax = np.zeros((dout.size, pool_size)) dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten() dmax = dmax.reshape(dout.shape + (pool_size, )) dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1) dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad) return dx CNN 的代码实现 基于上述讨论，我们就可以实现一个完整的 CNN 神经网络了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170class SimpleConvNet: &quot;&quot;&quot;简单的ConvNet conv - relu - pool - affine - relu - affine - softmax Parameters ---------- input_size : 输入大小（MNIST的情况下为784） hidden_size_list : 隐藏层的神经元数量的列表（e.g. [100, 100, 100]） output_size : 输出大小（MNIST的情况下为10） activation : &#x27;relu&#x27; or &#x27;sigmoid&#x27; weight_init_std : 指定权重的标准差（e.g. 0.01） 指定&#x27;relu&#x27;或&#x27;he&#x27;的情况下设定“He的初始值” 指定&#x27;sigmoid&#x27;或&#x27;xavier&#x27;的情况下设定“Xavier的初始值” &quot;&quot;&quot; def __init__( self, input_dim=(1, 28, 28), conv_param=&#123;&quot;filter_num&quot;: 30, &quot;filter_size&quot;: 5, &quot;pad&quot;: 0, &quot;stride&quot;: 1&#125;, hidden_size=100, output_size=10, weight_init_std=0.01, ): filter_num = conv_param[&quot;filter_num&quot;] filter_size = conv_param[&quot;filter_size&quot;] filter_pad = conv_param[&quot;pad&quot;] filter_stride = conv_param[&quot;stride&quot;] input_size = input_dim[1] conv_output_size = ( input_size - filter_size + 2 * filter_pad ) / filter_stride + 1 pool_output_size = int( filter_num * (conv_output_size / 2) * (conv_output_size / 2) ) # 初始化权重 self.params = &#123;&#125; self.params[&quot;W1&quot;] = weight_init_std * np.random.randn( filter_num, input_dim[0], filter_size, filter_size ) self.params[&quot;b1&quot;] = np.zeros(filter_num) self.params[&quot;W2&quot;] = weight_init_std * np.random.randn( pool_output_size, hidden_size ) self.params[&quot;b2&quot;] = np.zeros(hidden_size) self.params[&quot;W3&quot;] = weight_init_std * np.random.randn(hidden_size, output_size) self.params[&quot;b3&quot;] = np.zeros(output_size) # 生成层 self.layers = OrderedDict() self.layers[&quot;Conv1&quot;] = Convolution( self.params[&quot;W1&quot;], self.params[&quot;b1&quot;], conv_param[&quot;stride&quot;], conv_param[&quot;pad&quot;], ) self.layers[&quot;Relu1&quot;] = Relu() self.layers[&quot;Pool1&quot;] = Pooling(pool_h = 2, pool_w = 2, stride = 2) self.layers[&quot;Affine1&quot;] = Affine(self.params[&quot;W2&quot;], self.params[&quot;b2&quot;]) self.layers[&quot;Relu2&quot;] = Relu() self.layers[&quot;Affine2&quot;] = Affine(self.params[&quot;W3&quot;], self.params[&quot;b3&quot;]) self.last_layer = SoftmaxWithLoss() def predict(self, x): for layer in self.layers.values(): x = layer.forward(x) return x def loss(self, x, t): &quot;&quot;&quot;求损失函数 参数x是输入数据、t是教师标签 &quot;&quot;&quot; y = self.predict(x) return self.last_layer.forward(y, t) def accuracy(self, x, t, batch_size = 100): if t.ndim != 1: t = np.argmax(t, axis=1) acc = 0.0 for i in range(int(x.shape[0] / batch_size)): tx = x[i * batch_size : (i + 1) * batch_size] tt = t[i * batch_size : (i + 1) * batch_size] y = self.predict(tx) y = np.argmax(y, axis=1) acc += np.sum(y == tt) return acc / x.shape[0] def numerical_gradient(self, x, t): &quot;&quot;&quot;求梯度（数值微分） Parameters ---------- x : 输入数据 t : 教师标签 Returns ------- 具有各层的梯度的字典变量 grads[&#x27;W1&#x27;]、grads[&#x27;W2&#x27;]、...是各层的权重 grads[&#x27;b1&#x27;]、grads[&#x27;b2&#x27;]、...是各层的偏置 &quot;&quot;&quot; loss_w = lambda w: self.loss(x, t) grads = &#123;&#125; for idx in (1, 2, 3): grads[&quot;W&quot; + str(idx)] = numerical_gradient( loss_w, self.params[&quot;W&quot; + str(idx)] ) grads[&quot;b&quot; + str(idx)] = numerical_gradient( loss_w, self.params[&quot;b&quot; + str(idx)] ) return grads def gradient(self, x, t): &quot;&quot;&quot;求梯度（误差反向传播法） Parameters ---------- x : 输入数据 t : 教师标签 Returns ------- 具有各层的梯度的字典变量 grads[&#x27;W1&#x27;]、grads[&#x27;W2&#x27;]、...是各层的权重 grads[&#x27;b1&#x27;]、grads[&#x27;b2&#x27;]、...是各层的偏置 &quot;&quot;&quot; # forward self.loss(x, t) # backward dout = 1 dout = self.last_layer.backward(dout) layers = list(self.layers.values()) layers.reverse() for layer in layers: dout = layer.backward(dout) # 设定 grads = &#123;&#125; grads[&quot;W1&quot;], grads[&quot;b1&quot;] = self.layers[&quot;Conv1&quot;].dW, self.layers[&quot;Conv1&quot;].db grads[&quot;W2&quot;], grads[&quot;b2&quot;] = self.layers[&quot;Affine1&quot;].dW, self.layers[&quot;Affine1&quot;].db grads[&quot;W3&quot;], grads[&quot;b3&quot;] = self.layers[&quot;Affine2&quot;].dW, self.layers[&quot;Affine2&quot;].db return grads def save_params(self, file_name=&quot;params.pkl&quot;): params = &#123;&#125; for key, val in self.params.items(): params[key] = val with open(file_name, &quot;wb&quot;) as f: pickle.dump(params, f) def load_params(self, file_name=&quot;params.pkl&quot;): with open(file_name, &quot;rb&quot;) as f: params = pickle.load(f) for key, val in params.items(): self.params[key] = val for i, key in enumerate([&quot;Conv1&quot;, &quot;Affine1&quot;, &quot;Affine2&quot;]): self.layers[key].W = self.params[&quot;W&quot; + str(i + 1)] self.layers[key].b = self.params[&quot;b&quot; + str(i + 1)]","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"NumPy","slug":"NumPy","permalink":"http://example.com/tags/NumPy/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Div.2 Round 882 总结","slug":"Div.2 Round 882 总结","date":"2023-07-09T07:10:00.000Z","updated":"2023-07-17T11:38:12.032Z","comments":true,"path":"2023/07/09/Div.2 Round 882 总结/","link":"","permalink":"http://example.com/2023/07/09/Div.2%20Round%20882%20%E6%80%BB%E7%BB%93/","excerpt":"","text":"比赛链接 这一场整体下来感觉难度适中，对位运算性质的考查较多，个人感觉 A、B、C 比较简单。 A 「The Man who became a God」 我们不妨假设起初所有村庄都是一个整体，那么 suspicion 的值就是所有相邻村庄的怀疑值差值的绝对值总和，Kars 对村庄进行 \\(k - 1\\) 次分割将其划分为 \\(k\\) 个部分，假设分割村庄 \\((i, i + 1)\\) ，那 suspicion 就在原来的基础上减去一个 \\(|a_i - a_{i +1}|\\) ，要得到最小的 suspicion ，换言之我们只需要找到最大的 \\(k - 1\\) 个相邻元素差值的绝对值即可。 时间复杂度：\\(O(nlogn)\\) 空间复杂度：\\(O(n)\\) 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;numeric&gt;#include &lt;cmath&gt;#define MAX_N 105int arr[MAX_N];int diff[MAX_N];void solve() &#123; int n, k; std::cin &gt;&gt; n &gt;&gt; k; for (int i = 0; i &lt; n; i++) std::cin &gt;&gt; arr[i]; for (int i = 1; i &lt; n; i++) diff[i] = abs(arr[i] - arr[i - 1]); std::sort(diff + 1, diff + n, std::greater&lt;int&gt;()); int s1 = std::accumulate(diff + 1, diff + n, 0); int s2 = std::accumulate(diff + 1, diff + k, 0); std::cout &lt;&lt; s1 - s2 &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; B 「Hamon Odyssey」 注意到，对于正整数 \\(x\\)、\\(y\\) 而言，一定有 \\(x + y \\geq x\\ \\&amp;\\ y\\)，\\((x, y) = (0, 0)\\) 时取等，因此如果合并后的有两个相邻的数不全为 0，则可以继续合并使结果严格减小。 综上所述，我们可以得到： 若所有数的数位与不为 0，那将所有数字合并为一个整体一定最小，且只能将所有数合并为一个整体时取最小值。 若所有数的数位与为 0，则考虑将数组分割为尽可能多的片段，每个片段的所有数的数位与为 0。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;void solve() &#123; int n; std::cin &gt;&gt; n; int res = 0; for (int i = 0, s = 0xffffffff, x; i &lt; n; i++) &#123; std::cin &gt;&gt; x; s &amp;= x; if (!s) &#123; s = 0xffffffff; res++; &#125; &#125; std::cout &lt;&lt; (res == 0 ? 1 : res) &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; C 「Vampiric Powers, anyone?」 不难证明每一次操作得到的数都是某段连续序列的异或值。因此本题只需要找到最大的连续异或值即可。暴力求解显然会超时，所以最开始我想的是怎么用 DP，后面发现 \\((0 \\leq a_i &lt; 2 ^ 8)\\)，也就是说所有数字只有 256 种取值，因此我们使用一个哈希表维护前缀异或即可。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(1)\\) 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;unordered_set&gt;void solve() &#123; int n; std::cin &gt;&gt; n; std::unordered_set&lt;int&gt; s; s.insert(0); for (int i = 0, r = 0, x; i &lt; n; i++) &#123; std::cin &gt;&gt; x; r ^= x; s.insert(r); &#125; int res = 0; for (int x : s) &#123; for (int y : s) &#123; res = std::max(res, x ^ y); &#125; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) solve(); return 0;&#125; D 「Professor Higashikata」 贪心策略，我们假设 \\(f(i)\\) 表示 \\(t(s)[i]\\) 对应原字符串的下标，那么最右策略就是最大化 \\(k\\) 使得 \\(s_{f(0)} = 1、s_{f(1)} = 1, ..., s_{f(k)} = 1\\)。事实上，若存在 \\(i\\) 和 \\(j\\) 满足 \\(f(i) = f(j) \\ (i &lt; j)\\) ，则可以不考虑 \\(f(j)\\) ，因为 \\(s_{f(i)}\\) 和 \\(s_{f(j)}\\) 是一样的，且下标 \\(i\\) 更靠前，若 \\(s_{f(i)} = 1\\) 则必然有 \\(s_{f(j)} = 1\\) ，所以我们只要求每个下标第一次出现的时间顺序即可，然后将其按照从早到晚进行排序，以题目的第二个输入为例： 1234567891011121314151617188 6 10100110105 62 36 85 75 86 83562525841 根据题目依次输入的区间，每个下标的出现时间顺序为 5, 6, 2, 3, 7, 8。 假设原字符串为 \\(str\\)，接下来我们只需要最大化 \\(pat = [str[5]、str[6]、str[2]、str[3]、str[7]、str[8]]\\) 的字典序，即最大化其前缀 1 的数量，其初始状态为 100010，第一次翻转了下标为 3 的字符，\\(str\\) 更新为 10111010，\\(pat\\) 更新为 100110，只需要分别将 \\(str[1]\\)、\\(str[4]\\) 和 \\(str[6]\\)、\\(str[2]\\) 交换位置即可使得 \\(pat\\) 字典序最大，共需要两次操作，不难发现，每次的最小操作数量都等于 \\(pat\\) 在 区间 \\([1, min\\{num\\_of\\_ones,\\ pat.size\\}]\\)（\\(num\\_of\\_ones\\) 表示 \\(str\\) 中有多少个 1）中 0 的个数。 综上所述，完成本题需要两个步骤： 求出每个字符串下标的出现次序。 根据出现次序构造新字符串 \\(pat\\)，每一轮更新后区间 \\([1, min\\{num\\_of\\_ones, pat.size\\}]\\) 中 0 的个数即最小操作数。这一步涉及单点修改和区间查询，可以考虑使用线段树。 时间复杂度：\\(O((n + m + q)logn)\\) 空间复杂度：\\(O(n + m)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;set&gt;class SegTree &#123;private: int n; std::vector&lt;int&gt; tree; void update(int idx, int val, int node, int start, int end) &#123; if (start == end) &#123; tree[node] = val; return; &#125; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; if (idx &lt;= mid) &#123; update(idx, val, leftNode, start, mid); &#125; else &#123; update(idx, val, rightNode, mid + 1, end); &#125; tree[node] = tree[leftNode] + tree[rightNode]; &#125; int query(int left, int right, int node, int start, int end) &#123; if (start &gt; right || end &lt; left) return 0; if (start &gt;= left &amp;&amp; end &lt;= right) return tree[node]; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; return query(left, right, leftNode, start, mid) + query(left, right, rightNode, mid + 1, end); &#125;public: SegTree(int _n): n(_n), tree(4 * _n) &#123;&#125; void update(int idx, int val) &#123; update(idx, val, 0, 0, n - 1); &#125; int query(int left, int right) &#123; return query(left, right, 0, 0, n - 1); &#125;&#125;;void solve() &#123; int n, m, q; std::cin &gt;&gt; n &gt;&gt; m &gt;&gt; q; std::string str; std::cin &gt;&gt; str; std::vector&lt;int&gt; pat; // 记录在区间内出现过的数，按照第一次出现的时间排序 std::vector&lt;int&gt; pos(n, -1); // 原字符串在 pat 串的索引，-1 表示不存在 std::vector&lt;std::pair&lt;int, int&gt;&gt; ranges; for (int i = 0, l, r; i &lt; m; i++) &#123; std::cin &gt;&gt; l &gt;&gt; r; ranges.push_back(std::make_pair(l - 1, r - 1)); &#125; std::set&lt;int&gt; s; for (int i = 0; i &lt; n; i++) s.insert(i); // s 存储没有目前出现过的数字 for (const auto&amp; r : ranges) &#123; auto iter = s.lower_bound(r.first); // *iter &gt;= r.first std::vector&lt;int&gt; toErase; // 将要删除的数字 while (iter != s.end() &amp;&amp; *iter &lt;= r.second) &#123; toErase.push_back(*iter); pat.push_back(*iter); pos[*iter] = pat.size() - 1; iter++; &#125; for (int x : toErase) &#123; s.erase(x); &#125; &#125; int np = pat.size(); SegTree st(np); for (int i = 0; i &lt; np; i++) st.update(i, str[pat[i]] == &#x27;1&#x27;); int cntOne = 0; // 1 的数量 for (char ch : str) cntOne += ch == &#x27;1&#x27;; for (int i = 0, p; i &lt; q; i++) &#123; std::cin &gt;&gt; p; int idx = pos[p - 1]; // 对应的 pat 串下标 if (str[p - 1] == &#x27;1&#x27;) &#123; str[p - 1] = &#x27;0&#x27;; cntOne--; if (idx != -1) st.update(idx, 0); &#125; else &#123; str[p - 1] = &#x27;1&#x27;; cntOne++; if (idx != -1) st.update(idx, 1); &#125; int d = std::min(np, cntOne); std::cout &lt;&lt; d - st.query(0, d - 1) &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"http://example.com/tags/Codeforces/"},{"name":"Div.2","slug":"Div-2","permalink":"http://example.com/tags/Div-2/"},{"name":"贪心算法","slug":"贪心算法","permalink":"http://example.com/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"前缀异或","slug":"前缀异或","permalink":"http://example.com/tags/%E5%89%8D%E7%BC%80%E5%BC%82%E6%88%96/"},{"name":"线段树","slug":"线段树","permalink":"http://example.com/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"}]},{"title":"哈尔滨避暑记","slug":"哈尔滨避暑记","date":"2023-07-05T15:38:31.000Z","updated":"2023-09-06T17:24:50.979Z","comments":true,"path":"2023/07/05/哈尔滨避暑记/","link":"","permalink":"http://example.com/2023/07/05/%E5%93%88%E5%B0%94%E6%BB%A8%E9%81%BF%E6%9A%91%E8%AE%B0/","excerpt":"","text":"4 号晚上到哈尔滨的火车，本想着睡一觉起来就到了，奈何卧铺实在是睡得不舒服，又挤又热，半夜还有个哥们抖音外放，显然晚上是睡不着了，就这样熬了一晚上，次日凌晨终于到了哈尔滨站。 中央大街 我们的酒店离中央大街只有不到两百米的距离，而许多景区又都是辐射性分布在中央大街附近的，故颇为便利。 中央大街街景，一股浓浓的俄式风格 工艺品商店一角的俄罗斯套娃 中央大街有一处很显眼的拜占庭风建筑，那便是坐落于索菲亚广场的圣 · 索菲亚教堂，现在已经完全对游客开放了。 再来说下这个俄餐，都是硬菜，量还不小，只能说很符合我对战斗民族的想象。😆 然后就是推荐品尝一下这里的鲜酿格瓦斯（到处都有），有一股独特的清香和甘甜，毕竟离原产地更近，那肯定也更正宗一些。 沿江夜骑 731 罪证陈列馆","categories":[{"name":"日常","slug":"日常","permalink":"http://example.com/categories/%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"哈尔滨","slug":"哈尔滨","permalink":"http://example.com/tags/%E5%93%88%E5%B0%94%E6%BB%A8/"}]},{"title":"Educational Div.2 Round 151 总结","slug":"Educational Div.2 Round 151 总结","date":"2023-07-01T03:08:48.000Z","updated":"2023-07-10T08:11:07.990Z","comments":true,"path":"2023/07/01/Educational Div.2 Round 151 总结/","link":"","permalink":"http://example.com/2023/07/01/Educational%20Div.2%20Round%20151%20%E6%80%BB%E7%BB%93/","excerpt":"","text":"比赛链接 A 「Forbidden Integer」 这个没啥好说的，分类讨论一下就行。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;void solve() &#123; int n, k, x; std::cin &gt;&gt; n &gt;&gt; k &gt;&gt; x; if (x != 1) &#123; std::cout &lt;&lt; &quot;YES\\n&quot; &lt;&lt; n &lt;&lt; &#x27;\\n&#x27;; for (int i = 0; i &lt; n; i++) std::cout &lt;&lt; 1 &lt;&lt; &quot; \\n&quot;[i == n - 1]; return; &#125; // x == 1 if (k == 1) &#123; std::cout &lt;&lt; &quot;NO\\n&quot;; return; &#125; if (k == 2) &#123; if (n &amp; 1) &#123; std::cout &lt;&lt; &quot;NO\\n&quot;; return; &#125; else &#123; std::cout &lt;&lt; &quot;YES\\n&quot; &lt;&lt; n / 2 &lt;&lt; &#x27;\\n&#x27;; for (int i = 0; i &lt; n; i += 2) &#123; std::cout &lt;&lt; 2 &lt;&lt; &quot; \\n&quot;[i == n - 2]; &#125; return; &#125; &#125; // k &gt;= 3 if (n == 1) &#123; std::cout &lt;&lt; &quot;NO\\n&quot;; return; &#125; // n &gt;= 2 std::cout &lt;&lt; &quot;YES\\n&quot; &lt;&lt; n / 2 &lt;&lt; &#x27;\\n&#x27;; while (n) &#123; if (n &amp; 1) &#123; n -= 3; std::cout &lt;&lt; 3 &lt;&lt; &quot; \\n&quot;[n == 0]; &#125; else &#123; n -= 2; std::cout &lt;&lt; 2 &lt;&lt; &quot; \\n&quot;[n == 0]; &#125; &#125;&#125;int main() &#123; int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125; B 「Come Together」 这个也没啥好说的，只需要看 B、C 和 A 的相对位置然后分类讨论一下即可。 时间复杂度：\\(O(1)\\) 空间复杂度：\\(O(1)\\) 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;cmath&gt;using i64 = long long;void solve() &#123; int xa, ya, xb, yb, xc, yc; std::cin &gt;&gt; xa &gt;&gt; ya &gt;&gt; xb &gt;&gt; yb &gt;&gt; xc &gt;&gt; yc; xb -= xa, xc -= xa; yb -= ya, yc -= ya; int res = 1; bool same_x = (i64)xb * xc &gt;= 0; bool same_y = (i64)yb * yc &gt;= 0; if (same_x) &#123; // xb xc 同号 if (same_y) &#123; res += std::min(abs(xb), abs(xc)) + std::min(abs(yb), abs(yc)); &#125; else &#123; res += std::min(abs(xb), abs(xc)); &#125; &#125; else &#123; // xb xc 异号 if (same_y) &#123; res += std::min(abs(yb), abs(yc)); &#125; &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125; C 「Strong Password」 考虑贪心策略，每一次从限定条件中选取最晚在 database string 中出现的字符，这样可以尽可能快地消耗掉 database string 的前缀，如果中途出现了后缀中不存在的限定条件内的字符，则说明存在答案，反之说明不存在。 为了记录 database string 所有后缀中字符的出现时间，我们需要一个数组来维护每个后缀所有字符出现的最小索引。 时间复杂度：\\(O(nm)\\) 空间复杂度：\\(O(nm)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;vector&gt;#define INF 0x7f7f7f7fvoid solve() &#123; std::string dat; std::cin &gt;&gt; dat; int n; std::cin &gt;&gt; n; std::string l, r; std::cin &gt;&gt; l &gt;&gt; r; int len = dat.size(); // 记录区间 [i, len - 1] 中每个数出现的最早下标 std::vector&lt;std::vector&lt;int&gt;&gt; nextIdx(len + 1); nextIdx.back() = std::vector&lt;int&gt;(10, INF); for (int i = len - 1; i &gt;= 0; i--) &#123; nextIdx[i] = nextIdx[i + 1]; nextIdx[i][dat[i] - &#x27;0&#x27;] = i; &#125; int p = 0; for (int i = 0; i &lt; n; i++) &#123; p = *std::max_element(nextIdx[p].begin() + l[i] - &#x27;0&#x27;, nextIdx[p].begin() + r[i] - &#x27;0&#x27; + 1) + 1; // 找到最晚出现的数字 if (p &gt;= INF) &#123; // 出现无法找到的数字 std::cout &lt;&lt; &quot;YES\\n&quot;; return; &#125; &#125; std::cout &lt;&lt; &quot;NO\\n&quot;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"http://example.com/tags/Codeforces/"},{"name":"Div.2","slug":"Div-2","permalink":"http://example.com/tags/Div-2/"},{"name":"贪心算法","slug":"贪心算法","permalink":"http://example.com/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"},{"name":"分类讨论","slug":"分类讨论","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E8%AE%A8%E8%AE%BA/"}]},{"title":"CodeTon Round 5 总结","slug":"CodeTon Round 5 总结","date":"2023-06-28T13:08:28.000Z","updated":"2023-07-10T08:11:25.574Z","comments":true,"path":"2023/06/28/CodeTon Round 5 总结/","link":"","permalink":"http://example.com/2023/06/28/CodeTon%20Round%205%20%E6%80%BB%E7%BB%93/","excerpt":"","text":"比赛链接 这一场打得一般，因为太困了。😢 A 「Tenzing and Tsondu」 水题，易证总和高的人必胜，总和相等则平局。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(1)\\) 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using i64 = long long;void solve() &#123; int n, m; std::cin &gt;&gt; n &gt;&gt; m; i64 sum_1 = 0, sum_2 = 0; for (int i = 0, x; i &lt; n; i++) &#123; std::cin &gt;&gt; x; sum_1 += x; &#125; for (int i = 0, x; i &lt; m; i++) &#123; std::cin &gt;&gt; x; sum_2 += x; &#125; if (sum_1 &gt; sum_2) &#123; std::cout &lt;&lt; &quot;Tsondu\\n&quot;; &#125; else if (sum_1 &lt; sum_2) &#123; std::cout &lt;&lt; &quot;Tenzing\\n&quot;; &#125; else &#123; std::cout &lt;&lt; &quot;Draw\\n&quot;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125; B 「Tenzing and Books」 根据题意，如果某本书的 knowledge 某个 bit 位为 1 而 x 在该位为 0，即满足 knowledge &amp; ~x 非 0，则该书一定不能选取，根据栈的性质，该书以下的书也不能选取。 而或运算对于 3 个栈的操作顺序本身而言没有影响，所以我们依次遍历每个栈即可，如果遍历过程中出现不能选择的书，那么就结束该轮循环，进入下一个栈，3 轮循环中如果出现某个状态等于 x ，则说明可以使得 knowledge 的值等于 x ，若 3 轮循环结束后都没有得到目标答案，则说明无法使得 knowledge 的值等于 x 。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#define MAX_N 100005int stk[3][MAX_N];void solve() &#123; int n, x; std::cin &gt;&gt; n &gt;&gt; x; for (int i = 0; i &lt; 3; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; std::cin &gt;&gt; stk[i][j]; &#125; &#125; int mask = ~x, ans = 0; if (x == 0) &#123; std::cout &lt;&lt; &quot;Yes\\n&quot;; return; &#125; for (int i = 0; i &lt; 3; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (stk[i][j] &amp; mask) break; ans |= stk[i][j]; if (ans == x) &#123; std::cout &lt;&lt; &quot;Yes\\n&quot;; return; &#125; &#125; &#125; std::cout &lt;&lt; &quot;No\\n&quot;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125; C 「Tenzing and Balls」 若存在 \\(i、 j、 m、 n\\) 使得 \\(a_i = a_j\\) 且 \\(a_m = a_n\\) ，则考虑区间 \\([i, j]\\) 和 \\([m, n]\\) ： 若两个区间无交集，则两个区间都可以删除且互不影响； 若两个区间是包含关系，不妨设 \\([i, j] \\subsetneq [m, n]\\)，则 \\([i, j]\\) 只能在 \\([m, n]\\) 之前删除，而删除 \\([i, j]\\) 再删除 \\([m, n]\\) 与直接删除 \\([m, n]\\) 的效果是一样的； 若两个区间相交且不为包含关系，则只能删除其中一个区间。 综上所述，问题就变成了如何选取不相交的区间，使得选取的区间总长度最长。 我们假设 \\(dp[i]\\) 表示区间 \\([0, i]\\) 删除完后剩下来的数的最小值，\\(dp[0]\\) 初始化为 1，我们可以得到以下关系： 若不删除 \\(a_i\\) ，则 \\(dp[i] = dp[i - 1] + 1\\) 若能删除 \\(a_i\\) ，则 \\(dp[i] = \\underset{j}{min}\\ \\{dp[j]\\ |\\ j &lt; i - 1 \\land a_{j + 1} = a_i \\}\\) 于是，我们就得到了状态转移方程：\\(dp[i] = min\\{dp[i - 1] + 1,\\ \\underset{j}{min}\\ \\{dp[j]\\ |\\ j &lt; i - 1 \\land a_{j + 1} = a_i \\}\\) 而对于 \\(\\underset{j}{min}\\ \\{dp[j]\\ |\\ j &lt; i - 1 \\land a_{j + 1} = a_i \\}\\) 这一项，我们考虑使用一个数组更新每轮迭代后满足 \\(a_{j + 1} = a_i\\) 的最小 \\(dp[j]\\) 的值即可。迭代完后 \\(n - dp[n - 1]\\) 即为可删除的最大数量。 时间复杂度：\\(O(n)\\) 空间复杂度：\\(O(n)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;cstring&gt;#define MAX_N 200005int arr[MAX_N];int dp[MAX_N]; // 最少剩多少个int memo[MAX_N]; // memo[t] 表示满足 arr[j + 1] == t 的所有数里面 dp[j] 的最小值void solve() &#123; int n; std::cin &gt;&gt; n; for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; arr[i]; dp[i] = i + 1; &#125; memset(memo + 1, 0x7f, n * sizeof(int)); memo[arr[0]] = 0; for (int i = 1; i &lt; n; i++) &#123; dp[i] = std::min(dp[i - 1] + 1, memo[arr[i]]); memo[arr[i]] = std::min(memo[arr[i]], dp[i - 1]); &#125; std::cout &lt;&lt; n - dp[n - 1] &lt;&lt; &#x27;\\n&#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int numTest; std::cin &gt;&gt; numTest; while (numTest--) &#123; solve(); &#125; return 0;&#125; D 「Tenzing and His Animal Friends」 题目有点抽象，大概就是说全部轮游戏中 \\(u_i\\) 和 \\(v_i\\) 的分开游戏时间总和均不超过 \\(y_i\\)，即 \\(u_i\\) 不和 \\(v_i\\) 玩的游玩时间不超过 \\(y_i\\) ，对 \\(v_i\\) 也是同理。于此同时，顶点 1 每轮游戏都要参加，顶点 n 每轮游戏都不能参加。 我们接下来将所有的限制看成一个无向图，若存在限制 \\((u_i, v_i, y_i)\\)，那么就在顶点 \\(u_i\\) 和 \\(v_i\\) 之间连接一条权重为 \\(y_i\\) 的边。 考虑以下两种情况： 若顶点 1 无法在有限步内到顶点 n，就说明顶点 1 和顶点 n 属于不同的分支，那我们每次可以和顶点 1 所在分支全部顶点一起玩，且没有时间限制。此时答案为 inf 。 若顶点 1 可以到达顶点 n，我们假设其中一条路径为 \\(&lt;1, k_1, k_2, ..., k_m, n&gt;\\) ，每个顶点的游玩时间为 \\(t_1, t_{k_1}, t_{k_2}, ..., t_{k_m}, t_n\\)。 因为顶点 1 每轮游戏都参与，所以顶点 1 游玩的时间就是总的游戏时间，因此我们只要求出 \\(t_1\\) 的最小值即可。 由于一对顶点 \\((x, y)\\) 分开的时间不超过 \\(d(x, y)\\)，我们可以得到：\\(t_x - t_y \\leq d(x, y)\\)。 所以有： \\[ \\begin{array}{} t_1 - t_{k_1} \\leq d(1, k_1) \\\\ t_{k_1} - t_{k_2} \\leq d(k_1, k_2) \\\\ ... \\\\ t_{k_m} - t_{n} \\leq d(k_m, n) \\end{array} \\] 将上式求和： \\[ \\implies t_1 - t_n \\leq d(1, k_1) + d(k_1, k_2) + ... + d(k_m, n) \\] 又因为顶点 n 不参与游戏，所以 \\(t_n = 0\\)，综上所述： \\[ t_1 \\leq d(1, k_1) + d(k_1, k_2) + ... + d(k_m, n) \\] 右式其实就是顶点 1 到顶点 n 的路径长度，换言之，游戏的时长必须小于等于所有顶点 1 到顶点 n 的路径长度。所以我们只要求出顶点 1 到顶点 n 到最短路径即可，考虑最小堆优化的 Dijkstra 算法，并用一个数组记录每次出队列的顶点。 时间复杂度：\\(O(mlog(m + n))\\) 空间复杂度：\\(O(n + m)\\) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;queue&gt;using i64 = long long;void solve() &#123; int n, m; std::cin &gt;&gt; n &gt;&gt; m; std::vector&lt;std::vector&lt;std::pair&lt;int, int&gt;&gt;&gt; g(n); for (int i = 0, u, v, y; i &lt; m; i++) &#123; std::cin &gt;&gt; u &gt;&gt; v &gt;&gt; y; u--; v--; g[u].push_back(&#123;v, y&#125;); g[v].push_back(&#123;u, y&#125;); &#125; std::vector&lt;i64&gt; dist(n, -1); std::priority_queue&lt;std::pair&lt;i64, int&gt;, std::vector&lt;std::pair&lt;i64, int&gt;&gt;, std::greater&lt;&gt;&gt; q; q.push(&#123;0, 0&#125;); std::vector&lt;i64&gt; ans; while (!q.empty()) &#123; auto [d, to] = q.top(); q.pop(); if (dist[to] != -1) continue; dist[to] = d; ans.push_back(to); if (to == n - 1) break; for (auto [nxt, w] : g[to]) &#123; q.push(&#123;d + w, nxt&#125;); &#125; &#125; if (dist[n - 1] == -1) &#123; std::cout &lt;&lt; &quot;inf\\n&quot;; return; &#125; std::cout &lt;&lt; dist[n - 1] &lt;&lt; &#x27; &#x27; &lt;&lt; ans.size() - 1 &lt;&lt; &#x27;\\n&#x27;; std::string s(n, &#x27;0&#x27;); for (int i = 1, len = ans.size(); i &lt; len; i++) &#123; s[ans[i - 1]] = &#x27;1&#x27;; std::cout &lt;&lt; s &lt;&lt; &#x27; &#x27; &lt;&lt; dist[ans[i]] - dist[ans[i - 1]] &lt;&lt; &#x27;\\n&#x27;; &#125;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); solve(); return 0;&#125;","categories":[{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"}],"tags":[{"name":"Codeforces","slug":"Codeforces","permalink":"http://example.com/tags/Codeforces/"},{"name":"Div.1","slug":"Div-1","permalink":"http://example.com/tags/Div-1/"},{"name":"Div.2","slug":"Div-2","permalink":"http://example.com/tags/Div-2/"},{"name":"DP","slug":"DP","permalink":"http://example.com/tags/DP/"},{"name":"Dijkstra","slug":"Dijkstra","permalink":"http://example.com/tags/Dijkstra/"}]},{"title":"二进制集合与状压 DP","slug":"二进制集合与状压 DP","date":"2023-06-28T03:55:33.000Z","updated":"2023-11-19T02:08:36.164Z","comments":true,"path":"2023/06/28/二进制集合与状压 DP/","link":"","permalink":"http://example.com/2023/06/28/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%9B%86%E5%90%88%E4%B8%8E%E7%8A%B6%E5%8E%8B%20DP/","excerpt":"","text":"二进制集合 二进制集合介绍 利用计算机存储数据的特点，我们可以用二进制数来表示集合。 设一个集合有 n 个元素，则可以使用一个 n bit 的数来表示该集合的所有子集，若该数字第 k 个 bit 位为 1，表示存在该元素，为 0 则说明不存在该元素。 例如，有集合：\\(U = \\{0, 1, 2, 3\\}\\)，则 1111 表示全集 \\(U\\)，0000 表示空集 \\(\\emptyset\\)，1010 表示子集 \\(\\{1, 3\\}\\)。 一般情况下，若要表示的集合元素数量较少，可以直接使用 int 或者 long long 整数来表示，若集合元素的数量大于 64，则可以考虑使用 C++ 中的 std::bitset 来表示，可以参考笔者之前的文章：std::bitset 讲解 。 二进制集合的运算 设有集合 \\(A\\) 和 \\(B\\) ，它们的二进制表示分别为 a 和 b ，则常见的集合运算规则如下： 一元运算 数学表示 二进制集合表示 集合的阶 \\(|A|\\) __builtin_popcount(a)（a 为 int 类）__builtin_popcountll(a) （a 为 long long 类）a.count() （a 为 std::bitset 类） 补集 \\(\\overline{A}\\) ~a 二元运算 数学表示 二进制集合表示 集合并 \\(A \\cup B\\) a | b 集合交 \\(A \\cap B\\) a &amp; b 集合差 \\(A - B\\) a &amp; ~b 二进制集合子集的遍历 若集合 \\(X\\) 的二进制表示为 x ，则逆序遍历 \\(X\\) 的非空子集的代码如下： 123for (auto sub = x; sub; sub = (sub - 1) &amp; x) &#123; // s 为 x 的子集&#125; 状态压缩 DP 状态压缩 DP 是一种在动态规划算法中使用的优化技巧。它主要应用于具有指数级别状态数的问题，通过将状态用一个整数表示，从而减少内存空间的使用和提高计算效率。这里所说的用一个整数表示状态，也就是上文提到的二进制集合。 典型示例 状压 + 图论 Shortest Path Visiting All Nodes 我们设 \\(dp[i][S]\\) 表示从顶点 \\(i\\) 出发，需要走完集合 \\(S\\) 包含的所有点的最小步数，不难得到状态转移方程： \\[ dp[i][S] = \\underset{&lt;i, j&gt; \\in G(V, E)}{\\text{min}}\\ dp[j][S - i] + 1 \\] 基于此，我们可以用记忆化搜索来解决问题。但由于这里面是可以走回路的，则可能出现无限递归的情况，为了解决这个问题，我们可以在递归函数中对状态 \\((i, S)\\) 进行标记（代码中是将 \\(dp[i][S]\\) 设置为一个特殊的值），保证每个状态只经过一次，这个做法显然是合理的，因为如果从顶点 \\(i\\) 出发，走了若干步回到顶点 \\(i\\) 后，需要走完的点的集合还是 \\(S\\)，则说明这若干步都没有意义，顾可以舍去。 递归出口： \\[ dp[i][S] = 0\\ \\ \\text{if}\\ S = \\{i\\} \\] 代码如下： 12345678910111213141516171819202122232425262728293031class Solution &#123;private: int dp[12][1 &lt;&lt; 12]; // dp[i][s], 起点为 i, 需要走完集合 s 所有点的最短路径 static const int inf = 0x3f3f3f3f;public: Solution() &#123; memset(dp, 0xff, sizeof(dp)); &#125; int shortestPathLength(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; int n = graph.size(); function&lt;int(int, int)&gt; dfs = [&amp;](int i, int s) -&gt; int &#123; int&amp; res = dp[i][s]; if (res &gt;= 0) return res; res = -2; // 后续不再处理 dfs(i, s), 避免无限递归 s &amp;= ~(1 &lt;&lt; i); if (s == 0) return res = 0; int ans = inf; for (int j : graph[i]) &#123; if (dp[j][s] != -2) ans = min(ans, dfs(j, s) + 1); &#125; return res = ans; &#125;; int res = inf; for (int i = 0; i &lt; n; i++) res = min(res, dfs(i, (1 &lt;&lt; n) - 1)); return res; &#125;&#125;; 状压 + 背包 Number of Ways to Wear Different Hats to Each Other 这道题是背包问题与状态压缩的结合，我们设 \\(dp[i][S]\\) 表示可以使用前 \\(i\\) 个帽子，分配人员集合为 \\(S\\) 的方案数。 对于 \\(dp[i][S]\\)，若 \\(i &gt; 0\\) 且 \\(S\\) 非空，则可以分两种情况讨论： 所有人都不戴 \\(\\text{hat}_i\\) ，一共有 \\(dp[i - 1][S]\\) 种方案 有一个人戴 \\(\\text{hat}_i\\) ，则我们从集合 \\(S\\) 中选择一个喜欢 \\(\\text{hat}_i\\) 的人 \\(j\\) 让他戴上这个帽子，找出所有符合条件的人，一共有 \\(\\sum_j dp[i - 1][S - j]\\) 种方案 将以上二者求和即可，基于此，我们可以得到状态转移方程： \\[ \\begin{equation} dp[i][S] = \\left\\{ \\begin{array}{ll} \\ \\ dp[i - 1][S] + \\sum_{j \\in S \\land i \\in \\text{hats}[j]} dp[i - 1][S - j] &amp; \\text{if}\\ \\ S \\not= \\emptyset\\ \\ \\text{and}\\ \\ i &gt; 0 \\\\ \\ \\ 1 &amp; \\text{if}\\ \\ S = \\emptyset \\\\ \\ \\ 0 &amp; \\text{if}\\ \\ |S| &gt; i \\end{array} \\right. \\end{equation} \\] 代码如下： 12345678910111213141516171819202122232425262728293031323334class Solution &#123;private: using i64 = long long; static const int MOD = 1e9 + 7; int dp[41][1 &lt;&lt; 10]; // dp[i][S] 表示可以使用前 i 个帽子，需要分配的人员集合为 S 的方案数public: Solution() &#123; memset(dp, 0x00, sizeof(dp)); &#125; int numberWays(vector&lt;vector&lt;int&gt;&gt;&amp; hats) &#123; int n = hats.size(); vector&lt;i64&gt; pref(n, 0ll); for (int i = 0; i &lt; n; i++) &#123; for (int j : hats[i]) pref[i] |= (1ll &lt;&lt; j); // 记录每个人的喜好 &#125; for (int i = 1; i &lt;= 40; i++) &#123; dp[i - 1][0] = 1; for (int mask = 1, sz = (1 &lt;&lt; n); mask &lt; sz; mask++) &#123; if (__builtin_popcountll(mask) &gt; i) continue; dp[i][mask] = dp[i - 1][mask]; // 不选择 hat_i // 选择 hat_i for (int j = 0; j &lt; n; j++) &#123; if ((mask &amp; (1 &lt;&lt; j)) &amp;&amp; (pref[j] &amp; (1ll &lt;&lt; i))) &#123; // 从当前的人员集合中找到喜欢 hat_i 的人 dp[i][mask] = ((i64)dp[i][mask] + dp[i - 1][mask ^ (1 &lt;&lt; j)]) % MOD; &#125; &#125; &#125; &#125; return dp[40][(1 &lt;&lt; n) - 1]; &#125;&#125;; 由于 \\(dp[i][:]\\) 只与 \\(dp[i - 1][:]\\) 有关，因此我们还可以考虑使用滚动数组进一步优化空间： 1234567891011121314151617181920212223242526272829303132class Solution &#123;private: using i64 = long long; static const int MOD = 1e9 + 7; int dp[1 &lt;&lt; 10]; // 滚动数组优化空间public: Solution() &#123; memset(dp, 0x00, sizeof(dp)); &#125; int numberWays(vector&lt;vector&lt;int&gt;&gt;&amp; hats) &#123; int n = hats.size(); vector&lt;i64&gt; pref(n, 0ll); for (int i = 0; i &lt; n; i++) &#123; for (int j : hats[i]) pref[i] |= (1ll &lt;&lt; j); // 记录每个人的喜好 &#125; dp[0] = 1; for (int i = 1; i &lt;= 40; i++) &#123; for (int mask = (1 &lt;&lt; n) - 1; mask; mask--) &#123; if (__builtin_popcountll(mask) &gt; i) continue; for (int j = 0; j &lt; n; j++) &#123; if ((mask &amp; (1 &lt;&lt; j)) &amp;&amp; (pref[j] &amp; (1ll &lt;&lt; i))) &#123; // 从当前人员集合中找到喜欢 hat_i 的人 dp[mask] = ((i64)dp[mask] + dp[mask ^ (1 &lt;&lt; j)]) % MOD; &#125; &#125; &#125; &#125; return dp[(1 &lt;&lt; n) - 1]; &#125;&#125;; 其他 这里给出其他的案例链接和笔者提供的 AC 代码，如果读者感兴趣可以自行尝试去完成。 Maximize Score After N Operations 参考代码： 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123;private: int gcd(int x, int y) &#123; return x ? gcd (y % x, x) : y; &#125; int g_map[14][14]; // 提前记录 gcd(i, j) int dp[1 &lt;&lt; 14]; // dp[S] 表示当前剩余点的集合为 S 可以拿到的最大得分public: Solution() &#123; memset(g_map, 0x00, sizeof(g_map)); memset(dp, 0xff, sizeof(dp)); dp[0] = 0; &#125; int maxScore(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); for (int i = 0; i &lt; n; i++) &#123; for (int j = i; j &lt; n; j++) &#123; g_map[i][j] = g_map[j][i] = gcd(nums[i], nums[j]); &#125; &#125; function&lt;int(int)&gt; dfs = [&amp;](int mask) -&gt; int &#123; if (dp[mask] != -1) return dp[mask]; int idx = 1 + (n - __builtin_popcount(mask)) / 2; // 当前游戏次数 vector&lt;int&gt; sub; for (int i = 0; i &lt; n; i++) &#123; if (mask &amp; (1 &lt;&lt; i)) sub.push_back(i); &#125; int res = 0; for (int i = 0, sz = sub.size(); i &lt; sz - 1; i++) &#123; for (int j = i + 1; j &lt; sz; j++) &#123; int x = sub[i], y = sub[j]; res = max(res, idx * g_map[x][y] + dfs(mask ^ (1 &lt;&lt; x) ^ (1 &lt;&lt; y))); &#125; &#125; return dp[mask] = res; &#125;; return dfs((1 &lt;&lt; n) - 1); &#125;&#125;; 总结 状态压缩动态规划并不是在 DP 算法本身上创新，而是给某个维度为「集合」的状态提供了一种利于计算机运算的表达方式。什么时候考虑使用状压 DP 呢？ 动态规划中的状态转移涉及到集合运算（交、并、补、差） 集合的最大阶是一个比较小的数字，即 \\(2 ^ {|S|}\\) 是计算机内存可以承受的数组大小 这种情况下，就很有可能是一个状压 DP 的问题了。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"集合","slug":"集合","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88/"}]},{"title":"NumPy 学习笔记","slug":"NumPy 学习笔记","date":"2023-06-25T11:44:47.000Z","updated":"2024-01-11T07:53:33.994Z","comments":true,"path":"2023/06/25/NumPy 学习笔记/","link":"","permalink":"http://example.com/2023/06/25/NumPy%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"NumPy（Numerical Python）是一个用于科学计算的 Python 库。它提供了高性能的多维数组对象（ndarray），以及处理这些数组的工具。NumPy 是 Python 科学计算生态系统中的核心库，被广泛用于数据分析、统计建模、图像处理、机器学习等领域。 由于 NumPy 的高性能和丰富的功能，它成为了许多科学计算和数据处理的基础库。许多其他的 Python 科学计算库，如 SciPy、 Pandas和 Scikit-learn 等，都建立在 NumPy 的基础上，并通过 NumPy 的 ndarray 对象进行数据交换和共享。 NumPy 官网 导包： 1import numpy 多维数组 NumPy 所有的计算都是围绕着数组进行的，因此在运算之前我们需要将数据转化为数组的形式。这一点与 MATLAB 十分相似，我们可以结合 Octave 的语法来理解 NumPy。 数组的定义 示例： 1234567891011121314151617181920import numpy as npdef main(): arr1 = np.array([1, 2, 3, 4, 5]) arr2 = np.zeros((4, 3)) # 4 行 3 列的全 0 数组 arr3 = np.ones((4, 3)) # 4 行 3 列的全 1 数组 print(arr3.shape) # 得到数组的尺寸，返回一个元组 # 输出：(4, 3) arr4 = np.arange(1, 10) # 得到一个 1 到 10 的递增数组 # arr4 == [1 2 3 4 5 6 7 8 9] arr5 = np.linspace(0, 1, 11) # 得到 0 ～ 1 等间距分布的数组 # arr5 == [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ] arr6 = np.random.rand(2, 2) # 生成一个 2 行 2 列的随机数组，每个元素服从 0 ~ 1 的均匀分布if __name__ == &quot;__main__&quot;: main() 对于 NumPy 而言，数组元素默认是 np.float64 类型，我们也可以指定 dtype 参数来选择数组的类型： 1arr = np.array([1, 2, 3, 4], dtype = np.int64) # 指定数组元素类型为 64 位整数 也可以通过 astype() 函数转化类型： 123arr1 = np.array([1.5, 2.5, 3.2, 4.7])arr2 = arr1.astype(np.int32)# arr2 = [1 2 3 4] 数组的运算 同尺寸的数组可以直接作对应元素的基本运算 123456789arr1 = np.array([1, 2, 3, 4])arr2 = np.array([2, 3, 4, 5])print(arr1 + arr2)print(arr2 - arr1)print(arr1 * arr2)print(arr1 ** arr2)print(arr1 / arr2)print(arr2 // arr1) 控制台输出： 123456[3 5 7 9][1 1 1 1][ 2 6 12 20][ 1 8 81 1024][0.5 0.66666667 0.75 0.8 ][2 1 1 1] 其他运算 123456789101112131415print(np.dot(arr1, arr2)) # 点乘# 输出：40a = np.array([[1, 2],[3, 4]])b = np.array([[1], [3]])print(a @ b) # 矩阵乘法，等同于 np.matmul() 函数# 输出：# [[ 7]# [15]]# NumPy 中的数组也可以像 MATLAB 那样直接做函数的参数，返回同尺寸的矩阵，矩阵所有元素是原先元素在该函数下的返回值print(np.sqrt(a))# 输出：# [[1. 1.41421356]# [1.73205081 2. ]] 注意： 对于 dot() 函数而言，如果两个参数是一维数组，那就会计算两个数组的点积；如果是两个二维数组，那就会计算矩阵的乘积；如果第一个参数是多维数组，第二个参数是一维数组，则会利用广播操作来计算点积。 广播 广播（broadcasting），指 NumPy 可以对不同形状的数组进行运算，通过广播机制，使得形状不同的数组可以进行逐元素的操作，而无需显式循环。 获取数组元素 对于 2 维数组 arr 而言，获取 i 行 j 列的元素的语法如下： 1arr[i, j] 也可以按条件查找： 1arr[arr &gt; 0] # 列举所有大于 0 的元素 注意： 条件语句中的与用 &amp; 表示，或用 | 表示。 数组切片 123arr = np.array([[1, 2],[3, 4]])print(arr[0, 0 : 2])# [1 2] start : end : step 启始索引：终止索引：步长 步长在这里可以为负数 : 单个 : 表示全部元素 数组压缩 在 NumPy 中，可以使用 flatten() 或 ravel() 函数将多维数组压缩成一维数组。 1234567891011121314import numpy as np# 创建一个多维数组arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])# 使用 flatten() 函数压缩成一维数组arr_flattened = arr.flatten()print(arr_flattened)# 输出: [1 2 3 4 5 6 7 8 9]# 使用 ravel() 函数压缩成一维数组arr_raveled = arr.ravel()print(arr_raveled)# 输出: [1 2 3 4 5 6 7 8 9] 或者使用 reshape() 函数： 12345678910111213141516171819202122import numpy as np# 三维数组arr = np.array([ [[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])# 获取数组的形状shape = arr.shapeprint(shape)# 输出: (2, 2, 3)# 将三维数组转换成二维数组arr_reshaped = arr.reshape((shape[0], shape[1] * shape[2]))print(arr_reshaped)# 输出:# [[ 1 2 3 4 5 6]# [ 7 8 9 10 11 12]] 数组拼接 在 NumPy 中，你可以使用 numpy.concatenate() 函数来实现两个矩阵的左右或上下拼接。 下面是两种常用的方法示例： 左右拼接（水平拼接）： 1234567891011import numpy as npmatrix1 = np.array([[1, 2], [3, 4]])matrix2 = np.array([[5, 6], [7, 8]])result = np.concatenate((matrix1, matrix2), axis = 1)print(result) 在这个示例中，我们有两个矩阵 matrix1 和 matrix2。通过使用 np.concatenate() 函数，并将 axis = 1 参数传递给它，我们可以将这两个矩阵在水平方向上拼接起来。输出结果如下： 12[[1 2 5 6] [3 4 7 8]] 上下拼接（垂直拼接）： 1234567891011import numpy as npmatrix1 = np.array([[1, 2], [3, 4]])matrix2 = np.array([[5, 6], [7, 8]])result = np.concatenate((matrix1, matrix2), axis = 0)print(result) 在这个示例中，我们仍然有两个矩阵 matrix1 和 matrix2。通过使用 np.concatenate() 函数，并将 axis = 0 参数传递给它，我们可以将这两个矩阵在垂直方向上拼接起来。输出结果如下： 1234[[1 2] [3 4] [5 6] [7 8]] 无论是左右拼接还是上下拼接，都可以使用 np.concatenate() 函数，并指定合适的 axis 参数来实现。注意，两个矩阵在除了指定拼接方向的轴以外的其他轴上的维度必须是一致的，这样才能成功进行拼接。 使用 row_stack() 和 column_stack() 方法实现拼接： np.row_stack（也可以使用 np.vstack 或 np.concatenate）： row_stack 用于将多个数组按行堆叠在一起，将它们垂直叠放，使得每个数组的行数保持不变，列数可以不同。 如果传递给 row_stack 的数组维度不匹配，它将尝试匹配数组的列数，然后垂直堆叠它们。这通常用于将多个行向量垂直叠加成一个矩阵。 示例： 1234567import numpy as np arr1 = np.array([1, 2, 3])arr2 = np.array([4, 5, 6])result = np.row_stack((arr1, arr2)) print(result) 输出： 12[[1 2 3] [4 5 6]] np.column_stack（也可以使用 np.hstack）： column_stack 用于将多个数组按列堆叠在一起，将它们水平叠放，使得每个数组的列数保持不变，行数可以不同。 如果传递给 column_stack 的数组维度不匹配，它将尝试匹配数组的行数，然后水平堆叠它们。这通常用于将多个列向量水平叠加成一个矩阵。 示例： 1234567import numpy as np arr1 = np.array([1, 2, 3])arr2 = np.array([4, 5, 6])result = np.column_stack((arr1, arr2)) print(result) 输出： 123[[1 4] [2 5] [3 6]] 总之，row_stack 和 column_stack 是用于堆叠多个数组的方便方法，它们根据需要垂直或水平堆叠数组，使得结果数组的维度适合您的需求。 矩阵的逆 np.linalg.inv() 函数用于计算矩阵的逆。 以下是 np.linalg.inv() 的基本用法和一些注意事项： 1234567891011import numpy as np# 创建一个矩阵A = np.array([[2, 1], [1, 3]])# 计算矩阵 A 的逆矩阵A_inv = np.linalg.inv(A)# 打印逆矩阵print(A_inv) 需要注意的是： 矩阵必须是方阵（即行数和列数相等），才能计算逆矩阵。 如果矩阵不可逆（例如，奇异矩阵），则 np.linalg.inv() 会引发 LinAlgError 异常。 计算逆矩阵是一个计算密集型的操作，特别是对于大型矩阵。在数值计算中，尽量避免计算逆矩阵，而是使用其他方法来解决线性方程组，如矩阵分解（LU 分解、QR 分解等）或迭代方法。 通常情况下，尽量避免使用逆矩阵来解决线性方程组，而是使用 NumPy 的线性方程求解函数 np.linalg.solve()，因为后者通常更稳定且计算效率更高。如果只是需要对矩阵进行逆运算以进行其他操作，那么 np.linalg.inv() 是一个合适的选择。 综合案例（实现一个简单的三层神经网络）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344import numpy as npdef sigmoid(x): return 1 / (1 + np.exp(-x))def softmax(x): exp_x = np.exp(x) return exp_x / np.sum(exp_x)class NetWork: &#x27;&#x27;&#x27; 三层神经网络: - 输入层有 3 个神经元 - 第 1 个隐藏层有 3 个神经元 - 第 2 个隐藏层有 3 个神经元 - 输出层有 2 个神经元 &#x27;&#x27;&#x27; def __init__(self): self.__net = &#123;&#125; self.__net[&#x27;W1&#x27;] = np.array([[0.3, 0.4, 0.5], [0.2, 0.4, 0.6], [0.2, 0.95, 0.7]]) self.__net[&#x27;B1&#x27;] = np.array([0.5, 0.6, 0.4]) self.__net[&#x27;W2&#x27;] = np.array([[0.2, 0.7, 0.6], [0.4, 0.35, 0.6], [0.3, 0.5, 0.45]]) self.__net[&#x27;B2&#x27;] = np.array([0.35, 0.4, 0.9]) self.__net[&#x27;W3&#x27;] = np.array([[0.45, 0.75, 0.15], [0.5, 0.1, 0.2]]) self.__net[&#x27;B3&#x27;] = np.array([1.5, 3]) def forward(self, x: np.array) -&gt; np.float64: w1, w2, w3 = self.__net[&#x27;W1&#x27;], self.__net[&#x27;W2&#x27;], self.__net[&#x27;W3&#x27;] b1, b2, b3 = self.__net[&#x27;B1&#x27;], self.__net[&#x27;B2&#x27;], self.__net[&#x27;B3&#x27;] x1 = np.dot(w1, x) + b1 x2 = np.dot(w2, sigmoid(x1)) + b2 x3 = np.dot(w3, sigmoid(x2)) + b3 return softmax(x3)def main(): n = NetWork() print(n.forward([12, 34, 17])) # [0.2622667 0.7377333] if __name__ == &#x27;__main__&#x27;: main() 其他 数组显示选项 np.set_printoptions() 用于配置NumPy在打印数组时的显示选项。它允许更改打印数组时的格式、精度、对齐方式等参数，以满足特定的需求。 下面是一些常用的 np.set_printoptions() 参数及其说明： precision（默认为 8）：设置打印浮点数时的小数点后位数的精度。 threshold（默认为 1000）：用于控制在数组元素数目超过此值时，NumPy会截断并以省略号表示。 suppress（默认为 False）：如果为 True，小数值将以科学计数法的形式打印。 linewidth（默认为 75）：设置打印输出的行宽。如果行中的字符数超过此值，NumPy将自动换行。 edgeitems（默认为 3）：控制打印数组时边缘元素的数量。 nanstr（默认为 'nan' ）：设置表示 NaN（非数字）值的字符串。 infstr（默认为 'inf' ）：设置表示正无穷大值的字符串。 formatter（默认为 None）：可以指定一个格式化函数来自定义打印数组的方式。 以下是一个示例，演示如何使用np.set_printoptions()来更改打印选项： 12345678910import numpy as np# 创建一个示例数组arr = np.array([1.23456789, 2.3456789, 3.456789])# 设置打印选项np.set_printoptions(precision=2, suppress=True)# 打印数组print(arr) 在上述示例中，我们设置了小数点后的精度为 2，并且将小数值以科学计数法的形式打印。 输出： 1[1.23 2.35 3.46] 将数组保存为二进制文件 NumPy 中的 .npy 文件是一种用于存储 NumPy 数组数据的二进制文件格式。这个文件格式是专门为 NumPy 数组设计的，可以高效地保存和加载多维数组数据。.npy 文件格式在科学计算、数据分析和机器学习等领域中广泛使用，因为它能够保留数组的数据类型和形状，同时具有较小的存储开销。 以下是一些关于 .npy 文件的重要特点和用法： 数据保存与加载： 使用 NumPy 的 np.save 和 np.load 函数可以方便地将 NumPy 数组保存到 .npy 文件中，以及从 .npy 文件中加载数组数据。 保存数组到 .npy 文件： 1234import numpy as nparr = np.array([1, 2, 3, 4, 5])np.save(&#x27;my_array.npy&#x27;, arr) 从 .npy 文件加载数组： 1loaded_arr = np.load(&#x27;my_array.npy&#x27;) 高效的存储和加载： .npy 文件采用二进制格式存储数据，因此比文本格式（如CSV）更高效。这意味着它可以更快速地保存和加载大型数组，减少了I/O操作的开销。 保留数据类型和形状： .npy 文件能够精确地保存数组的数据类型和形状，这对于科学计算任务非常重要。加载数据时，数据的类型和形状将被自动还原。 多维数组支持： .npy 文件不仅可以保存一维数组，还可以保存多维数组，包括矩阵和张量等。 压缩选项： NumPy 还提供了一些压缩选项，允许您将 .npy 文件以更小的存储空间保存。这可以在 np.save 函数中使用 allow_pickle 和 fix_imports 参数来控制。 1np.save(&#x27;my_array.npy&#x27;, arr, allow_pickle=True, fix_imports=False) 总之，.npy 文件是在 NumPy 中存储和加载数组数据的一种高效和方便的方式。它不仅保留了数据的精度和形状，还允许您轻松地在不同的 Python 环境中分享和传输数据。 图像绘制 matplotlib.pyplot 库可以很好地与 Numpy 库结合来绘制图像，以下介绍一些常用的图像绘制方法： plot() 方法绘制连续图像 12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltdef main(): x = np.linspace(-10, 10, 200) y1 = x ** 2 y2 = np.cos(x) plt.figure() plt.title(&#x27;$y_1 = x^2\\ &amp;\\ y_2 = cos(x)$&#x27;) plt.xlabel(&#x27;x&#x27;) plt.ylabel(&#x27;y&#x27;) plt.plot(x, y1, label=&#x27;$f(x) = x^2$&#x27;) plt.plot(x, y2, label=&#x27;$f(x) = cos(x)$&#x27;) plt.legend() plt.savefig(&#x27;function.png&#x27;) # 保存图像 plt.show() # 展示图像if __name__ == &#x27;__main__&#x27;: main() 效果： scatter() 方法绘制散点图 123456789101112131415import numpy as npimport matplotlib.pyplot as pltdef main(): x = np.random.randn(100) y = np.random.randn(100) c = x * y &gt; 0 plt.figure() plt.scatter(x, y, c=c, cmap=&#x27;bwr&#x27;, s=10) plt.xlabel(&#x27;x&#x27;) plt.ylabel(&#x27;y&#x27;) plt.show()if __name__ == &#x27;__main__&#x27;: main() 效果： 数值运算 回归 np.polyfit() 函数用于多项式拟合。多 np.polyfit 的基本语法如下： 1numpy.polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False) 参数说明： - x：输入数据的 x 坐标（自变量）。 - y：输入数据的 y 坐标（因变量）。 - deg：要拟合的多项式的次数。 - rcond：奇异值分解的阈值，用于控制拟合过程中的数值稳定性。默认为 None。 - full：如果为 True，返回额外的诊断信息，包括拟合残差。默认为 False。 - w：每个数据点的权重。可以用于加权拟合，默认为 None。 - cov：如果为 True，返回多项式系数的协方差矩阵。默认为 False。 np.polyfit 返回一个多项式的系数数组，其中最高次幂的系数位于数组的第一个元素。拟合多项式的次数由 deg 参数指定。 以下是一个简单的示例，演示如何使用 np.polyfit 对一组数据进行多项式拟合： 12345678910111213141516171819202122232425import numpy as npimport matplotlib.pyplot as plt# 创建一组示例数据x = np.array([0, 1, 2, 3, 4, 5])y = np.array([0, 0.8, 0.9, 0.1, -0.8, -1])# 使用 np.polyfit 进行多项式拟合coefficients = np.polyfit(x, y, 3) # 拟合一个 3 次多项式# 创建一个多项式函数poly_function = np.poly1d(coefficients)# 生成拟合后的曲线上的点x_fit = np.linspace(0, 5, 100)y_fit = poly_function(x_fit)# 绘制原始数据和拟合曲线plt.scatter(x, y, label=&#x27;Original Data&#x27;)plt.plot(x_fit, y_fit, label=&#x27;Fitted Curve&#x27;, color=&#x27;red&#x27;)plt.legend()plt.xlabel(&#x27;X&#x27;)plt.ylabel(&#x27;Y&#x27;)plt.title(&#x27;Polynomial Fit Example&#x27;)plt.show() 在这个示例中，我们使用 np.polyfit 对一组示例数据进行了 3 次多项式拟合，并通过 np.poly1d 创建了一个多项式函数。然后，我们绘制了原始数据和拟合曲线，以可视化拟合效果。 线性代数 np.linalg 是 NumPy 库的一个子模块，提供了一系列用于线性代数的函数。 求解线性方程组 np.linalg.solve 函数是 NumPy 库中用于解决线性方程组的一个函数。这个函数可以解决形如 Ax = b 的方程组，其中 A 是一个已知的非奇异（即可逆）方阵，b 是一个已知向量，而 x 是要求解的未知向量。 使用方法 1234567import numpy as npA = np.array([[3, 1], [1, 2]])b = np.array([9, 8])x = np.linalg.solve(A, b)print(x) # [2. 3.] 计算行列式 np.linalg.det 是 NumPy 库中用于计算矩阵行列式的函数。 使用方法 12345678910import numpy as npA = np.array([ [1, 2, 1], [2, 3, 1], [0, 4, 3]])detA = np.linalg.det(A)print(detA) # 1.0 计算矩阵的秩 np.linalg.matrix_rank 是 NumPy 中的一个函数，用于计算矩阵的秩（rank）。 使用方法 1234567891011import numpy as npA = np.array([ [1, 2], [2, 1], [1, 3]])rank = np.linalg.matrix_rank(A)print(rank) # 2 计算矩阵的逆 np.linalg.inv 是 NumPy 库中用于计算矩阵逆的函数。 使用方法 12345678910import numpy as npA = np.array([ [1, 2, 1], [2, 3, 1], [0, 4, 3]])invA = np.linalg.inv(A)print(invA) 控制台输出： 123[[ 5. -2. -1.] [-6. 3. 1.] [ 8. -4. -1.]] 计算矩阵的特征值和特征向量 np.linalg.eig 是 NumPy 中用于计算矩阵的特征值（eigenvalues）和特征向量（eigenvectors）的函数。函数返回一个包含两个数组的元组 (w, v)，其中 w 是包含矩阵 a 的特征值的一维数组，v 是包含矩阵 a 的特征向量的二维数组。特征值数组 w 的顺序是从小到大排列的。 使用方法 12345678import numpy as npA = np.array([[4, 2], [1, 3]])eigenvalues, eigenvectors = np.linalg.eig(A)print(&quot;Eigenvalues:\\n&quot;, eigenvalues)print(&quot;Eigenvectors:\\n&quot;, eigenvectors) 控制台输出： 12345Eigenvalues: [5. 2.]Eigenvectors: [[ 0.89442719 -0.70710678] [ 0.4472136 0.70710678]] 奇异值分解 np.linalg.svd 是 NumPy 中的一个函数，用于执行奇异值分解（Singular Value Decomposition，SVD）。 使用方法 123456789import numpy as npA = np.array([ [1, 2], [2, 1], [1, 3]])U, S, VT = np.linalg.svd(A, full_matrices=True) 其中： A 是输入的待分解矩阵，可以是一个二维 NumPy 数组（矩阵）。 U 是一个矩阵，包含了输入矩阵 A 的左奇异向量（Left Singular Vectors）。 S 是一个一维数组，包含了输入矩阵 A 的奇异值（Singular Values），按照从大到小排列。 VT 是一个矩阵，包含了输入矩阵 A 的右奇异向量的转置（Transpose of Right Singular Vectors）。 计算矩阵的范数 np.linalg.norm 是 NumPy 中的一个函数，用于计算向量或矩阵的范数（norm）。 使用方法 123import numpy as npnorm_value = np.linalg.norm(x, ord=None, axis=None) 其中： x 是要计算范数的向量或矩阵，可以是一个 NumPy 数组。 ord 是一个可选参数，用于指定计算的范数类型。默认情况下，ord 为 None，表示计算默认的二范数（L2 范数）。可以设置 ord 为不同的值来计算不同类型的范数，例如： 如果 ord 设置为 1，计算的是一范数（L1 范数）。 如果 ord 设置为 np.inf，计算的是无穷范数（L∞ 范数）。 如果 ord 设置为 -np.inf，计算的是负无穷范数（负无穷范数）。 如果 ord 设置为其他正数，计算的是 Lp 范数，其中 p 为指定的正数。 axis 是一个可选参数，用于指定在多维数组中沿哪个轴计算范数。默认情况下，计算整个数组的范数，但可以设置 axis 来沿指定轴计算范数。","categories":[{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"NumPy","slug":"NumPy","permalink":"http://example.com/tags/NumPy/"},{"name":"数值运算","slug":"数值运算","permalink":"http://example.com/tags/%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97/"}]},{"title":"CMake 介绍","slug":"CMake 介绍","date":"2023-06-17T02:30:57.000Z","updated":"2023-07-10T08:07:50.846Z","comments":true,"path":"2023/06/17/CMake 介绍/","link":"","permalink":"http://example.com/2023/06/17/CMake%20%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"CMake 简介 CMake 是一个跨平台的构建工具，用于管理和构建 C++ 项目。它的设计目标是提供一种简化的构建过程，使开发人员能够在不同的操作系统和编译器上轻松地生成可执行文件、库和其他构建目标。 CMake 的主要思想是通过描述项目的构建过程来生成构建系统所需的构建脚本。它使用一种称为 CMakeLists.txt 的文本文件来定义项目的目录结构、源文件、编译选项、依赖项和构建规则。CMake 具有很好的跨平台性，可以在多种操作系统上使用，包括 Windows、Linux、macOS 等。它可以生成不同的构建系统文件，如 Makefile、Ninja、Visual Studio 解决方案等，从而使开发人员能够在不同的开发环境中使用适合的构建系统。 总而言之，CMake 简化了跨平台 C++ 项目的构建过程，使开发人员能够更轻松地管理项目的编译和构建，同时提供了灵活性和可扩展性来处理复杂的项目结构和依赖关系。 学习 CMake 的目的，是为将来处理大型的 C / C++ / Java 项目做准备。 CMake 安装 绝大多数 Linux 系统已经安装了 CMake，没有安装的话可以去 CMake 官网 进行安装。 MacOS 也可以用 Homebrew 进行快速安装： 1brew install cmake 构建 CMake 项目 构建 CMake 项目，大致分为 3 个步骤： 创建 CMakeLists.txt 文件 使用 CMake 指令生成 Makefile 文件 使用 make 指令进行编译 一个简单示例 创建一个 demo.cpp ： 12345678#include &lt;iostream&gt;int main() &#123; std::cout &lt;&lt; &quot;Hello world!\\n&quot;; return 0;&#125; 同级目录下创建一个 CMakeLists.txt 文件，输入以下文本： 1234567PROJECT(HELLO)SET(SRC_LIST demo.cpp)MESSAGE(STUTAS &quot;Configuring project...&quot;)ADD_EXECUTABLE(Demo $&#123;SRC_LIST&#125;) 终端下使用 cmake 指令生成 Makefile 文件： 1cmake . 若运行成功，则目录下会生成 Makefile 文件。 使用 make 指令进行编译： 1make 编译成功，则会生成可执行文件 Demo 。 运行 Demo 即可： 1./Demo CMakeLists.txt 基本语法介绍 PROJECT 关键字 PROJECT 关键字用于定义和配置项目。它用于指定项目的名称、版本号和语言。。 PROJECT关键字的基本语法如下： 1PROJECT(&lt;project_name&gt; [VERSION &lt;version&gt;] [LANGUAGES &lt;languages&gt;]) 其中，&lt;project_name&gt; 是要定义的项目名称。&lt;version&gt; 是可选的，用于指定项目的版本号。 &lt;languages&gt; 也是可选的，用于指定项目所使用的编程语言。 以下是一些 PROJECT 关键字的示例用法： 定义一个简单的项目： 1PROJECT(MyProject) 定义一个带有版本号的项目： 1PROJECT(MyProject VERSION 1.0) 定义一个使用多种编程语言的项目： 1PROJECT(MyProject LANGUAGES CXX C) SET 关键字 SET 关键字用于设置变量的值。语法如下： 1SET(&lt;variable&gt; &lt;value&gt; [CACHE &lt;type&gt; &lt;docstring&gt; [FORCE]]) 其中，&lt;variable&gt; 是要设置的变量名，&lt;value&gt; 是要为变量设置的值。&lt;value&gt; 可以是一个字符串、一个列表、一个布尔值或一个数值。SET关键字还支持一些其他选项： CACHE ：指定变量为缓存变量，即用户可以通过CMake的缓存机制进行设置或修改该变量的值。缓存变量的值可以在CMake运行期间持久保存，并在下一次运行时保持不变。 &lt;type&gt; ：指定缓存变量的类型。可以是BOOL、STRING、PATH等类型。 &lt;docstring&gt; ：可选项，用于提供变量的描述文本。 FORCE ：可选项，强制设置变量的值，即使它已经被缓存。 以下是一些 SET 关键字的示例用法： 设置一个字符串变量： 1SET(my_string &quot;Hello, World!&quot;) 设置一个列表变量： 1SET(my_list 1 2 3 4) 设置一个缓存变量： 1SET(my_variable &quot;default value&quot; CACHE STRING &quot;Description of my variable&quot;) 强制设置一个缓存变量的值： 1SET(my_variable &quot;new value&quot; CACHE STRING &quot;Description of my variable&quot; FORCE) 通过 SET 关键字，你可以在 CMake 脚本中设置变量的值，并根据需要使用它们来控制构建过程、传递参数或处理其他逻辑。 变量取值：使用 $&#123;&#125; ，但是在 IF 控制语句中直接使用变量名。 MESSAGE 关键字 在 CMake 中，MESSAGE 是一个用于输出消息的关键字。它允许你在 CMake 脚本中打印信息，以便在构建过程中向用户提供有用的反馈或调试信息。 MESSAGE关键字的语法如下： 1MESSAGE([&lt;mode&gt;] &quot;&lt;message&gt;&quot;) 其中，&lt;mode&gt; 是可选的，用于指定消息的模式。常用的消息模式有以下几种： STATUS ：以普通状态的形式输出消息。 WARNING ：以警告的形式输出消息。 AUTHOR_WARNING ：以作者警告的形式输出消息。 SEND_ERROR ：以错误的形式输出消息，并终止 CMake 的配置过程。 FATAL_ERROR ：以致命错误的形式输出消息，并终止 CMake 的配置过程。 &lt;message&gt; 是要输出的消息内容，可以是一个字符串或一个变量。 以下是一些MESSAGE关键字的示例用法： 输出普通状态消息： 1MESSAGE(STATUS &quot;Configuring project...&quot;) 输出警告消息： 1MESSAGE(WARNING &quot;Warning: Invalid configuration detected.&quot;) 输出错误消息并终止配置过程： 1MESSAGE(SEND_ERROR &quot;Error: Required library not found.&quot;) ADD_EXECUTABLE 关键字 在 CMake 中，ADD_EXECUTABLE 是一个用于添加可执行文件的关键字。它用于指定要构建的可执行文件的名称和源代码文件。 ADD_EXECUTABLE 关键字的语法如下： 1ADD_EXECUTABLE(&lt;executable_name&gt; [WIN32] [MACOSX_BUNDLE] [EXCLUDE_FROM_ALL] source1 [source2 ...]) 其中，&lt;executable_name&gt; 是要生成的可执行文件的名称。[WIN32] 和 [MACOSX_BUNDLE] 是可选的标志，用于指定在 Windows 上构建一个 GUI 应用程序或在 macOS 上构建一个应用程序捆绑包。[EXCLUDE_FROM_ALL] 也是可选的标志，表示该目标不会被默认构建，除非明确要求。 source1 [source2 ...] 是要包含在可执行文件中的源代码文件的列表。可以通过相对或绝对路径指定这些源文件。 以下是 ADD_EXECUTABLE 关键字的示例用法： 1ADD_EXECUTABLE(MyApp main.cpp utils.cpp) 上述示例将创建一个名为 MyApp 的可执行文件，并将 main.cpp 和 utils.cpp 作为源代码文件包含在可执行文件中。 使用 ADD_EXECUTABLE 关键字时，CMake 会自动检测源代码文件的编程语言，并相应地设置编译器和编译选项。 ADD_EXECUTABLE 关键字允许你定义项目中的可执行文件，并指定与之相关的源代码文件。通过 ADD_EXECUTABLE，你可以将源代码文件与特定的可执行文件关联起来，以便在构建过程中生成所需的可执行文件。 ADD_SUBDIRECTORY 关键字 ADD_SUBDIRECTORY 是用于向 CMake 构建系统添加子目录的关键字。它的作用是告诉 CMake 在当前项目中包含另一个目录，并在该子目录中查找并处理另一个 CMakeLists.txt 文件。 ADD_SUBDIRECTORY 的语法如下： 1ADD_SUBDIRECTORY(directory [binary_dir] [EXCLUDE_FROM_ALL]) directory ：要添加的子目录的路径。这个路径可以是相对于当前 CMakeLists.txt 文件的相对路径，也可以是绝对路径。 binary_dir（可选）：指定生成的二进制文件的输出目录。如果不提供，则使用默认值（通常是当前构建目录）。 EXCLUDE_FROM_ALL（可选）：如果指定了这个选项，将会在构建目标时排除这个子目录。这对于包含一些可选的或不常用的子项目很有用。 使用 ADD_SUBDIRECTORY 时，CMake 会进入子目录并处理对应的 CMakeLists.txt 文件。这意味着子目录中可以有自己的构建规则、目标等。通过使用 ADD_SUBDIRECTORY，可以将复杂的项目划分为多个子项目，并使用各自的 CMakeLists.txt 文件进行管理，从而提高项目的组织性和可维护性。 请注意，在使用 ADD_SUBDIRECTORY 之前，通常需要在子目录中准备一个有效的 CMakeLists.txt 文件，以定义子项目的构建规则、目标等。 以下是一个示例，展示如何使用 ADD_SUBDIRECTORY： 1234567# 主项目的 CMakeLists.txt# 添加子目录ADD_SUBDIRECTORY(subdir)# 主项目的构建规则和目标# ... 1234# 子目录的 CMakeLists.txt# 子目录的构建规则和目标# ... 上述示例中，主项目的 CMakeLists.txt 文件使用 ADD_SUBDIRECTORY 添加了一个名为 \"subdir\" 的子目录。然后，CMake 进入子目录并处理对应的 CMakeLists.txt 文件，执行子目录的构建规则和目标的设置。 通过使用 ADD_SUBDIRECTORY ，你可以将项目组织成多个子目录，每个子目录都可以有自己的 CMakeLists.txt 文件，方便地管理和构建大型项目。 INSTALL 关键字 INSTALL 用于定义要安装的文件、目录和相关设置。它用于在构建过程中指定将生成的文件复制到特定位置的规则。 INSTALL 关键字的基本语法如下： 1234567891011121314INSTALL([CODE &lt;code&gt;] [SCRIPT &lt;file&gt;] [SCRIPTS &lt;files&gt;...] [FILES &lt;files&gt;...] [PROGRAMS &lt;files&gt;...] [DIRECTORY &lt;dir&gt;...] [TARGETS &lt;targets&gt;...] [EXPORT &lt;export-name&gt;] [ALIAS &lt;target&gt;] [FILES_MATCHING] [[PATTERN &lt;pattern&gt; | REGEX &lt;regex&gt;] [EXCLUDE] [PERMISSIONS permissions...] [CONFIGURATIONS [Debug|Release|...]]]... [...]) 下面是 INSTALL 关键字的一些常用选项： CODE &lt;code&gt; ：指定自定义安装逻辑的 CMake 代码。 SCRIPT &lt;file&gt; ：指定一个脚本文件，该脚本文件包含安装逻辑。 SCRIPTS &lt;files&gt;... ：指定多个脚本文件，这些脚本文件包含安装逻辑。 FILES &lt;files&gt;... ：指定要安装的普通文件。 PROGRAMS &lt;files&gt;... ：指定要安装的可执行文件。 DIRECTORY &lt;dir&gt;... ：指定要安装的目录。 TARGETS &lt;targets&gt;... ：指定要安装的构建目标（可执行文件、静态库、共享库等）。 EXPORT &lt;export-name&gt; ：指定要安装的导出目标。 ALIAS &lt;target&gt; ：指定要安装的构建目标的别名。 FILES_MATCHING ：指定在安装文件时进行匹配的模式。 PATTERN &lt;pattern&gt; | REGEX &lt;regex&gt; ：指定文件匹配的模式或正则表达式。 EXCLUDE ：排除匹配的文件。 PERMISSIONS permissions... ：指定安装文件的权限。 CONFIGURATIONS [Debug|Release|...] ：指定仅在特定构建配置下安装文件。 INSTALL 关键字允许您以灵活的方式定义文件和目录的安装规则。可以使用多个 INSTALL 关键字来安装多个文件和目录。例如： 1234567891011121314# CMakeLists.txt# 安装脚本文件和目录INSTALL(SCRIPT my_script.cmake)INSTALL(DIRECTORY my_directory DESTINATION /path/to/destination)# 安装文件INSTALL(FILES file1.txt file2.txt DESTINATION /path/to/destination)# 安装可执行文件INSTALL(PROGRAMS my_program DESTINATION /path/to/destination)# 安装构建目标INSTALL(TARGETS my_target RUNTIME DESTINATION /path/to/destination) 上述示例演示了如何使用 INSTALL 关键字来指定不同类型的文件和目录的安装位置。 cmake 指令 cmake 基本语法： 1cmake [options] &lt;path-to-source&gt; options ：CMake的选项，用于配置生成过程的行为和参数。 &lt;path-to-source&gt; ：CMakeLists.txt 所在的源代码目录路径。 常用选项： -G &lt;generator&gt; ：指定生成器，用于生成特定构建系统的文件（如 Makefile 或 Visual Studio 解决方案）。例如，-G \"Unix Makefiles\" 表示生成 Unix 系统下的 Makefile 文件。 -D &lt;var&gt;=&lt;value&gt; ：设置 CMake 变量的值。例如，-D CMAKE_BUILD_TYPE=Release 设置 CMake 变量 CMAKE_BUILD_TYPE 的值为 Release。 -B &lt;path-to-build&gt; ：指定构建目录的路径。生成的构建系统文件将存储在该目录中。 -S &lt;path-to-source&gt; ：指定源代码目录的路径。 示例用法： 在源代码目录中直接运行CMake（in-source build）： 1cd /path/to/source &amp;&amp; cmake . 在指定的构建目录中运行CMake（out-of-source build）： 1cd /path/to/build &amp;&amp; cmake /path/to/source 指定生成器和构建类型： 1cmake -G &quot;Unix Makefiles&quot; -DCMAKE_BUILD_TYPE=Release /path/to/source make 指令 Make 是一个常用的构建工具，用于自动化软件项目的编译和构建过程。它使用一个名为Makefile 的文件来定义构建规则和依赖关系，以确定如何生成目标文件（例如可执行文件、库文件等）。 以下是 make 指令的基本语法： 1make [options] [target] 其中，options 是可选的命令行选项，用于控制 make 的行为。target 是要构建的目标，通常是在 Makefile 中定义的一个规则。 常用的 make 选项包括： -f &lt;filename&gt;：指定要使用的 Makefile 文件的名称。如果未指定，则默认使用当前目录下的 Makefile 文件。 -C &lt;dir&gt;：在指定的目录下执行 make 命令。这可以用于指定 Makefile 文件所在的目录。 -j &lt;num&gt;：指定并行构建的作业数，加快构建速度。 在 Makefile 文件中，你可以定义多个目标和规则，每个规则描述了如何根据依赖关系生成目标文件。一个基本的规则结构如下： 1234target: dependencies command1 command2 ... 其中，target 是目标文件的名称，dependencies 是生成目标文件所依赖的文件或目标，commandX 是用于生成目标文件的命令。 以下是一个简单的示例 Makefile 文件的内容： 12hello: main.c hello.c gcc -o hello main.c hello.c 上述示例中，我们定义了一个目标 hello，它依赖于 main.c 和 hello.c 这两个源代码文件。make 指令会检查依赖关系，并在需要时执行相应的命令来生成目标文件。 要使用 make 指令进行构建，只需在终端中进入包含 Makefile 文件的目录，并运行 make 命令。如果没有指定目标，默认会构建第一个目标。 Make 工具基于目标文件和规则之间的依赖关系，通过增量构建的方式进行构建，只重新构建已修改的文件和受其影响的文件，从而提高构建效率。Make 是一个强大而灵活的构建工具，它在软件开发中广泛应用。通过定义适当的规则和依赖关系，可以自动化构建过程，简化项目的管理和部署。 CMake 与 Make 之间的关系可以简述如下： CMake 负责生成适合不同平台和编译器的构建系统文件（如Makefile）。 Make 负责根据 Makefile 中的规则和依赖关系来执行实际的编译和构建操作。 make install 指令 make install 用于将构建生成的文件复制到指定位置，完成软件的安装过程。这个指令通常与 Makefile 文件一起使用，用于定义安装规则。 在 Makefile 中，可以定义一个名为 install 的目标规则，该规则包含安装过程的指令。安装指令通常使用系统的 cp 命令或类似的工具来复制文件或目录到目标位置。 以下是一个示例 Makefile 文件中的 install 规则： 123install: cp myapp /usr/local/bin cp -r resources /usr/local/share/myapp 在上述示例中，install 规则中定义了两个命令。第一个命令使用 cp 命令将 myapp 可执行文件复制到 /usr/local/bin 目录下，第二个命令将 resources 目录递归复制到 /usr/local/share/myapp 目录下。 要执行安装过程，可以在命令行中运行 make install 命令。Make 将读取 Makefile 文件，并根据 install 目标规则中定义的指令来执行安装操作。 需要注意的是，make install 命令通常需要使用超级用户权限（sudo）来执行，因为将文件复制到系统目录通常需要管理员权限。如果没有权限，可以尝试将文件复制到用户的个人目录或其他有权限的目录。 使用 make install 指令可以方便地自动化软件的安装过程，将生成的文件复制到指定位置，使用户可以直接使用已安装的软件。 工程化目录结构 基本目录结构： 12345678910.├─CMakeLists.txt├─README.md├─bulid├─runhello.sh├─doc├─COPYRIGHT├─src├───CMakeLists.txt└───demo.cpp 每个目录下都有一个 CMakeLists.txt ，用于实现 CMake 嵌套。 外层 CMakeLists.txt ： 123PROJECT(HELLO) # 指定项目名称ADD_SUBDIRECTORY(src bin) # 将 src 子目录加入工程并指定编译输出路径为 bin 目录 内层 CMakeLists.txt ： 12345SET(SRC_LIST demo.cpp)MESSAGE(STUTAS &quot;Configuring project...&quot;)ADD_EXECUTABLE(Demo $&#123;SRC_LIST&#125;) # 添加可执行项目 bulid 文件夹：用于存储构建过程中生成的中间文件和最终的构建结果。 src 文件夹：用于存放源代码 doc 文件夹：用于存放文档 COPYRIGHT ：版权 runhello.sh ：安装脚本 构建库 ADD_LIBRARY 关键字 ADD_LIBRARY 是一个用于定义和构建库（Library）目标的关键字。它用于创建静态库（Static Library）、共享库（Shared Library）或模块库（Module Library）的规则，并将源代码文件编译成库文件。 ADD_LIBRARY 关键字的基本语法如下： 123ADD_LIBRARY(&lt;name&gt; [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] [source1] [source2 ...]) 其中，&lt;name&gt; 指定要创建的库的名称。可以使用自定义名称或者 CMake 的变量作为库的名称。 选项 [STATIC | SHARED | MODULE] 指定库的类型。可以选择其中一种类型： - STATIC：创建静态库。静态库在链接时被静态地链接到可执行文件中。 - SHARED：创建共享库（也称为动态库）。共享库在运行时被动态地加载。 - MODULE：创建模块库（适用于像 Apple 的 macOS 平台）。模块库是一种特殊的共享库类型。 可选项 [EXCLUDE_FROM_ALL] 表示将该库目标从生成的默认目标中排除。 后续的参数 source1、source2 等指定库的源代码文件，可以是单个源文件，也可以是一个文件列表。CMake 将编译这些源代码文件，并生成库文件。 以下是一个示例： 1234567# CMakeLists.txt# 创建静态库ADD_LIBRARY(my_static_lib STATIC source1.cpp source2.cpp)# 创建共享库ADD_LIBRARY(my_shared_lib SHARED source3.cpp source4.cpp) INCLUDE_DIRECTORIES 关键字 INCLUDE_DIRECTORIES 是一个用于指定包含目录的关键字。它用于将一个目录添加到编译器的包含路径中，以使编译器能够找到所需的头文件。 INCLUDE_DIRECTORIES 关键字的基本语法如下： 1INCLUDE_DIRECTORIES([AFTER|BEFORE] directory1 [directory2 ...]) 其中，directory1、directory2 等参数指定要添加到包含路径中的目录。可以指定一个或多个目录。 选项 [AFTER|BEFORE] 控制新目录的添加顺序。默认情况下，新目录会添加到已有包含目录列表的末尾，即在已有包含目录之后。如果指定了 AFTER 选项，新目录将添加到列表的末尾。如果指定了 BEFORE 选项，新目录将添加到列表的开头。 以下是一个示例： 1234567# CMakeLists.txt# 添加包含目录INCLUDE_DIRECTORIES(include_dir1 include_dir2)# 添加包含目录，并将其放置在列表的开头INCLUDE_DIRECTORIES(BEFORE include_dir3)","categories":[{"name":"C/C++","slug":"C-C","permalink":"http://example.com/categories/C-C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"CMake","slug":"CMake","permalink":"http://example.com/tags/CMake/"},{"name":"跨平台项目构建","slug":"跨平台项目构建","permalink":"http://example.com/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA/"}]},{"title":"字典树","slug":"字典树","date":"2023-05-16T16:22:35.000Z","updated":"2023-07-24T17:47:36.715Z","comments":true,"path":"2023/05/17/字典树/","link":"","permalink":"http://example.com/2023/05/17/%E5%AD%97%E5%85%B8%E6%A0%91/","excerpt":"","text":"介绍 字典树（Trie），就是像字典一样的树，可用于插入和检索字符串。 假设某字典树只需要存储单词，所有单词均由 26 个小写字母组合而成，那么对于该字典树而言，每个节点都有 27 个域，分别为 26 个子节点（可以为 nullptr ）以及一个布尔标识符，表示是否存在某个单词以该字母结尾。 以下图为例： 该字典树一共存储了 dog、dot、dig、tea、tease、tease 六个单词，其中黄色的节点表示结束节点。 代码实现 在这里还是以 26 个字母组成的单词为例，给出字典树的代码实现。 使用链式节点的字典树模版 123456789101112131415161718192021222324252627282930313233343536373839404142class Trie &#123;private: std::vector&lt;Trie*&gt; child; bool isEnd; Trie* searchPrefix(const std::string&amp; prefix) &#123; Trie* p = this; for (char ch : prefix) &#123; p = p-&gt;child[ch - &#x27;a&#x27;]; if (p == nullptr) return nullptr; &#125; return p; &#125;public: Trie(): child(26, nullptr), isEnd(false) &#123;&#125; ~Trie() &#123; for (Trie* ct : child) &#123; if (ct != nullptr) &#123; delete ct; ct = nullptr; &#125; &#125; &#125; void insert(const std::string&amp; word) &#123; Trie* p = this; for (char ch : word) &#123; if (p-&gt;child[ch - &#x27;a&#x27;] == nullptr) &#123; p-&gt;child[ch - &#x27;a&#x27;] = new Trie(); &#125; p = p-&gt;child[ch - &#x27;a&#x27;]; &#125; p-&gt;isEnd = true; &#125; bool search(const std::string&amp; word) &#123; Trie* p = searchPrefix(word); return p &amp;&amp; p-&gt;isEnd; &#125;&#125;;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"字典树","slug":"字典树","permalink":"http://example.com/tags/%E5%AD%97%E5%85%B8%E6%A0%91/"},{"name":"字符串匹配","slug":"字符串匹配","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"}]},{"title":"数据库规范化理论","slug":"数据库规范化理论","date":"2023-05-15T12:45:27.000Z","updated":"2023-07-10T08:17:52.909Z","comments":true,"path":"2023/05/15/数据库规范化理论/","link":"","permalink":"http://example.com/2023/05/15/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%84%E8%8C%83%E5%8C%96%E7%90%86%E8%AE%BA/","excerpt":"","text":"什么是数据库规范化？ 数据库规范化（Normalization）是一种数据库设计技术，其旨在实现以下两个主要目标： 减少数据冗余（Redundancy）。 确保数据的依赖性是有意义的，即数据存储是有逻辑的。 函数依赖 基本定义 函数依赖（Functional Dependncy）是规范化中的重要概念，简而言之，函数依赖用于描述属性（Attributes）之间的关系。 概念： 若 \\(A\\) 和 \\(B\\) 是关系模式 \\(R\\) 中的两个属性集合，对于给定的 \\(A\\) 值，都有唯一的 \\(B\\) 值与其对应，我们就称 \\(A\\) 函数决定 \\(B\\)，\\(B\\) 函数依赖于 \\(A\\)，记作：\\(A \\to B\\)，其中 \\(A\\) 称为决定因子（Determinant） 若 \\(A\\) 和 \\(B\\) 相互依赖，即二者一一对应，则记为：\\(A\\) \\(\\leftrightarrow B\\) 例如： 在一个学生信息的关系模型 \\(Student(\\underline{s\\_id}, name, gender, age)\\) 中，我们假设学号 \\(s\\_id\\) 是关系模型中的主键，则有： \\[ s\\_id \\to name \\] 即：唯一的学号对应唯一的姓名，因此姓名在这里是函数依赖于学号的。 平凡函数依赖和非平凡函数依赖 我们从决定因子和被决定因子的集合关系角度出发可以将函数依赖分为两类： 平凡函数依赖（Trivial Functional Dependency）： 若 \\(A \\to B\\) ，且 \\(B \\subseteq A\\) ，则称该依赖为平凡依赖。 非平凡函数依赖（Nontrivial Functional Dependency）： 若 \\(A \\to B\\) ，且 \\(B \\not\\subseteq A\\) ，则称该依赖为非平凡依赖。 部分函数依赖和完全函数依赖 同时，我们从决定因子属性的必要性又可以将函数依赖分为两类： 部分函数依赖（Partial Functional Dependency）： 若 \\(A \\to B\\) ，且存在 \\(A\\) 的真子集 \\(X\\) ，使得 \\(X \\to B\\) ，我们就称 \\(B\\) 部分函数依赖于 \\(A\\) 。 完全函数依赖（Full Functional Dependency）： 若 \\(A \\to B\\) ，且不存在 \\(A\\) 的真子集 \\(X\\) ，使得 \\(X \\to B\\)，我们就称 \\(B\\) 完全函数依赖于 \\(A\\) 。 即 \\(A\\) 中删去任意一个属性都无法满足 \\(A \\to B\\) 。 例如，在上述例子中，显然有 \\((s\\_id, name) \\to gender\\)， 但其决定因子的一个真子集 \\(s\\_id\\) 也满足被 \\(gender\\) 函数依赖，因此该函数依赖是一个部分函数依赖。相反，\\(s\\_id \\to gender\\) 就是一个完全函数依赖。 注意到，一般只有在 \\(A\\) 是多个特征的集合时才会考虑此分类，若 \\(A\\) 为单属性，且 \\(A \\to B\\) ，则一定构成完全函数依赖。 传递函数依赖 函数依赖具有传递性，传递函数依赖（Transitive Functional Dependency）描述如下： 若 \\(A\\) ，\\(B\\) ，\\(C\\) 是关系模型 \\(R\\) 中的三个特征集合，且满足： \\(A \\to B\\) 且 \\(B \\not\\to A\\) \\(B \\to C\\) 则称 \\(C\\) 通过 \\(B\\) 函数依赖于 \\(A\\) 。 多值依赖 设 \\(R(U)\\) 是属性集 \\(U\\) 上的一个关系模式。\\(X\\)、\\(Y\\)、\\(Z\\) 是 \\(U\\) 的子集，若对 \\(U\\) 的任意一对关系而言，给定一对 \\((X, Z)\\) 的值，都有若干组 \\(Y\\) 值与之对应，而 \\(Y\\) 的取值仅仅与 \\(X\\) 相关而与 \\(Z\\) 无关，这就是多值依赖（Multi-valued Dependency）。记作：\\(X \\to\\!\\!\\!\\to Y\\)。 我们也可以这样描述：给定 \\(X\\) 的值，有多组 \\((Y, Z)\\) 的值与之对应，且 \\(Y\\) 与 \\(Z\\) 的取值相互独立。 例如： 我们给定关系 \\(subject(subject\\_name, teacher, text\\_book)\\) 来描述学科、老师和学科教材的关系，在该关系模型中，一门学科对应多组老师和教材，而老师和教材又是相互独立的，即老师和学科教材分别只决定于学科，所以我们有： \\[ \\begin{array}{} subject\\_name \\to\\!\\!\\!\\to teacher \\\\ subject\\_name \\to\\!\\!\\!\\to text\\_book \\end{array} \\] 平凡多值依赖和非平凡多值依赖 进一步，我们又可以将多值依赖分为平凡多值依赖和非平凡多值依赖： 平凡多值依赖（Trivial Multi-valued Dependency）： 在关系模型 \\(R\\) 的属性集为 \\(U\\)，属性 \\(A\\) 和 \\(B\\) 满足 \\(A \\to\\!\\!\\!\\to B\\) 且满足以下两个条件之一： \\(A \\subseteq B\\) \\(A \\cup B = R\\) 我们就称该多值依赖是平凡的。 非平凡多值依赖（Nontrivial Multi-valued Dependency）： 若 \\(A \\to\\!\\!\\!\\to B\\) 且不满足以上任意一个条件，我们就称该多值依赖是非平凡的。 范式 范式（Normal Form），简称 NF，是一种数据库规范化评级标准，范式越高，数据模型越规范。 数据库规范化技术，就是不断提高数据模型的范式等级。 UNF UNF（Unormalized Form），即无范式，是一种未规范化的表格，表格中的数据可能包括一个或多个值。 示例： 1NF 1NF（First Normal Form），即第一范式。指在一张表格中给定行和列，对应唯一的数据，且一个关系模型中的所有的属性都是不可分的基本数据项。1NF 是关系型数据库的基本要求。 示例： UNF \\(\\to\\) 1NF 将缺省单元格的数据进行拷贝，然后对无范式表格重新划分，即可得到每个单元格仅有一个值的第一范式表格。 2NF 2NF（Second Normal Form），即第二范式。指在 1NF 的基础上，满足所有非主属性完全依赖于候选键（Candidate key）。 1NF \\(\\to\\) 2NF 确定主键：确定 1NF 关系中的主键 确定函数依赖：分析非主键列对主键的完全依赖关系。也就是说，找出哪些非主键列的值是由主键决定的，而不是由主键的一部分决定的 创建新表：对于那些非主键列存在部分依赖的情况，将其分离出来，创建一个新的表 调整关系：在新的表中，将非主键列和相应的主键列作为新表的列 示例： 上述关系中存在如下函数依赖： 不难发现，我们可以指定 \\((clinetNo, PropertyNo)\\) 作为该关系中的主键，而函数依赖 fd2 和 fd3 的决定因子是主键的真子集，因此其被决定因子（图中下画线部分的属性）是部分依赖于主键的，因此我们要将其从当前关系中抽离出来： 最终建立的关系模型的 Schema 如下： 该关系模型的三张表都不存在非主属性对主键的部分依赖，各自满足第二范式。 3NF 3NF（Third Normal Form），即第三范式。指在 2NF 的基础上，不存在非主属性传递依赖于候选键。 2NF \\(\\to\\) 3NF 确定主键 确定函数依赖 找到依赖于主键的传递函数依赖，并将其分离出来 示例： 在上述建立的 2NF 关系模型中的第二张表 \\(PropertyOwner\\) 中，存在函数依赖关系 \\(propertyNo \\to ownerNo\\)（\\(ownerNo \\not\\to propertyNo\\)）和 $ ownerNo oName$ ，因此 \\(oName\\) 传递依赖于主键，所以我们要将其从当前关系中分离出来。 满足 3NF 的关系模型 Schema 如下所示： 该关系模型中的 4 张表都不存在非主属性对主键的传递依赖，各自满足第三范式。 BCNF BCNF（Boyce-Codd Normal Form），即巴斯-科德范式。指在 3NF 的基础上，清除了主属性对候选键的部分函数依赖。 即满足 BCNF 的充要条件是关系模型中所有函数依赖的决定因子都是候选键。 3NF \\(\\to\\) BCNF 确定主键和主属性 确定函数依赖 消除主属性对候选键的部分函数依赖 例如，有如下关系模型： \\[ studentGrade(\\underline{class\\_id}, \\underline{s\\_id}, t\\_id, grade) \\] 该关系模型用于储存学生某门课程的成绩，每门课有且仅有一名老师来教学，可以作为该表的候选键有 \\((class\\_id, s\\_id)\\) 或者 \\((t\\_id, s\\_id)\\) ，我们选取前者作为主键，那么此关系模型中唯一的非主属性就是 \\(grade\\) 。 该关系模型符合 3NF，但是我们不难发现，主属性 \\(t\\_id\\) 对主键构成部分依赖关系，因此该关系模型不符合 BCNF，因此我们将其拆分为两张表： \\[ \\begin{array}{} teacher(\\underline{class\\_id}, t\\_id) \\\\ studentGrade(\\underline{class\\_id}, \\underline{s\\_id}, grade) \\end{array} \\] 这样，我们就消除了主属性对候选键的部分依赖，上述两张表各自符合 BCNF。 4 NF 4 NF（Forth Normal Form），即第四范式，即在 BCNF 的基础上，消除了所有决定因子不为候选键的非平凡多值依赖。换言之，满足 4NF 的充要条件是对于关系 \\(R\\) 中的每一对非平凡多值依赖 \\(A \\to\\!\\!\\!\\to B\\) 而言，\\(A\\) 都是关系中的候选键。 BCNF \\(\\to\\) 4NF 确定主键和候选键 确定关系中的非平凡多值依赖 消除所有决定因子不为候选键的非平凡多值依赖 例如，现有如下关系： 在如上 \\(BranchStaffOwner(branchNo, sName, oName)\\) 关系中，一个 \\(branchNo\\) 可以对应多组 \\((sName, oName)\\) ，而 \\(sName\\) 和 \\(oName\\) 之间相互不影响，所以我们有： \\[ \\begin{array}{} branchNo \\to\\!\\!\\!\\to sName \\\\ branchNo \\to\\!\\!\\!\\to oName \\end{array} \\] 而 \\(branchNo\\) 在这里不是候选键，所以我们要消除消除这两对非平凡多值依赖，因此将该关系拆分为两张表： 这样我们就消除了上面提到的两对非平凡多值依赖，以上两张表 \\(Branch(branchNo, sName)\\)、\\(BranchOwner(BranchNo, oName)\\) 分别满足第四范式。 事实上第四范式之上还有第五范式（Fifth Normal Form），但第四范式已经是相当规范的等级了，因此第五范式笔者在此就不赘述了。😃","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库系统","slug":"数据库系统","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"},{"name":"数据库规范化","slug":"数据库规范化","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%84%E8%8C%83%E5%8C%96/"}]},{"title":"如何在程序中计算定积分？—— Simpson 公式讲解","slug":"如何在程序中计算定积分？—— Simpson 公式讲解","date":"2023-04-30T06:04:03.000Z","updated":"2023-07-19T16:59:27.560Z","comments":true,"path":"2023/04/30/如何在程序中计算定积分？—— Simpson 公式讲解/","link":"","permalink":"http://example.com/2023/04/30/%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%AE%A1%E7%AE%97%E5%AE%9A%E7%A7%AF%E5%88%86%EF%BC%9F%E2%80%94%E2%80%94%20Simpson%20%E5%85%AC%E5%BC%8F%E8%AE%B2%E8%A7%A3/","excerpt":"","text":"Simpson 公式是一种用于求积分近似值的方法，相对于常规的矩形逼近和梯型逼近，其精度要高很多。 公式如下： \\[ \\int_a^b f(x)dx \\approx \\frac{b - a}{6n} (f(a) + f(b) + 2 \\sum_{i = 1} ^ {n - 1}f(x_i) + 4 \\sum_{i = 0}^{n - 1}f(x_{i + 0.5})) \\] 其中 \\(n\\) 是区间分隔的数量，\\(n\\) 越大，精度越高。 数学证明 Simpson 积分公式的原理就是采用二次函数逼近目标函数。 如上图所示，我们将函数区间 \\([x_1, x_2]\\) 近似看作是二次函数，\\(x_{1.5}\\) 是区间中点，我们规定： \\[ \\begin{array}{} f(x_1) = c_2 x_1^2 + c_1 x_1 + c_0 \\\\ f(x_2) = c_2 x_2^2 + c_1 x_2 + c_0 \\\\ f(x_{1.5}) = c_0 \\end{array} \\] 则积分面积 \\(S = \\int_{x_1}^{x_2} f(x)dx \\approx \\int_{x_1}^{x_2} (c_2 x^2 + c_1 x + c_0)dx\\) \\[ \\begin{array}{} \\implies S \\approx \\frac{c_2}{3}(x_2^3 - x_1^3) + \\frac{c1}{2}(x_2^2 - x_1^2) + c_0(x_2 - x_1) \\\\ = \\frac{x_2 - x_1}{6}(f(x_1) + f(x_2) + 4 f(x_{1.5})) \\end{array} \\] 现在我们将函数积分区域 \\([a, b]\\) 划分为 \\(n\\) 段，对每一段 \\([x_i, x_{i + 1}]\\) 采取同样的方式求定积分， 最后求和就可以得到我们的目标答案： \\[ \\begin{array}{} \\int_a^b f(x)dx \\approx \\frac{b - a}{6n} (f(a) + f(b) + 2 \\sum_{i = 1} ^ {n - 1}f(x_i) + 4 \\sum_{i = 0}^{n - 1}f(x_{i + 0.5})) \\\\ (x_0 = a, x_n = b) \\end{array} \\] 误差 最大误差为 \\(\\frac{(b - a)^5}{180 n^4} M\\)，其中 \\(M\\) 是函数在区间 \\([a, b]\\) 上四阶导的绝对值的最大值。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;cstdio&gt;#include &lt;cmath&gt;inline double fn(double x) &#123; return x * exp(-x);&#125;double solve_rect(double left, double right, int n) &#123; // 采用一般的矩形逼近法求定积分 double res = 0; double d = (right - left) / n; for (int i = 0; i &lt; n; i++) &#123; res += fn(left + i * d); &#125; return res * d;&#125;double solve_simpson(double left, double right, int n) &#123; // 采取辛普森公式求定积分 double res = -fn(left) + fn(right); double d = (right - left) / n; for (int i = 0; i &lt; n; i++) &#123; res += (2 * fn(left + i * d) + 4 * fn(left + (i + 0.5) * d)); &#125; return d * res / 6;&#125;int main() &#123; printf(&quot;%lf\\n&quot;, solve_rect(0, 1, 10)); // 0.245014 printf(&quot;%lf\\n&quot;, solve_rect(0, 1, 100)); // 0.262393 printf(&quot;%lf\\n&quot;, solve_rect(0, 1, 1000)); // 0.264057 printf(&quot;%lf\\n&quot;, solve_simpson(0, 1, 10)); // 0.264241 return 0;&#125; 实际答案 \\(\\int_0^1 x e^{-x}dx = 1 - \\frac{2}{e} \\approx 0.2642411176571\\)，可见上述积分采用 Simpson 公式计算时在 \\(n = 10\\) 时已经达到了一个较高的精度，远超常规的矩形逼近法。","categories":[{"name":"数学","slug":"数学","permalink":"http://example.com/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"计算几何","slug":"计算几何","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/"},{"name":"Simpson 公式","slug":"Simpson-公式","permalink":"http://example.com/tags/Simpson-%E5%85%AC%E5%BC%8F/"},{"name":"定积分","slug":"定积分","permalink":"http://example.com/tags/%E5%AE%9A%E7%A7%AF%E5%88%86/"}]},{"title":"MySQL 知识点总结","slug":"MySQL 知识点总结","date":"2023-04-10T14:58:57.000Z","updated":"2023-07-10T08:45:59.882Z","comments":true,"path":"2023/04/10/MySQL 知识点总结/","link":"","permalink":"http://example.com/2023/04/10/MySQL%20%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","excerpt":"","text":"MySQL 基本介绍 MySQL 是一种关系型数据库管理系统，由瑞典 MySQL AB 公司开发，属于 Oracle 旗下产品，由于其体积小、速度快、成本低、开源等优点，使其在 Web 开发中尤其受欢迎。 MySQL 官网 MySQL 客户端连接 1mysql -u [用户名] -p 示例： 以 root 用户登陆： 1mysql -u root -p MySQL Command 介绍 MySQL 所使用的 SQL 语言是用于访问数据库的最常用标准化语言。 SQL 语句分类 最常见的 SQL 语句包括以下 4 大类： DDL（Data Definition Language） 用途：对数据库对象（数据库、表、列、索引等）进行创建、删除、修改等。 常用关键字：create、drop、alter DML（Data Manipulation Language） 用途：用于添加、修改、删除和查询数据库记录，并检查数据完整性。 常用关键字：insert、update、delete DQL（Data Query Language） 用途：用于查询数据。 常用关键字：select DCL（Data Control Language） 用途：用于管理用户权限。 DDL 语句 数据库操作 查询所有数据库： 1show databases; 创建数据库： 123create database [数据库名称];create database if not exists [数据库名称];create database [数据库名称] default charset [字符集]; 删除数据库： 12drop database [数据库名称];drop database if exists [数据库名称]; 使用数据库： 1use [数据库名称]; 查询当前数据库： 1select database(); 表操作 查询当前数据库所有表： 1show tables; 查询表结构： 1desc [表名]; 查询指定表的创建语句： 1show create table [表名]; 创建表： 123456create table [表名]( 字段1 字段1类型 [约束] [comment], 字段2 字段2类型 [约束] [comment], # ... 字段n 字段n类型 [约束] [comment])comment 表注释; 例如： 1234567# 创建如下员工表create table demo( id int comment &#x27;编号&#x27;, name varchar(50) comment &#x27;姓名&#x27;, age int comment &#x27;年龄&#x27;, gender varchar(1) comment &#x27;性别&#x27;)comment &#x27;员工&#x27;; 修改表名： 1alter table [表名] rename to [新表名]; 删除表： 1drop table (if exists) [表名]; 删除指定表，并重新创建该表（即删除表中所有行）： 1truncate table [表名]; 字段操作 添加字段： 1alter table [表名] add [字段名] [类型(长度)] [约束] [comment]; 例如： 12alter table staff add gender varchar(10) default &#x27;undefined&#x27; not null comment &#x27;性别&#x27;; 如上，给 staff 表格添加 gender 字段 修改字段数据类型 1alter table [表名] modify [字段名] [新数据类型]; 修改字段名和字段数据类型： 1alter table [表名] change [旧字段名] [新字段名] [类型(长度)] [约束] [comment]; 例如： 12alter table staff change id s_id int not null comment &#x27;员工 ID&#x27;; 删除字段： 1alter table [表名] drop [字段名]; 补充 MySQL 表格字段数据类型 基本数据类型： 类型 大小 描述 tinyint 1 byte 整数 smallint 2 bytes 整数 mediumint 3 bytes 整数 int 或者 integer 4 bytes 整数 bigint 8 bytes 整数 float 4 bytes 单精度浮点数 double 8 bytes 双精度浮点数 decimal 依赖于精度和标度的值 小数值 字符串类型： 类型 大小 描述 char 0 ~ 255 bytes 定长字符串 varchar 0 ~ 65535 bytes 变长字符串 tinyblob 0 ~ 255 bytes 不超过 255 个字符的二进制数据 tinytext 0 ~ 255 bytes 短文本字符串 blob 0 ~ 65535 bytes 二进制形式的长文本数据 text 0 ~ 65535 bytes 长文本数据 日期类型： 类型 大小 格式 说明 date 3 bytes YYYY-MM-DD 日期值 time 3 bytes HH:MM:SS 持续时间值 year 1 bytes YYYY 年份值 datetime 8 bytes YYYY-MM-DD HH:MM:SS 混合日期和时间值 timestamp 4 bytes YYYY-MM-DD HH:MM:SS 混合日期和时间值，时间戳 枚举类型： 关键词：enum 枚举范围需要在创建表格时通过枚举的方式指定，最多允许有 65535 个成员。 例如： 12345create table stu( id int primary key auto_increment, name varchar(20) not null, gender enum(&#x27;男&#x27;, &#x27;女&#x27;) not null); 其中 gender 字段只能是「男」或者「女」 MySQL 约束 约束是作用于表中字段上的规则，用于限制存储在表中的数据。 分类： 约束 关键字 描述 非空约束 not null 字段不能为 NULL 唯一约束 unique 字段数据都是唯一的，不重复的 主键约束 primary key 主键是一行数据的唯一表示，要求非空唯一 默认约束 default 保存数据时，如果未指定该字段的值，则采用默认值 检查约束 check 保证字段满足某一个条件 外键约束 foreign key 用来建立两张表的数据之间的联系，保证数据的一致性和完整性 案例： 根据以下需求完成表的创建： 字段名 字段含义 字段类型 约束条件 约束关键词 id ID 唯一标识 int 主键，并且自动增长 primary key, auto_increment name 姓名 varchar(10) 非空唯一 not null, unique age 年龄 int 大于 0，不大于 120 check status 状态 char(1) 默认为 1 default gender 性别 char(1) 无 1234567create table stu( id int primary key auto_increment comment &#x27;ID&#x27;, name varchar(10) not null unique comment &#x27;姓名&#x27;, age int check ( age &gt; 0 and age &lt;= 120 ) comment &#x27;年龄&#x27;, status char(1) default &#x27;1&#x27; comment &#x27;状态&#x27;, gender char(1) comment &#x27;性别&#x27;)comment &#x27;学生&#x27;; 外键约束 让多个表的数据产生连接，子表的外键是父表的一个候选键，如下图： 管理外键关联： 创建表时添加外键关联： 1[外键名称] foreign key [外键字段名] references [主表(主表列名)] [指定行为]; 创建表后添加外键关系： 1alter table [表名] add constraint [外键名称] foreign key [外键字段名] references [主表(主表列名)] [指定行为]; 删除外键关联： 1alter table [表名] drop foreign key [外键名称]; 外键删除和更新行为： 行为 说明 no action 当父表中删除或更新对应记录时，首先检查是否有对应外键，如果有则不允许删除或更新（默认） restrict 当父表中删除或更新对应记录时，首先检查是否有对应外键，如果有则不允许删除或更新（与 no action 一致） cascade 当父表中删除或更新对应记录时，首先检查是否有对应外键，如果有则也删除或者更新外键在子表中的记录 set null 当父表中删除或更新对应记录时，首先检查是否有对应外键，如果有则设置子表的外键值为 NULL set default 当父表中删除或更新对应记录时，首先检查是否有对应外键，如果有则设置子表的外键值为默认值（Innodb 不支持） 案例： 1234# 给 staff 表的 dept_id 属性添加关联 dept 表的 id 属性的外键关系，并且将更新行为和删除行为设置为级联alter table staff add constraint fk_staff_dept_id foreign key (dept_id) references dept(id) on update cascade on delete cascade; DML 语句 添加数据： 给指定字段添加数据： 1insert into [表名(字段名1, 字段名2, ...)] values(值1, 值2, ...); 给全部字段添加数据： 1insert into [表名] values(值1, 值2, ...); 批量添加： 1insert into [表名] values(值1, 值2, ...), (值1, 值2, ...), ...; 示例： 123insert into staff (s_id, name, age, gender)values (1002, &#x27;Tom&#x27;, 24, &#x27;男&#x27;), (1003, &#x27;Frank&#x27;, 25, &#x27;男&#x27;); 修改数据： 1update [表名] set 字段名1 = 值1， 字段名2 = 值2, ... [where 条件]; 删除数据： 1delete from [表名] [where 条件]; DQL 语句 语法： 1234567891011121314select [字段列表]from [表名列表]where [条件列表]group by [分组字段列表]having [分组后条件列表]order by [排序字段列表]limit [分页参数]; select 之后添加 distinct 可以消除重复元组 查询多个字段： 12345select [字段1, 字段2, ...] from [表名];select * from [表名]; # 查询所有字段（不推荐）select [字段] as [别名] from [表名]; 条件查询： 1select [字段列表] from [表名] where [条件列表]; 条件： 比较运算符 功能 &gt; 大于 &gt;= 大于等于 &lt; 小于 &lt;= 小于等于 = 等于 &lt;&gt; 或者 != 不等于 between ... and ... 在某个范围之内（含最小、最大值） in(...) 在 in 之后的列表中的值 like 占位符 模糊匹配，_ 匹配单个字符，% 匹配任意个字符 is null 是 NULL 逻辑运算符 功能 and 或 &amp;&amp; 并且 or 或 || 或者 not 或 ! 非 几个案例： 1234567891011121314select name, s_id from staff where age &gt;= 25;# 查找年龄不小于 25 的员工姓名和 IDselect name, s_id from staff where age between 20 and 30;# 查找年龄在 20 和 30 岁之间的员工姓名和年龄select name, s_id from staff where gender is null;# 查找 gender 为 null 的员工姓名和 IDselect name, s_id from staff where age &gt;= 25 and gender = &#x27;女&#x27;;# 查找年龄不小于 25 的女员工姓名和 IDselect name from staff like &#x27;李%&#x27;;# 查找姓李的员工 聚合函数 聚合函数是指将一列数据作为一个整体，进行纵向计算。 函数 功能 count() 统计数量 max() 最大值 min() 最小值 avg() 平均值 sum() 求和 注：NULL 值不参与除 count() 之外的聚合函数的运算 语法： 1select 聚合函数(字段列表) from [表名]; 几个案例： 12345select count(s_id) from staff;# s_id 数量，NULL 值不参与聚合函数计算select max(age) from staff;# 查找员工年龄最大值 分组查询 语法： 1select [字段列表] from [表名] where [条件列表] group by [分组字段名] having [分组后过滤条件]; ‼️ where 和 having 的区别： 执行时机不同：where 是分组之前进行过滤，不满足 where 条件，不参与分组；而 having 是分组之后对结果进行过滤。 判断条件不同，where 不能对聚合函数进行判断，而 having 可以。 几个案例： 12select gender, count(*) as numebr from staff group by gender;# 查询男性员工和女性员工的数量 结果： 12select address, count(*) as address_count from emp where age &lt;= 35 group by address having address_count &gt;= 5;# 查询不同地区年龄小于等于 35 岁的员工且人数不小于 5 的地区及其员工数量 ‼️ 执行顺序： where 聚合函数 having 排序查询 语法： 12select [字段列表] from [表名] order by [字段1] [排序方案1], [字段2] [排序方案2] ...;# 多个字段时先看前面的字段，若前面的字段值相同，则看后面的字段规则 排序方案： asc ：升序排序 desc ：降序排序 几个案例： 12select name, s_id from staff order by age asc;# 将员工姓名和 ID 按照年龄升序排列 分页查询 关键词：limit 语法： 1select [字段列表] from [表名] limit [起始索引], [查询记录数]; 注：起始索引从 0 开始，若索引为 0，则 0 可以省略 几个案例： 12select * from emp limit 0, 10;# 展示从索引 0 开始的 10 条记录 ‼️ 多表查询 直接使用 select 语句： 1select [字段列表] from [表1], [表2]; 以上语句会直接得到 表1 和 表2 的笛卡尔积的投影字段。 自然连接： 1select [字段列表] from [表1], [表2] where [表1.key] = [表2.key]; key 在这里为主表的外键 JOIN 语句 cross join ：笛卡尔积 1select [字段列表] from [表1] cross join [表2]; on 关键字：在 join 语句后添加 on [条件列表] 可以筛选特定条件的元组 内连接 natural join ：自然连接 1select [字段列表] from [表1] natural join [表2]; inner join ：内连接，join 不加修饰的默认连接，显示左表和右表符合条件的记录 1select [字段列表] from [表1] (inner) join [表2] on [条件列表]; 上图使用 where 语句的等价连接方式叫做隐式内连接。 外连接 left join ：左连接，即保留左表所有元组，右表无法匹配的属性用 NULL 取代 1select [字段列表] from [表1] left join [表2] on [条件列表]; right join ：右连接，即保留右表所有元组，左表无法匹配的属性用 NULL 取代 1select [字段列表] from [表1] right join [表2] on [条件列表]; full join ：全连接，即保留两张表所有元组，无法匹配的属性用 NULL 取代 1select [字段列表] from [表1] full join [表2] on [条件列表]; ‼️ 子查询 在 SQL 语句中嵌套 select 语句，称为嵌套查询，又称子查询。 标量子查询：子查询的结果为单个值 列子查询：子查询的结果为一列 常用操作符：in、not in、any、some、all 行子查询：子查询的结果为一行 常用操作符：=、!=、in、not in、exists、not exists exists (select ...) 用来判断是否有后面的 select 语句是否有返回值。若至少返回一行，则返回 true ，否则返回 false 表子查询：子查询的结果为多行多列 常用操作符：in 根据子查询的位置，又可以分为： where 之后 from 之后 select 之后 DCL 语句 DCL（Data Control Language）用来管理数据库用户控制数据库的访问权限。 管理用户： 查询用户： 12use mysql;select * from user; 创建用户： 1create user [&#x27;用户名&#x27;@&#x27;主机名&#x27;] identified by [&#x27;密码&#x27;]; 示例： 12345# 创建用户 Jack，只能在当前主机 localhost 访问，密码 123456create user &#x27;Jack&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;;# 创建用户 Tina，可以在任意主机访问该数据库，密码 123456create user &#x27;Tina&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;; 修改用户密码： 1alter user [&#x27;用户名&#x27;@&#x27;主机名&#x27;] identified with mysql_native_password by [&#x27;新密码&#x27;]; 删除用户： 1drop user [&#x27;用户名&#x27;@&#x27;主机名&#x27;]; 权限控制： 权限 说明 all, all privileges 所有权限 select 查询数据 insert 插入数据 update 修改数据 delete 删除数据 alter 修改表 drop 删除数据库 / 表 / 视图 create 创建数据库 / 表 查询权限： 1show grants for [&#x27;用户名&#x27;@&#x27;主机名&#x27;]; 授予权限： 1grant [权限列表] on [数据库名.表名] to [&#x27;用户名&#x27;@&#x27;主机名&#x27;]; 撤销权限： 1revoke [权限列表] on [数据库名.表名] to [&#x27;用户名&#x27;@&#x27;主机名&#x27;]; 多个权限之间，采取逗号分隔 授权时，数据库和表名可以使用 * 进行通配 MySQL 函数 函数是指一段可以直接被另一段程序调用的程序或代码。 字符串函数 函数 功能 length(s) 返回字符串的长度 concat(s1, s2, ...) 字符串拼接 lower(str) 将字符串全部小写 upper(str) 将字符串全部大写 lpad(str, n, pad) 左填充 rpad(str, n, pad) 右填充 trim(str) 去掉字符串头部和尾部的空格 substring(str, start, len) 返回字符串从 start 位置起的 len 个长度的子字符串 数据函数 函数 说明 ceil(x) 向上取整 floor(x) 向下取整 mod(x, y) 返回 x mod y 的值 rand() 返回 0 ~ 1 之间的随机数 round(x, y) 求参数 x 的四舍五入的值，保留 y 位小数 日期函数 函数 说明 curdate() 返回当前日期 curtime() 返回当前时间 now() 返回当前日期和时间 year(date) 获取指定 date 的年份 month(date) 获取指定 date 的月份 day(date) 获取指定 date 的日期 date_add(date, interval expr type) 返回一个日期 / 时间值加上一个时间间隔 expr 后的时间值 datediff(date1, date2) 返回结束时间 date1 和起始时间 date2 之间的天数 date_format(date, format) date_format(date, format) ：用于以不同的格式显示日期 / 时间数据。date 参数是合法的日期，format 规定日期/时间的输出格式。例如，将 2023-03-14 转化为 2023-03 （即年 - 月）输出，则为： date_format(target_date, '%Y-%m') 流程函数 流程函数也是很常用的一类函数，可以在 SQL 语句中实现条件筛选，从而提高语句效率。 函数 功能 if(value, t, f) value 为 true 返回 t ，否则返回 f ifnull(value1, value2) 如果 value1 不为空，返回 value1 ，否则返回 value2 case when [val1] then [res1] ... else [default] end 如果 val1 为 true ，返回 res1 ，...，default 为默认值 case [expr] when [val1] then [res1] ... else [default] end 同上，若 expr 的值等于 val1 ，则返回 res1， ...，default 为默认值 MySQL 事务操作 事务（Transaction）是一组操作的集合，它是一个不可分割的工作单位，事务会把所有操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。 事务 4 大特性（ACID）： 原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败 一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态 隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行 持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的 事务操作 查看 / 设置事务提交方式 12select @@autocommit;set @@autocommit = 0; # 将事务设置为手动提交 开启事务 1start transaction; # 我们也可以不更改 @@autocommit 参数 提交事务 1commit; # 设置为手动提交后必须要手动提交才能更新数据 回滚事务 1rollback; # 回滚 / 撤销事务","categories":[{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"}]},{"title":"素数筛","slug":"素数筛","date":"2023-04-02T05:23:45.000Z","updated":"2023-07-10T08:22:04.009Z","comments":true,"path":"2023/04/02/素数筛/","link":"","permalink":"http://example.com/2023/04/02/%E7%B4%A0%E6%95%B0%E7%AD%9B/","excerpt":"","text":"引入 如果我们想要求出小于 n 的所有素数，一个很自然的想法就是从 1 到 n 进行遍历，然后对素数进行记录，但这样的话时间复杂度为 \\(O(n^{\\frac{3}{2}})\\) ，当 n 足够大的时候这个算法是较慢的，有没有更高效的算法呢？ 接下来我们介绍最常见的两种素数筛，以 Leetcode 模版题为例：计数质数 埃氏筛 埃氏筛也叫埃拉托斯特尼筛法，考虑任意素数 x ，则 x 的所有倍数都是合数。 12345678910111213141516171819class Solution &#123;public: int countPrimes(int n) &#123; // 埃式筛 bool* notPrime = new bool[n](); int res = 0; for (int i = 2; i &lt; n; i++) &#123; if (!notPrime[i]) &#123; res++; for (long long k = (long long)i * i; k &lt; n; k += i) &#123; // 若 j &lt; i，则 j * i 一定已经被筛过 notPrime[k] = true; &#125; &#125; &#125; return res; &#125;&#125;; 时间复杂度：\\(O(n\\ loglogn)\\) 如果想了解其证明，读者可以自行去 OI Wiki 上看。 尽管埃氏筛法已经有较高的效率，但其仍然无法达到线性时间复杂度，因为有些数存在重复筛除的情况，例如 12，其会被 2，3 分别筛除一次，有没有办法可以避免重复筛除呢？ 欧式筛（线性筛） 欧式筛，即 Euler 筛法，其避免了上述的重复筛而造成的时间浪费，真正意义上实现了线性时间复杂度。对于特别大的数据量（\\(n &gt; 10^8\\)）时适用。 1234567891011121314151617181920212223class Solution &#123;public: int countPrimes(int n) &#123; if (n &lt; 2) return 0; int* primeNum = new int[(int)(1.5 * n / log(n)) + 1]; // π(n) &lt; 1.5 * n / ln(n) 素数数目的一个粗糙上界 bool* notPrime = new bool[n](); int res = 0; for (int i = 2; i &lt; n; i++) &#123; if (!notPrime[i]) &#123; primeNum[res++] = i; &#125; for (int j = 0; j &lt; res &amp;&amp; i * primeNum[j] &lt; n; j++) &#123; notPrime[i * primeNum[j]] = true; if (i % primeNum[j] == 0) break; // 如果 i 能被 primeNum[j] 整除，则 i 的倍数一定会被 primeNum[j] 的倍数筛除 // 故此刻不需要继续再筛除，退出循环 &#125; &#125; return res; &#125;&#125;; 时间复杂度：\\(O(n)\\) 注意到，欧式筛中被筛除的合数都是被当前记录的最小素数筛除的，所以我们我们也可以同时得到每个数的最小质因数。 案例 HDU - 6954 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;cmath&gt;#define MAX_NUM 10000005using i64 = long long;bool notPrime[MAX_NUM];i64 ans[MAX_NUM];int primeNum[MAX_NUM];int cnt = 0;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(0); std::cout.tie(0); for (int i = 2; i &lt; MAX_NUM; i++) &#123; if (!notPrime[i]) &#123; ans[i] = ans[i - 1] + 2ll * i; primeNum[cnt++] = i; &#125; else &#123; ans[i] = ans[i - 1] + i; &#125; for (int j = 0; j &lt; cnt &amp;&amp; (i64)i * primeNum[j] &lt; MAX_NUM; j++) &#123; notPrime[i * primeNum[j]] = true; if (i % primeNum[j] == 0) break; &#125; &#125; int numTest; std::cin &gt;&gt; numTest; int n; while (numTest--) &#123; std::cin &gt;&gt; n; std::cout &lt;&lt; ans[n] - 4 &lt;&lt; &#x27;\\n&#x27;; &#125; return 0;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"素数","slug":"素数","permalink":"http://example.com/tags/%E7%B4%A0%E6%95%B0/"},{"name":"数论","slug":"数论","permalink":"http://example.com/tags/%E6%95%B0%E8%AE%BA/"},{"name":"素数筛","slug":"素数筛","permalink":"http://example.com/tags/%E7%B4%A0%E6%95%B0%E7%AD%9B/"},{"name":"埃氏筛","slug":"埃氏筛","permalink":"http://example.com/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B/"},{"name":"欧式筛","slug":"欧式筛","permalink":"http://example.com/tags/%E6%AC%A7%E5%BC%8F%E7%AD%9B/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2023-04-01T02:54:12.000Z","updated":"2023-07-10T08:23:40.818Z","comments":true,"path":"2023/04/01/正则表达式/","link":"","permalink":"http://example.com/2023/04/01/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"什么是正则表达式？ 正则表达式（regular expression），又称为规则表达式，是一种文本模式，其拥有独特的语法和独立的处理引擎，可以帮助我们实现文本匹配，特别是当匹配模式比较复杂时，正则表达式有相当大的优势。 构造正则表达式的方法和创建数学表达式的方法一样。也就是用多种元字符与运算符可以将小的表达式结合在一起来创建更大的表达式。正则表达式的组件可以是单个的字符、字符集合、字符范围、字符间的选择或者所有这些组件的任意组合。 正则表达式基本语法 字符类 表达式 说明 [abc] 只能是 a, b, c [^abc] 除了 a, b, c 之外的任何字符 [a-zA-Z] a 到 z，A 到 Z 的所有字符 [a-d[m-p]] a 到 d，m 到 p [a-z&amp;&amp;[def]] a-z 和 def 到交集，在这里相当于 [def] [a-z&amp;&amp;[^bc]] a-z 和非 bc 的交集 [a-z&amp;&amp;[^m-p]] a-z 和除了 m 到 p 的交集 预定义字符 表达式 说明 . 任何字符 \\d 一个数字（[0-9]） \\D 非数字（[^0-9]） \\s 一个空白字符（[\\t\\n\\x0B\\f\\r]） \\S 非空白字符（[^\\t\\n\\x0B\\f\\r]） \\w 英文、数字、下划线（[a-zA-Z0-9_]） \\W 一个非单词字符（[^a-zA-Z0-9_]） 数量词 表达式 说明 X? X， 一次或者零次 X* X ，零次或者多次 X+ X ，一次或者多次 X&#123;n&#125; X ，正好 n 次 X&#123;n,&#125; X ，至少 n 次 X&#123;n,m&#125; X ，至少 n 次，不超过 m 次 特殊字符 表达式 说明 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 \\n 或 \\r。要匹配 $ 字符本身，请使用 \\$ 。 () 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 \\( 和 \\) 。 | 指明两项之间的一个选择。要匹配 | ，请使用 \\| 。 典型案例 匹配网址 URL：[a-zA-z]+://[^\\s]* 匹配中国邮编编码：[1-9]\\d&#123;5&#125;(?!\\d) 匹配 18 位身份证：^(\\d&#123;6&#125;)(\\d&#123;4&#125;)(\\d&#123;2&#125;)(\\d&#123;2&#125;)(\\d&#123;3&#125;)([0-9]|X)$ 正则表达式在线测试工具 实际运用 当前大多数流行语言都有自己的正则表达式库，例如 C++11 更新的 Regex 库 。 今天我们以 Java 为例，讲解正则表达式的一些实际运用。 Java 中的 String 内置正则匹配方法 matches() 方法： boolean matches(String regex) ，根据正则表达式，判断字符串是否能匹配成功，返回对应的布尔值 12345678910111213// 匹配手机号码// 以 1 开头// 第二位只能是 3 到 9// 任意数字 9 位String regex_1 = &quot;1[3-9]\\\\d&#123;9&#125;&quot;;System.out.println(&quot;13170488669&quot;.matches(regex_1)); // true// 匹配座机号码// 区号 以 0 开头// 中间可能有 -// 号码总长度 5 到 10 位String regex_2 = &quot;0\\\\d&#123;2,3&#125;-?[1-9]\\\\d&#123;4,9&#125;&quot;;System.out.println(&quot;027-142424&quot;.matches(regex_2)); // true replaceFirst() 方法和 replaceAll() 方法： String replaceFirst(String regex, String replacement) ，将字符串匹配到的第一个子串进行替换，返回新字符串。 String replaceAll(String regex, String replacement) ，将字符串所有匹配成功的子串进行替换，返回新字符串。 1234567String name = &quot;Isaac Newton&quot;;// 隐藏姓名System.out.println(name.replaceFirst(&quot;[a-zA-Z]+&quot;, &quot;*****&quot;)); // ***** NewtonString number = &quot;12-(900)84632&quot;;// 删除所有非数字字符System.out.println(number.replaceAll(&quot;[^0-9]&quot;, &quot;&quot;)); // 1290084632 split() 方法： String[] split(String regex) String[] split(String regex, int limit) 根据正则表达式对字符串进行分割，返回分割后的字符串数组。 这里 limit 参数用来控制分割次数： 若 limit &gt; 0 ：字符串最多被分割 n - 1 次，返回长度为 n 的字符串数组 若 limit &lt;= 0 ：字符串被尽可能多次分割，返回尽可能长的字符串数组 12345String[] member = &quot;张三, 李四, 王五&quot;.split(&quot;, &quot;);for (var name : member) System.out.println(name);// 张三// 李四// 王五 练习 驼峰匹配 1234567891011121314class Solution &#123; public List&lt;Boolean&gt; camelMatch(String[] queries, String pattern) &#123; String regexModel = &quot;[a-z]*&quot;; for (int i = 0, len = pattern.length(); i &lt; len; i++) &#123; regexModel += (pattern.charAt(i) + &quot;[a-z]*&quot;); &#125; ArrayList&lt;Boolean&gt; ans = new ArrayList&lt;&gt;(); for (int i = 0, len = queries.length; i &lt; len; i++) &#123; ans.add(queries[i].matches(regexModel)); &#125; return ans; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://example.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"讲解 C++ 匿名函数","slug":"讲解 C++ 匿名函数","date":"2023-03-29T18:00:51.000Z","updated":"2023-07-10T08:08:08.374Z","comments":true,"path":"2023/03/30/讲解 C++ 匿名函数/","link":"","permalink":"http://example.com/2023/03/30/%E8%AE%B2%E8%A7%A3%20C++%20%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/","excerpt":"","text":"匿名函数，也叫 Lambda 表达式，是 C++ 11 提出的特性，匿名函数能使得我们的程序更加灵活轻便。 基本语法 1[capture](para) -&gt; returnType &#123; body &#125; capture ：闭包 para ：参数 returnType ：返回类型 body ：函数体 示例： 12auto fun = [](int x, int y) &#123; return x + y; &#125;;std::cout &lt;&lt; fun(1, 2) &lt;&lt; &#x27;\\n&#x27;; // 3 闭包 capture 称为闭包，作用是引用匿名函数体外的变量，其有如下格式： 12345678[] // 不引用外部变量，无法在函数体内使用外部变量[x, &amp;y] // x 按值捕获，y 按照引用捕获[&amp;] // 可以捕获所有外部变量，按照引用捕获[=] // 可以捕获所有外部变量，按照值捕获[&amp;, x] // x 按照值捕获，其余所有变量按照引用捕获[=, &amp;y] // y 按照引用捕获，其余所有变量按照值捕获[this] // 通过引用捕获当前对象[*this] // 通过传值的方式捕获当前对象 示例： 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; int sum = 0; std::vector&lt;int&gt; arr = &#123;1, 2, 3, 4, 5&#125;; auto fun = [&amp;sum](int x) &#123; sum += x; &#125;; // auto fun = [sum](int x) &#123; sum += x; &#125;; 报错，sum 必须是可修改的左值，故只能通过引用的方式捕获 for (int x : arr) &#123; fun(x); &#125; std::cout &lt;&lt; sum &lt;&lt; &#x27;\\n&#x27;; // 15 return 0;&#125; 运用 匿名函数的运用十分灵活，以下我们举几个常见的例子： 在 STL 的排序函数中自定义排序方式： 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;struct Student &#123; std::string name; int grade;&#125;;int main() &#123; std::vector&lt;Student&gt; s_arr = &#123;&#123;&quot;Jack&quot;, 99&#125;, &#123;&quot;Alice&quot;, 97&#125;, &#123;&quot;Bob&quot;, 83&#125;, &#123;&quot;Carl&quot;, 100&#125;, &#123;&quot;Clara&quot;, 66&#125;&#125;; std::sort(s_arr.begin(), s_arr.end(), [](const Student&amp; s1, const Student&amp; s2) &#123; return s1.grade &gt; s2.grade; &#125;); // 自定义学生成绩按照降序排序 for (const auto&amp; s : s_arr) &#123; std::cout &lt;&lt; s.name &lt;&lt; &#x27; &#x27; &lt;&lt; s.grade &lt;&lt; &#x27;\\n&#x27;; &#125; // Carl 100 // Jack 99 // Alice 97 // Bob 83 // Clara 66 return 0;&#125; 定义一个匿名函数作为参数的函数： 12345678910111213141516171819#include &lt;iostream&gt;double solve(std::function&lt;double(double)&gt; fn, double left, double right, int n) &#123; // 求一元函数在区间 [left, right] 的定积分 double res = -fn(left) + fn(right); double d = (right - left) / n; for (int i = 0; i &lt; n; i++) &#123; res += 2 * fn(left + i * d) + 4 * fn(left + (i + 0.5) * d); &#125; return d * res / 6;&#125;int main() &#123; std::cout &lt;&lt; solve([](double x) &#123; return x * x * x; &#125;, 0, 1, 10) &lt;&lt; &#x27;\\n&#x27;; // 0.25 return 0;&#125;","categories":[{"name":"C/C++","slug":"C-C","permalink":"http://example.com/categories/C-C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"匿名函数","slug":"匿名函数","permalink":"http://example.com/tags/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"}]},{"title":"树状数组和线段树","slug":"树状数组和线段树","date":"2023-03-29T17:50:01.000Z","updated":"2023-09-10T07:06:00.631Z","comments":true,"path":"2023/03/30/树状数组和线段树/","link":"","permalink":"http://example.com/2023/03/30/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E5%92%8C%E7%BA%BF%E6%AE%B5%E6%A0%91/","excerpt":"","text":"树状数组和线段树是两种常用的数据结构，其可以大大提升数组的区间查询的效率，同时也保证了数据修改的灵活度。 一般数组 前缀和数组 树状数组 线段树 单点查询 \\(O(1)\\) \\(O(1)\\) \\(O(logn)\\) \\(O(logn)\\) 区间查询 \\(O(n)\\) \\(O(1)\\) \\(O(logn)\\) \\(O(logn)\\) 单点修改 \\(O(1)\\) \\(O(n)\\) \\(O(logn)\\) \\(O(logn)\\) 区间修改 \\(O(n)\\) \\(O(n^2)\\) \\(O(nlogn)\\) \\(O(logn)\\) 树状数组 树状数组的原理讲解可以参考视频：五分钟丝滑动画讲解 | 树状数组 用于区间求和和单点修改的树状数组模版 123456789101112131415161718192021222324252627282930313233343536class BIT &#123;private: int n; std::vector&lt;int&gt; tree; inline int lowbit(int x) &#123; // 数状数组第 i 项的区间长度为 lowbit(i) return x &amp; -x; &#125; int count(int m) &#123; // 求前 m 项的和 int res = 0; while (m) &#123; res += tree[m]; m -= lowbit(m); &#125; return res; &#125;public: BIT(int _n): n(_n), tree(_n + 1, 0) &#123;&#125; void add(int idx, int val) &#123; // 单点修改 while (idx &lt;= n) &#123; tree[idx] += val; idx += lowbit(idx); &#125; &#125; int rangeSum(int left, int right) &#123; // 区间求和 return count(right) - count(left - 1); &#125;&#125;; 树状数组的核心就是 lowbit() 函数，数状数组第 i 项代表的区间长度为 lowbit(i) 树状数组的下标只能从 1 开始，不能从 0 开始 用于求前缀最大值的树状数组模版 12345678910111213141516171819202122232425class BIT &#123;private: int n; std::vector&lt;int&gt; tree;public: BIT(int _n): n(_n), tree(_n + 1) &#123;&#125; int query(int idx) &#123; int res = 0; while (idx) &#123; res = std::max(res, tree[idx]); idx &amp;= idx - 1; &#125; return res; &#125; void update(int idx, int val) &#123; while (idx &lt;= n) &#123; tree[idx] = std::max(tree[idx], val); idx += idx &amp; -idx; &#125; &#125;&#125;; 线段树 线段树相对于树状数组而言则更为灵活，其可以实现高效区间修改。 线段树的原理就是将数组的区间储存在二叉树的节点中，[left, right] 区间对应的左右节点分别为 [left, mid] 和 [mid + 1, right]（mid = (left + right) / 2)。 ‼️注：线段树的数组长度要开到原数组长度的 4 倍 用于区间求和的线段树模版 单点更新 区间求和 1234567891011121314151617181920212223242526272829303132333435363738394041424344class SegmentTree &#123;private: int n; std::vector&lt;int&gt; tree; void update(int idx, int val, int node, int start, int end) &#123; // 单点更新 if (start == end) &#123; tree[node] = val; return; &#125; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; if (idx &lt;= mid) &#123; update(idx, val, leftNode, start, mid); &#125; else &#123; update(idx, val, rightNode, mid + 1, end); &#125; tree[node] = tree[leftNode] + tree[rightNode]; &#125; int rangeSum(int left, int right, int node, int start, int end) &#123; // 区间求和 if (start &gt; right || end &lt; left) return 0; if (start &gt;= left &amp;&amp; end &lt;= right) return tree[node]; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; return rangeSum(left, right, leftNode, start, mid) + rangeSum(left, right, rightNode, mid + 1, end); &#125;public: SegmentTree(int _n): n(_n), tree(4 * _n, 0) &#123;&#125; void update(int idx, int val) &#123; update(idx, val, 0, 0, n - 1); &#125; int rangeSum(int left, int right) &#123; return rangeSum(left, right, 0, 0, n - 1); &#125;&#125;; 用于求区间极值的线段树模版 单点更新 区间求极值 1234567891011121314151617181920212223242526272829303132333435363738394041424344class SegmentTree &#123;private: int n; std::vector&lt;int&gt; tree; void update(int idx, int val, int node, int start, int end) &#123; // 单点更新 if (start == end) &#123; tree[node] = val; return; &#125; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; if (idx &lt;= mid) &#123; update(idx, val, leftNode, start, mid); &#125; else &#123; update(idx, val, rightNode, mid + 1, end); &#125; tree[node] = std::max(tree[leftNode], tree[rightNode]); &#125; int maxVal(int left, int right, int node, int start, int end) &#123; // 求区间极大值 if (start &gt; right || end &lt; left) return INT_MIN; if (start &gt;= left &amp;&amp; end &lt;= right) return tree[node]; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; return std::max(maxVal(left, right, leftNode, start, mid), maxVal(left, right, rightNode, mid + 1, end)); &#125;public: SegmentTree(int _n): n(_n), tree(4 * _n, 0) &#123;&#125; void update(int idx, int val) &#123; update(idx, val, 0, 0, n - 1); &#125; int maxVal(int left, int right) &#123; return maxVal(left, right, 0, 0, n - 1); &#125;&#125;; 有时候我们可能会遇到这样的需求：要多次将数组中一个区间内的每个元素都添加一个固定的值，如果逐一修改，则会消耗大量的时间，这个时候我们就可以使用带延迟标记的线段树。 什么是延迟标记？ —— 即对线段树的某个节点的数据更新完后不急于对其子节点进行更新，而是将更新信息存储下来，而当必须更新的时候再将信息传递给子节点。 使用延迟标记进行区间修改的线段树模版 区间修改 区间求和 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class SegmentTree &#123;private: int n; std::vector&lt;int&gt; tree; std::vector&lt;int&gt; lazy; inline void maintain(int node, int start, int end) &#123; // 传递 lazy 标签 int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; tree[leftNode] += (mid - start + 1) * lazy[node]; lazy[leftNode] += lazy[node]; tree[rightNode] += (end - mid) * lazy[node]; lazy[rightNode] += lazy[node]; lazy[node] = 0; &#125; void add(int left, int right, int val, int node, int start, int end) &#123; // 给区间 [left, right] 的所有数添加 val if (start &gt; right || end &lt; left) return; if (start &gt;= left &amp;&amp; end &lt;= right) &#123; tree[node] += (end - start + 1) * val; lazy[node] += val; return; &#125; if (lazy[node]) maintain(node, start, end); int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; add(left, right, val, leftNode, start, mid); add(left, right, val, rightNode, mid + 1, end); tree[node] = tree[leftNode] + tree[rightNode]; &#125; int rangeSum(int left, int right, int node, int start, int end) &#123; // 区间求和 if (start &gt; right || end &lt; left) return 0; if (start &gt;= left &amp;&amp; end &lt;= right) return tree[node]; if (lazy[node]) maintain(node, start, end); int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; return rangeSum(left, right, leftNode, start, mid) + rangeSum(left, right, rightNode, mid + 1, end); &#125;public: SegmentTree(int _n): n(_n), tree(4 * _n), lazy(4 * _n) &#123;&#125; void add(int left, int right, int val) &#123; add(left, right, val, 0, 0, n - 1); &#125; int rangeSum(int left, int right) &#123; return rangeSum(left, right, 0, 0, n - 1); &#125;&#125;; 案例 逆序对记数 题目链接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;algorithm&gt;const int MAX_N = 5e5 + 5;struct &#123; int val; int id;&#125; arr[MAX_N];int rank[MAX_N];namespace __BIT &#123; int bit[MAX_N]; int n; inline int lowbit(int x) &#123; return x &amp; -x; &#125; int query(int idx) &#123; int res = 0; while (idx) &#123; res += bit[idx]; idx -= lowbit(idx); &#125; return res; &#125; void add(int idx, int val) &#123; while (idx &lt;= n) &#123; bit[idx] += val; idx += lowbit(idx); &#125; &#125;&#125;using namespace __BIT;using i64 = long long;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); std::cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) &#123; std::cin &gt;&gt; arr[i].val; arr[i].id = i; &#125; std::sort(arr + 1, arr + n + 1, [](const auto&amp; a1, const auto&amp; a2) &#123; return a1.val != a2.val ? a1.val &lt; a2.val : a1.id &lt; a2.id; &#125;); for (int i = 1; i &lt;= n; i++) rank[arr[i].id] = i; i64 res = 0; for (int i = 1; i &lt;= n; i++) &#123; res += i - 1 - query(rank[i]); add(rank[i], 1); &#125; std::cout &lt;&lt; res &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; 二维数点 题目链接 二维数点是树状数组的一个典型应用，本题的 AC 代码如下： 注：需要开启 O2 优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;iostream&gt;#include &lt;algorithm&gt;const int MAX_N = 5e5 + 5, MAX_M = 5e5 + 5;int n, m;struct Tree &#123; int x; int y;&#125; tree[MAX_N];struct Query &#123; int x; int y; int id; int res;&#125; q[4 * MAX_M];const int MAX_Y = 1e7 + 7;namespace __BIT &#123; int bit[MAX_Y]; int len; inline int lowbit(int x) &#123; return x &amp; -x; &#125; int query(int idx) &#123; idx = idx &lt;= len ? idx : len; int res = 0; for (int i = idx; i; i -= lowbit(i)) res += bit[i]; return res; &#125; void add(int idx, int val) &#123; for (int i = idx; i &lt;= len; i += lowbit(i)) bit[i] += val; &#125;&#125;using namespace __BIT;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); std::cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) &#123; std::cin &gt;&gt; tree[i].x &gt;&gt; tree[i].y; tree[i].x++, tree[i].y++; len = std::max(len, tree[i].y); &#125; std::sort(tree, tree + n, [](const Tree&amp; t1, const Tree&amp; t2) &#123; return t1.x &lt; t2.x; &#125;); int all = 4 * m; for (int i = 0, a, b, c, d; i &lt; all; i += 4) &#123; std::cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d; a++, b++, c++, d++; q[i] = &#123;c, d, i&#125;; q[i + 1] = &#123;a - 1, d, i + 1&#125;; q[i + 2] = &#123;c, b - 1, i + 2&#125;; q[i + 3] = &#123;a - 1, b - 1, i + 3&#125;; &#125; std::sort(q, q + all, [](const Query&amp; q1, const Query&amp; q2) &#123; return q1.x &lt; q2.x; &#125;); int j = 0; for (int i = 0; i &lt; n; i++) &#123; while (j &lt; all &amp;&amp; tree[i].x &gt; q[j].x) &#123; // 当前范围已经统计结束 q[j].res = query(q[j].y); j++; &#125; add(tree[i].y, 1); &#125; while (j &lt; all) &#123; q[j].res = query(q[j].y); j++; &#125; std::sort(q, q + all, [](const Query&amp; q1, const Query&amp; q2) &#123; return q1.id &lt; q2.id; &#125;); for (int i = 0; i &lt; all; i += 4) &#123; std::cout &lt;&lt; q[i].res - q[i + 1].res - q[i + 2].res + q[i + 3].res &lt;&lt; &#x27;\\n&#x27;; &#125; return 0;&#125; 统计最长递增子序列 题目链接 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;private: int n; std::vector&lt;int&gt; tree; int query(int idx) &#123; int res = 0; while (idx) &#123; res = std::max(res, tree[idx]); idx &amp;= idx - 1; &#125; return res; &#125; void update(int idx, int val) &#123; while (idx &lt;= n) &#123; tree[idx] = std::max(tree[idx], val); idx += idx &amp; -idx; &#125; &#125;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); this-&gt;n = n; tree.resize(n + 1); std::vector&lt;std::pair&lt;int, int&gt;&gt; p(n); for (int i = 0; i &lt; n; i++) &#123; p[i].first = nums[i]; p[i].second = i + 1; &#125; std::sort(p.begin(), p.end(), [](const std::pair&lt;int, int&gt;&amp; p1, const std::pair&lt;int, int&gt;&amp; p2) &#123; return p1.first != p2.first ? p1.first &lt; p2.first : p1.second &gt; p2.second; &#125;); for (const auto&amp; [_, idx] : p) &#123; update(idx, query(idx) + 1); &#125; return query(n); &#125;&#125;; 其他 网格图中最少访问的格子数（线段树 单点修改 + 区间查询） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class SegTree &#123;// 单点修改 + 区间查询private: int n; vector&lt;int&gt; tree; void update(int idx, int val, int node, int start, int end) &#123; if (start == end) &#123; tree[node] = val; return; &#125; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; if (idx &lt;= mid) &#123; update(idx, val, leftNode, start, mid); &#125; else &#123; update(idx, val, rightNode, mid + 1, end); &#125; tree[node] = min(tree[leftNode], tree[rightNode]); &#125; int query(int left, int right, int node, int start, int end) &#123; if (start &gt; right || end &lt; left) return INT_MAX; if (start &gt;= left &amp;&amp; end &lt;= right) return tree[node]; int leftNode = 2 * node + 1, rightNode = 2 * node + 2; int mid = (start + end) / 2; return min(query(left, right, leftNode, start, mid), query(left, right, rightNode, mid + 1, end)); &#125;public: SegTree(int _n): n(_n), tree(4 * _n, INT_MAX) &#123;&#125; void update(int idx, int val) &#123; update(idx, val, 0, 0, n - 1); &#125; int query(int left, int right) &#123; return query(left, right, 0, 0, n - 1); &#125;&#125;;class Solution &#123;public: int minimumVisitedCells(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int m = grid.size(), n = grid[0].size(); SegTree trRow(m * n); SegTree trCol(n * m); trRow.update(m * n - 1, 0); trCol.update(n * m - 1, 0); for (int i = m - 1; i &gt;= 0; i--) &#123; for (int j = n - 1; j &gt;= 0; j--) &#123; int resRow = trRow.query(n * i + j, n * i + min(j + grid[i][j], n - 1)); // (i, j) ~ (i, j + grid[i][j]) 中的最小值 int resCol = trCol.query(m * j + i, m * j + min(i + grid[i][j], m - 1)); // (i, j) ~ (i + grid[i][j], j) 中的最小值 int res = min(resRow, resCol); if (res != INT_MAX) &#123; trRow.update(n * i + j, res + 1); trCol.update(m * j + i, res + 1); &#125; &#125; &#125; int ans = trRow.query(0, 0); return ans != INT_MAX ? ans : -1; &#125;&#125;;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"线段树","slug":"线段树","permalink":"http://example.com/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"},{"name":"树状数组","slug":"树状数组","permalink":"http://example.com/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"区间查询","slug":"区间查询","permalink":"http://example.com/tags/%E5%8C%BA%E9%97%B4%E6%9F%A5%E8%AF%A2/"}]},{"title":"std::bitset 讲解","slug":"std-bitset 详解","date":"2023-03-08T08:46:06.000Z","updated":"2023-07-10T08:08:19.964Z","comments":true,"path":"2023/03/08/std-bitset 详解/","link":"","permalink":"http://example.com/2023/03/08/std-bitset%20%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"介绍 std::bitset 是 C++ 提供的一种 n-bit 固定大小序列的模版，可以用于标准逻辑运算，并且可以与字符串和整数相互转换，还可以使用标准流输出。 12template&lt; std::size_t N &gt;class bitset; 模版形参 N ：要为 bitset 分配储存的 bit 位数 头文件：&lt;bitset&gt; 构造方法 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;bitset&gt;int main() &#123; // 1. 无参构造 std::bitset&lt;5&gt; testCase_1; std::cout &lt;&lt; testCase_1 &lt;&lt; std::endl; // 00000 // 2. 传入整数 std::bitset&lt;4&gt; testCase_2&#123;0xb&#125;; std::cout &lt;&lt; testCase_2 &lt;&lt; std::endl; // 1011 std::bitset&lt;4&gt; testCase_3&#123;0x10&#125;; // 溢出位自动截断 std::cout &lt;&lt; testCase_3 &lt;&lt; std::endl; // 0000 // 3. 传入字符串 std::bitset&lt;8&gt; testCase_4&#123;&quot;10010101&quot;&#125;; // 传入 0-1 字符串 std::cout &lt;&lt; testCase_4 &lt;&lt; std::endl; // 10010101 std::bitset&lt;4&gt; testCase_5&#123;&quot;10010101&quot;&#125;; // 溢出位截断，只取前 4 位 std::cout &lt;&lt; testCase_5 &lt;&lt; std::endl; // 1001 std::bitset&lt;8&gt; testCase_6&#123;&quot;ABABA&quot;, /* 读取长度 */4, /* 代表 0 的字符 */&#x27;A&#x27;, /* 代表 1 的字符 */&#x27;B&#x27;&#125;; // 00000101 std::cout &lt;&lt; testCase_6 &lt;&lt; std::endl; // 4. 支持赋值构造以及整数和字符串到 bitset 的强制类型转化 std::bitset&lt;8&gt; testCase_7 = testCase_6; std::cout &lt;&lt; testCase_7 &lt;&lt; std::endl; // 00000101 std::cout &lt;&lt; (std::bitset&lt;8&gt;)0xf &lt;&lt; std::endl; // 00001111 std::cout &lt;&lt; (std::bitset&lt;8&gt;)&quot;1111&quot; &lt;&lt; std::endl; // 00001111 std::bitset&lt;10&gt; testCase_8 = 0x7f; std::cout &lt;&lt; testCase_8 &lt;&lt; std::endl; // 0001111111 return 0;&#125; 成员方法 支持下标 operator[] 123std::bitset&lt;10&gt; num = (std::bitset&lt;10&gt;)&quot;111011&quot;;std::cout &lt;&lt; num[2] &lt;&lt; std::endl; // 0// 从低位开始 bitset 支持所有常规位运算操作 123456789101112std::bitset&lt;10&gt; num = 0xf;std::cout &lt;&lt; (num &amp; (std::bitset&lt;10&gt;)0x12) &lt;&lt; std::endl; // 0000000010std::cout &lt;&lt; (num | (std::bitset&lt;10&gt;)0x12) &lt;&lt; std::endl; // 0000011111std::cout &lt;&lt; (num ^ (std::bitset&lt;10&gt;)0x12) &lt;&lt; std::endl; // 0000011101std::cout &lt;&lt; (num &lt;&lt; 2) &lt;&lt; std::endl; // 0000111100std::cout &lt;&lt; (num &gt;&gt; 2) &lt;&lt; std::endl; // 0000000011num = -1;std::cout &lt;&lt; num &lt;&lt; std::endl; // 1111111111std::cout &lt;&lt; (num &gt;&gt; 2) &lt;&lt; std::endl; // 0011111111// 对 bitset 的右移都是逻辑右移 set() ：设置单独位的值 123std::bitset&lt;10&gt; num = -1;num.set(0, false); // 将下标为 0 的位设置为 0std::cout &lt;&lt; num &lt;&lt; std::endl; // 1111111110 flip() ：取反，无参数时默认对全部位 12345std::bitset&lt;10&gt; num = 0xf;num.flip();std::cout &lt;&lt; num &lt;&lt; std::endl; // 1111110000num.flip(1);std::cout &lt;&lt; num &lt;&lt; std::endl; // 1111110010 检查位 all() ：判断是否所有位都为 1 any() ：判断是否有任意一位为 1 none() ：判断是否所有位为 0 12345std::bitset&lt;4&gt; num = 0x7;std::cout &lt;&lt; num.all() &lt;&lt; std::endl; // 0std::cout &lt;&lt; num.any() &lt;&lt; std::endl; // 1std::cout &lt;&lt; num.none() &lt;&lt; std::endl; // 0 count() ：返回 1 的数量 123std::bitset&lt;4&gt; num = 0x7;std::cout &lt;&lt; num.count() &lt;&lt; std::endl; // 3 size() ：返回位数 12std::bitset&lt;10&gt; num;std::cout &lt;&lt; num.size() &lt;&lt; std::endl; // 10 转换： to_string() ：返回数据的字符串类型 to_ulong ：返回数据的 unsigned long 整数表示 to_ullong ：返回数据的 unsigned long long 整数表示 12345678std::bitset&lt;8&gt; num_bit = 0xf;unsigned long num_1 = num_bit.to_ulong();unsigned long long num_2 = num_bit.to_ullong();std::string str = num_bit.to_string();std::cout &lt;&lt; num_1 &lt;&lt; std::endl; // 15std::cout &lt;&lt; num_2 &lt;&lt; std::endl; // 15std::cout &lt;&lt; str &lt;&lt; std::endl; // 00001111 ​","categories":[{"name":"C/C++","slug":"C-C","permalink":"http://example.com/categories/C-C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"STL","slug":"STL","permalink":"http://example.com/tags/STL/"}]},{"title":"链式前向星介绍","slug":"链式前向星介绍","date":"2023-03-06T08:42:40.000Z","updated":"2023-07-10T08:24:40.172Z","comments":true,"path":"2023/03/06/链式前向星介绍/","link":"","permalink":"http://example.com/2023/03/06/%E9%93%BE%E5%BC%8F%E5%89%8D%E5%90%91%E6%98%9F%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"什么是链式前向星？ 链式前向星是一种常用的图存储结构，其思路类似于邻接链表法，只是实现方式有所不同，链式向前星更像是用数组模拟链表。 与一般的邻接链表法不同，链式向前星储存的图的每条边都有编号。 以下是链式前向星的存储结构： cnt ：用来记录当前所有边的数量 first 数组：用来存储从某个节点出发的第一条边，例如 first[0] == 3 可以得出从 0 号节点出发的第一条边的编号为 3 edges 数组：用来记录每条边的信息，对于每个 edges[i] 都有 3 个域： to ：记录边的终点 weight ：记录边的权重 next ：记录从当前起点出发下一条边的编号，例如：若 edges[i] 的起点为 j 号节点，则 edges[i].next 表示从 j 出发的下一条边 示例： 如上图，这就是链式向前星存储图的方式了，其中编号为 -1 的边表示不存在，即没有其他的出边。 若我们需要新增一条从 i 到 j 的边，只需更新在 edges 数组内增加元素并且使其新增边的 next 等于 first[i] ，然后更新 first[i] 为新增的边的编号即可。 代码 12345678910111213141516171819202122232425262728293031#define MAX_VERTEX 100000#define MAX_EDGE 100000int cnt; // 边的数量int first[MAX_VERTEX]; // first 数组struct &#123; int to; int weight; int next;&#125; edges[MAX_EDGE]; // 记录边void initEdge() &#123; cnt = 0; // 初始化，将 first 数组全初始化为 -1 memset(first, 0xff, sizeof(first));&#125;void addEdge(int from, int to, int weight) &#123; edges[cnt] = &#123;to, weight, first[from]&#125;; // 新增边 first[from] = cnt; // 更新 first 数组 cnt++; // 边数增加&#125;void traverseEdgeFrom(int v) &#123; // 遍历从 v 出发的所有边 for (int p = first[v]; p != -1; p = edges[p].next) &#123; std::cout &lt;&lt; &quot;eNo: &quot; &lt;&lt; p &lt;&lt; &quot; to: &quot; &lt;&lt; edges[p].to &lt;&lt; &quot; weight: &quot; &lt;&lt; edges[p].weight &lt;&lt; std::endl; &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"图论","slug":"图论","permalink":"http://example.com/tags/%E5%9B%BE%E8%AE%BA/"},{"name":"链式前向星","slug":"链式前向星","permalink":"http://example.com/tags/%E9%93%BE%E5%BC%8F%E5%89%8D%E5%90%91%E6%98%9F/"}]},{"title":"ICG 游戏博弈问题与 SG 定理","slug":"ICG 游戏博弈问题与 SG 定理","date":"2023-03-02T05:07:17.000Z","updated":"2023-07-10T08:25:45.820Z","comments":true,"path":"2023/03/02/ICG 游戏博弈问题与 SG 定理/","link":"","permalink":"http://example.com/2023/03/02/ICG%20%E6%B8%B8%E6%88%8F%E5%8D%9A%E5%BC%88%E9%97%AE%E9%A2%98%E4%B8%8E%20SG%20%E5%AE%9A%E7%90%86/","excerpt":"","text":"ICG 游戏 定义 ICG 游戏是博弈游戏的一种，其定义如下： 游戏由两人参加，两人轮流做出决策 当有一人无法决策即无论如何都必败时对手胜出，且 ICG 游戏一定会在有限步内完成，游戏没有平局 游戏的状态转移是单向的，同一个状态只能达到一次 必胜点和必败点 必胜点 N ( Next ) 和必败点 P ( Previous ) 描述的是某个游戏状态当前的胜负。 若当前状态为必胜点 N ，则先手必胜，反之，若当前状态为必败点 P ，则先手必败。 可能到这里为止大家还是会觉得比较抽象，所以我们给出一个实际例子： 假设有一堆石头，两人轮流从这堆石头中取走 1 ~ 5 块石头，初始状态下有 n 块石头，问 n 为何值时先手必胜？ 先说结论：n % 6 != 0 时先手必胜。 原因十分简单，若 n 不是 6 的倍数，则先手一定可以取走 1 ～ 5 块内的石头使得取走石头后这堆石头的数量能被 6 整除，此后，对手只要取走 m 块石头，我们就取走 6 - m 块石头，可以保证我们每次取完后石头的数量都是 6 的倍数。如此一来，最后的石头一定是被我们取走。 于是，我们可以得到石头数量 n 对应的 NP 状态： n 0 1 2 3 4 5 6 7 8 9 ... state P N N N N N P N N N ... 在这里，我们不难得出结论： 所有必胜点必然可以在一步操作内转移到必败点 所有必败点无论如何操作只能转移到必胜点 SG 定理 SG 是 Sprague-Grundy 的缩写，SG 定理是处理 ICG 博弈问题的重要方法，在讲解其使用之前，我们先简要介绍一下 SG 函数的定义。 SG 函数 首先我们定义 \\(mex\\) ( minimal excludant ) 运算，\\(mex(F)\\) 即表示不属于非负整数集 \\(F\\) 中最小的元素： 例如： \\[ \\begin{array}{} mex(\\{1, 2, 3\\}) = 0 \\\\ mex(\\{0, 1, 3, 4\\}) = 2 \\\\ mex(\\emptyset) = 0 \\end{array} \\] 什么是 SG 值？ SG 值是一种通过递归定义的值，它一般情况下是一个非负整数，可以用来描述游戏状态是必胜点还是必败点，假设游戏状态 \\(V_i\\) 的 SG 值为 \\(SG(V_i)\\) ，那么其状态转移方程如下： \\[ SG(V_i) = mex(\\{SG(V_j) \\ | \\ V_i \\rightarrow V_j \\}) \\] 其数值上等于与 \\(V_i\\) 所有后继状态的 SG 值不相等的最小非负整数。 基于此，我们得到一条重要结论：SG 值不为 0 的状态为必胜点，SG 值为 0 的状态为必败点。 这个结论很好证明：若 SG 值不为 0，说明该状态一定能一步转移到 SG 值为 0 的状态，即可以一步转移到必败点，所以该状态一定为必胜点；反之，若 SG 值为 0，则该状态无法一步转移到必败点，只能转移到必胜点或者无法决策，故该点一定为必败点。 我们还是用上述的取石头问题来举例说明，则不同石头数量 n 对应的 SG 值如下： n 0 1 2 3 4 5 6 7 8 9 10 SG(n) 0 1 2 3 4 5 0 1 2 3 4 \\[ \\begin{array}{} SG(0) = mex(\\emptyset) = 0 \\\\ SG(1) = mex(\\{0\\}) = 1 \\\\ SG(2) = mex(\\{0, 1\\}) = 2 \\\\ SG(3) = mex(\\{0, 1, 2\\}) = 3 \\\\ SG(4) = mex(\\{0, 1, 2, 3\\}) = 4 \\\\ SG(5) = mex(\\{0, 1, 2, 3, 4\\}) = 5 \\\\ SG(6) = mex(\\{1, 2, 3, 4, 5\\}) = 0 \\\\ ... \\newline SG(10) = mex(\\{5, 0, 1, 2, 3\\}) = 4 \\\\ ... \\end{array} \\] SG 定理详解 现在我们已经知道了 SG 函数的定义，那 SG 定理又是什么呢？ 什么是 SG 定理 ? SG 定理指的是若一个 ICG 博弈游戏的游戏状态可以分为多个子状态，且子状态互相独立，则该游戏状态下的 SG 值等于所有子状态的 SG 值的异或值。 这又是什么意思呢？别急，我们还是用取石头的例子来说明： 假设现在有 \\(k\\) 堆石头，每堆石头有 \\(n_i(i = 1, 2, ...,k)\\) 块石头 ，两个人轮流从每一堆石头中取走 \\([1, m]\\) 块石头，先取完所有石头的一方获胜。我们设此刻游戏状态的 SG 值为 \\(SG((n_1, n_2, ..., n_k))\\) ，由 SG 定理可得： \\[ SG((n_1, n_2, ..., n_k)) = SG(n_1) \\oplus SG(n_2) \\oplus ... \\oplus SG(n_k) \\] \\(SG((n_1, n_2, ..., n_k)) \\neq 0\\) ：先手胜 \\(SG((n_1, n_2, ..., n_k)) = 0\\) ：先手败 以上就是完整的 SG 定理了。 SG 定理的合理性 为什么 SG 定理会与位运算的异或有关呢？它们是如何联系上的？为什么这种计算是合理的呢？ 以下我们给出简要的证明： 根据 SG 值的定义，必败点的 SG 值一定为 0，对于此题而言，游戏的终点就是所有的石头被取完，此时 SG 值是 k 个 0 的异或值，显然为 0。 若当前的 SG 值不为 0，我们假设： \\[ SG((n_1, n_2, ..., n_k)) = {001010..}_2 \\] 我们找到该 SG 值数值为 1 的最高位，由异或运算符的性质，必然存在奇数个子状态的 SG 值该位为 1，我们不妨假设其中一个子状态对应的 SG 值为 \\(SG_0\\) ，由 SG 值的定义，该状态一定可以一步之内转变为任何 SG 值小于 \\(SG_0\\) 的状态，\\(SG_0\\) 对应母状态下数值为 1 的最高位的值也为 1，我们让其变为 0，然后从这一位开始之后全部位取反，则一定可以将母状态的 SG 值变为 0。 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 如上，我们将第二个子状态 的 SG 值转移到 0 0 0 1 1 1，就将母状态的 SG 值转化为 0 了 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 反之，如果母状态的 SG 值为 0，则改变任何一个子状态，由于异或运算的性质，母状态的 SG 值一定无法维持为 0。 而根据 ICG 博弈游戏的定义，游戏一定会在有限步内完成，故所有子状态 SG 值的异或运算不为 0 的母状态一定是必胜点。 实际应用 Fibonacci again and again Problem Description 任何一个大学生对菲波那契数列(Fibonacci numbers)应该都不会陌生，它是这样定义的： F(1) = 1； F(2) = 2； F(n) = F(n - 1) + F(n - 2) ( n &gt;= 3 )； 所以，1, 2, 3, 5, 8, 13, ... 就是菲波那契数列。 今天，又一个关于 Fibonacci 的题目出现了，它是一个小游戏，定义如下： 这是一个二人游戏； 一共有 3 堆石子，数量分别是 m, n, p 个； 两人轮流走； 每走一步可以选择任意一堆石子，然后取走f个； f 只能是菲波那契数列中的元素 ( 即每次只能取1，2，3，5，8 … 等数量 )； 最先取光所有石子的人为胜者； 假设双方都使用最优策略，请判断先手的人会赢还是后手的人会赢。 Input 输入数据包含多个测试用例，每个测试用例占一行，包含 3 个整数 m, n, p ( 1 &lt;= m, n, p &lt;= 1000 )。 m = n = p = 0 则表示输入结束。 Output 如果先手的人能赢，请输出“Fibo”，否则请输出“Nacci”，每个实例的输出占一行。 输入样例 1231 1 11 4 10 0 0 输出样例 12FiboNacci 分析： 本题所描述的游戏就是一种 ICG 博弈，且三堆石头互不影响，所以我们可以直接使用 SG 定理求解，再加上记忆化 DFS 优化，很容易就能求解此问题。废话不多说，直接上代码😎。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;#define MAX_FIB_NUM 50#define MAX_AMOUNT 1005int Fibonacci[MAX_FIB_NUM]; // 储存 Fibonacci 数列的值int SG[MAX_AMOUNT]; // 记录 SG 值，初始化为 -1// 记忆化搜索int fib(int n) &#123; if (Fibonacci[n]) &#123; return Fibonacci[n]; &#125; if (n == 0) &#123; Fibonacci[n] = 1; return 1; &#125; else if (n == 1) &#123; Fibonacci[n] = 2; return 2; &#125; Fibonacci[n] = fib(n - 1) + fib(n - 2); // 记忆 return Fibonacci[n];&#125;int sg(int n) &#123; // 返回 SG 值 if (SG[n] &gt;= 0) &#123; return SG[n]; &#125; if (n == 0) &#123; SG[n] = 0; return 0; &#125; bool vis[MAX_AMOUNT] = &#123;0&#125;; // 记录当前状态可达状态的 SG 值是否出现过 for (int i = 0; n - fib(i) &gt;= 0; i++) &#123; vis[sg(n - fib(i))] = true; // 记录已出现的 SG 值 &#125; for (int i = 0; i &lt; MAX_AMOUNT; i++) &#123; if (!vis[i]) &#123; SG[n] = i; break; &#125; &#125; return SG[n];&#125;int main() &#123; ios::sync_with_stdio(false); memset(SG, 0xff, sizeof(SG)); // 初始化 int m, n, p; while (cin &gt;&gt; m &gt;&gt; n &gt;&gt; p, m != 0 || n != 0 || p != 0) &#123; if (sg(m) ^ sg(n) ^ sg(p)) &#123; // SG 定理 cout &lt;&lt; &quot;Fibo&quot; &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; &quot;Nacci&quot; &lt;&lt; endl; &#125; &#125; return 0;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"SG 定理","slug":"SG-定理","permalink":"http://example.com/tags/SG-%E5%AE%9A%E7%90%86/"},{"name":"SG 函数","slug":"SG-函数","permalink":"http://example.com/tags/SG-%E5%87%BD%E6%95%B0/"},{"name":"组合博弈","slug":"组合博弈","permalink":"http://example.com/tags/%E7%BB%84%E5%90%88%E5%8D%9A%E5%BC%88/"},{"name":"组合数学","slug":"组合数学","permalink":"http://example.com/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"},{"name":"记忆化搜索","slug":"记忆化搜索","permalink":"http://example.com/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"},{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"}]},{"title":"记忆化 DFS","slug":"记忆化 DFS","date":"2023-02-26T15:47:02.000Z","updated":"2023-11-15T18:23:34.073Z","comments":true,"path":"2023/02/26/记忆化 DFS/","link":"","permalink":"http://example.com/2023/02/26/%E8%AE%B0%E5%BF%86%E5%8C%96%20DFS/","excerpt":"","text":"引入 记忆化 DFS，顾名思义，就是带有记忆的深度优先搜索。 总所周知，用程序实现 Fibonacci 数列求值有两种常见方式： 通过迭代即非递归的方式： 12345678910111213int Fibonacci(int n) &#123; if (n == 1 || n == 2) &#123; return 1; &#125; int pre = 1, next = 1, sum = 0; while (n-- &gt; 2) &#123; sum = pre + next; pre = next; next = sum; &#125; return sum;&#125; 通过递归方式： 123456int Fibonacci(int n) &#123; if (n == 1 || n == 2) &#123; return 1; &#125; return Fibonacci(n - 1) + Fibonacci(n - 2);&#125; 上述两种方式各有优缺点，迭代方式效率更高，但是写起来比较麻烦；递归方式运行效率低，但是代码实现容易。 有没有一种方式可以结合两者的优点呢？ 对于第二种递归方式，其主要的时间开销在于计算了许多重复内容，我们是否可以使用一个数组来维护已经计算过的值呢？ 答案是显然的，于是我们就有了 —— 记忆化 DFS： 123456789101112131415int fib[MAX_NUM]; // 记忆数组int Fibonacci(int n) &#123; if (fib[n]) &#123; return fib[n]; // 已经计算过的值直接返回 &#125; if (n == 1 || n == 2) &#123; fib[n] = 1; &#125; else &#123; fib[n] = Fibonacci(n - 1) + Fibonacci(n - 2); &#125; return fib[n];&#125; 以上代码以递归的方式实现，但是时间复杂度可以降到线性，和迭代形式一样，不同的地方在于我们需要额外的空间开销来记录已经计算过的值。 可能有同学就有疑问了： 上述例子很容易用 DP 来实现，为什么还需要记忆化 DFS 呢？ 接下来我们将给出几个实际例子加以说明。 实例分析 案例一 猫和老鼠 Problem Description 有个小老鼠在校园里收藏了一些它最爱吃的奶酪。 校园可以看成一个长度为n的正方形网格，每个网格可以标记为 (p, q) ，其中，0 &lt;= p , q &lt; n。每个网格都有一个洞，里面储存了 k（0 &lt;= k &lt;= 100）块奶酪。 现在，小老鼠准备享用这些美味啦。 开始的时候，他在 (0, 0) 这个位置，每到一个地方，它都会吃光这个地方的奶酪，然后沿着水平或者垂直的方向到达另外一个地方。麻烦的是，有个很凶的猫总是在它的洞口附近，所以他每次最多移动 k 个位置，否则就会被这只猫吃掉。更糟糕的是，每在一个地方吃过奶酪，小老鼠都会变胖，所以，为了获得足够下一次逃跑的能量，它每次只能去比当前位置的奶酪更多的格子。 现在已知 n 和 k ，以及在每个网格的洞中小老鼠储存的奶酪的数量，请计算小老鼠在无法移动之前，一共最多能吃到多少块奶酪。 Input 题目包含多组测试数据。 每组测试数据组成如下： 首先一行包含2个不超过100的正整数 n 和 k ; 接下来 n 行，每行包含n个数： 第一行 n 个数分别表示 (0, 0), (0, 1), … (0, n - 1) 这些位置储存的奶酪数量； 第二行 n 个数分别表示 (1, 0), (1, 1), … (1, n - 1) 这些位置储存的奶酪数量； 以此类推... 输入数据以两个 -1 结束。 Output 请输出小老鼠最多 能够吃到的奶酪数量，每组数据输出一行。 输入案例： 123453 11 2 510 11 612 12 7-1 -1 输出案例： 137 分析： 根据题意，我们假设从 \\((x, y)\\) 出发的老鼠可以吃到的最大奶酪数量为 \\(ans(x, y)\\)，\\((x, y)\\) 处的芝士储量为 \\(cheese(x, y)\\)，老鼠可以从 \\((x, y)\\) 出发在一次 \\(k\\) 步以内的移动中到达的坐标的集合为 \\(S = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3), ...\\}\\)，不难得出状态转移方程： \\[ ans(x, y) = max_{(x_n, y_n) \\in S} ans(x_n, y_n) \\ + \\ cheese(x, y) \\] 如果直接用动态规划求解，这个问题的处理会相当复杂，因为我们难以从该状态转移方程中确定 DP 的起点和 DP 的方向，所以直接采用迭代的方式恐怕不现实。 于是我们便考虑到可以使用记忆化 DFS，既保证了效率，又降低了编码难度。 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;vector&gt;#include &lt;array&gt;using namespace std;#define MAX_LENG 105int cheese[MAX_LENG][MAX_LENG];int ans[MAX_LENG][MAX_LENG]; // 储存结果，初始化为 -1int n, k;const vector&lt;array&lt;int, 2&gt;&gt; dirs = &#123; &#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;&#125;; // 运动方向int dfs(int x, int y) &#123; // 记忆化 DFS // 返回以 (x, y) 为起点可以吃到最多的奶酪 if (ans[x][y] &gt;= 0) &#123; // 已经计算过的值 return ans[x][y]; &#125; ans[x][y] = cheese[x][y]; int plusCheese = 0; for (auto&amp; dir :dirs) &#123; for (int s = 1; s &lt;= k; s++) &#123; int nx = x + s * dir[0]; int ny = y + s * dir[1]; if (nx &gt;= 0 &amp;&amp; nx &lt; n &amp;&amp; ny &gt;= 0 &amp;&amp; ny &lt; n &amp;&amp; cheese[nx][ny] &gt; cheese[x][y]) &#123; plusCheese = max(plusCheese, dfs(nx, ny)); &#125; &#125; &#125; ans[x][y] += plusCheese; return ans[x][y];&#125;int main() &#123; ios::sync_with_stdio(false); while (cin &gt;&gt; n &gt;&gt; k, n != -1 || k != -1) &#123; memset(ans, 0xff, sizeof(ans)); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; cin &gt;&gt; cheese[i][j]; &#125; &#125; cout &lt;&lt; dfs(0, 0) &lt;&lt; endl; &#125; return 0;&#125; 案例二 How many ways Problem Description 这是一个简单的生存游戏，你控制一个机器人从一个棋盘的起始点 (1, 1) 走到棋盘的终点 (n, m)。游戏的规则描述如下： 机器人一开始在棋盘的起始点并有起始点所标有的能量。 机器人只能向右或者向下走，并且每走一步消耗一单位能量。 机器人不能在原地停留。 当机器人选择了一条可行路径后，当他走到这条路径的终点时，他将只有终点所标记的能量。 img 如上图，机器人一开始在 (1, 1) 点，并拥有4单位能量，蓝色方块表示他所能到达的点，如果他在这次路径选择中选择的终点是 (2, 4) ，当他到达 (2, 4) 点时将拥有1单位的能量，并开始下一次路径选择，直到到达 (6, 6) 点。 我们的问题是机器人有多少种方式从起点走到终点。这可能是一个很大的数，输出的结果对 10000 取模。 Input 第一行输入一个整数T,表示数据的组数。 对于每一组数据第一行输入两个整数 n, m (1 &lt;= n, m &lt;= 100)。表示棋盘的大小。接下来输入 n 行,每行 m 个整数 e (0 &lt;= e &lt; 20)。 Output 对于每一组数据输出方式总数对10000取模的结果。 输入案例： 1234567816 64 5 6 6 4 32 2 3 1 7 21 1 4 6 2 75 8 4 3 9 57 6 6 2 1 53 1 1 3 7 2 输出案例： 13948 分析： 同案例一，我们只需找到状态转移方程后使用记忆化 DFS 即可，这里不再赘述。 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int T; // 数据组数int n, m;#define MAX_LENG 105#define MAX_NUM 10000int energy[MAX_LENG][MAX_LENG]; // 记录每个格点点能量int ans[MAX_LENG][MAX_LENG]; // 记录答案，初始化为 -1int dfs(int x, int y) &#123; // 表示从 (x, y) 出发到终点又多少种走法 if (ans[x][y] &gt;= 0) &#123; return ans[x][y]; &#125; if (x == n - 1 &amp;&amp; y == m - 1) &#123; ans[x][y] = 1; return ans[x][y]; &#125; int power = energy[x][y]; // 能量 ans[x][y] = 0; for (int i = 0; i &lt;= power; i++) &#123; for (int j = 0; j &lt;= power - i; j++) &#123; // 遍历所有可能位置 int nx = x + i, ny = y + j; if (nx != x || ny != y) &#123; if (nx &gt;= 0 &amp;&amp; nx &lt; n &amp;&amp; ny &gt;= 0 &amp;&amp; ny &lt; m) &#123; ans[x][y] = (ans[x][y] + dfs(nx, ny)) % MAX_NUM; &#125; &#125; &#125; &#125; return ans[x][y];&#125;int main() &#123; ios::sync_with_stdio(false); cin &gt;&gt; T; while (T--) &#123; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; cin &gt;&gt; energy[i][j]; &#125; &#125; memset(ans, 0xff, sizeof(ans)); cout &lt;&lt; dfs(0, 0) &lt;&lt; endl; &#125; return 0;&#125; 在 Python 中的简单实现 在 Python 中，实现记忆化搜索的一个简单方式是使用 functools 模块中的 lru_cache 装饰器。这个装饰器可以告诉 Python 缓存函数的输出值，以便相同的输入参数在后续调用中不需要重新计算。 基本的函数声明如下： 12345from functools import lru_cache@lru_cache(maxsize=None)def f(x): # 函数体 在这个例子中，@lru_cache(maxsize=None) 是一个装饰器，它应用于函数 f。这个装饰器会缓存 f 的调用结果，以便相同的输入 x 在将来的调用中可以直接从缓存中获取结果，而不需要重新计算。 maxsize 参数用于指定缓存的大小。如果设置为 None，缓存的大小是无限的，这意味着除非显式清除，否则所有的调用都会被缓存。 如果你想限制缓存的大小，可以设置 maxsize 为一个正整数，这将限制缓存的大小，当达到最大值时，最旧的结果将被移除。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"记忆化搜索","slug":"记忆化搜索","permalink":"http://example.com/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"},{"name":"DFS","slug":"DFS","permalink":"http://example.com/tags/DFS/"}]},{"title":"二分匹配问题 —— 匈牙利算法","slug":"二分匹配算法详解","date":"2023-02-24T17:21:01.000Z","updated":"2023-07-26T17:39:24.427Z","comments":true,"path":"2023/02/25/二分匹配算法详解/","link":"","permalink":"http://example.com/2023/02/25/%E4%BA%8C%E5%88%86%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"问题介绍 什么是二分图？ 对于图 \\(G(V,E)\\) 而言，若 \\(G\\) 中的所有点可以划分为两个子集 \\(G_1\\)、\\(G_2\\) ，且图中每条边 \\(e\\) 关联的两个顶点都属于不同的顶点子集，这样的图我们称为二分图（ Bipartite Graph ），或者二部图。 最大匹配问题和最小点覆盖问题 什么是最大匹配问题？给定一个二分图 \\(G(V,E)\\)，若 \\((a_i,b_j) \\in E\\) ，我们就称 \\(a_i\\) 和 \\(b_j\\) 是可配对的，已知该图中任意顶点至多匹配一个顶点，求最大匹配数。如下图，不难看出该图的最大匹配数为 2。其中一种匹配方式为 \\((a_1, b_1)\\)、\\((a_3, b_4)\\) 。 什么又是最小点覆盖问题呢？即从二分图中删除最少的顶点，使得图 \\(G\\) 中任何一对点都无法匹配。删除顶点的最小数量称为最小点覆盖数。如下图，不难看出最小覆盖数也是 2。我们可以删去 \\(a_3\\) 和 \\(b_1\\) 使得图中任何一对点都无法匹配。 这两个问题看似不一样，实际上实际上是处理一个相同的问题。为什么这么说呢？因为我们可以证明一条重要性质： 最大匹配数 = 最小覆盖数 具体证明就不在这里说明了，笔者打算以后单独出一期文章来证明该性质。 那我们该如何给出二分匹配问题的一般解决方案呢？1955 年，库恩（ W.W.Kuhn ）利用一个匈牙利数学家康哥尼（ D.Kőnig ）的一个定理构造了一种二分匹配问题的解法，后人称之为匈牙利算法。 匈牙利算法 在介绍匈牙利算法之前，我们先介绍几个概念： 交替路： 从未匹配点出发，依次经过未匹配的边和已匹配的边的路径称为交替路。 增广路： 经过除出发点之外其他未匹配点的交替路称为增广路。 当且仅当不存在关于图 \\(G\\) 的增广路径时当前的匹配为图 \\(G\\) 的最大匹配。 算法讲解 如下图所示，我们接下来将使用匈牙利算法来计算该二分图的最大匹配数。 我们从 \\(a_1\\) 开始匹配，\\(a_1\\) 与 \\(b_1\\) 匹配成功，即当前匹配对数为 1。 然后再对 \\(a_2\\) 进行匹配，我们发现 \\(a_2\\) 只能匹配 \\(b_1\\) ，而 \\(b_1\\) 已经与 \\(a_1\\) 匹配成功了，此时我们发现 \\(a_1\\) 和 \\(b_3\\) 可以成功匹配，于是我们可以取消 \\(a_1\\) 和 \\(b_1\\) 的匹配，然后匹配 \\(a_1\\) 和 \\(b_3\\) ，这个时候 \\(a_2\\) 就可以匹配 \\(b_1\\) 了。匹配对数加一，当前匹配对数为 2。 其实这一步相当于找到了一条增广路 \\((a_2, b_1, a_1, b_3)\\) ，然后对该增广路取反。 接下来对 \\(a_3\\) 进行匹配，\\(a_3\\) 与 \\(b_2\\) 成功匹配，匹配对数加一，当前匹配对数为 3。 最后对 \\(a_4\\) 进行匹配，发现其只能与 \\(b_1\\) 匹配，而 \\(b_1\\) 已经与 \\(a_1\\) 匹配过了，而且无法从 \\(a_4\\) 出发构造一条增广路，因此 \\(a_4\\) 无法与任何一个顶点成功匹配。 综上所述，展示的二分图的最大匹配数为 3。 伪代码： 123456789// 判断 ai 是否能匹配成功for bj 与 ai 相连: if bj 未被访问: 更新 bj 访问状态; if bj 未被匹配或者 bj 的配对点可以出发找到增广路径: 将 bj 的配对点改为 ai; return true;return false; 时间复杂度：\\(O(VE)\\) 代码实现 123456789101112131415161718192021222324252627282930313233343536373839#define NOT_MATCH 0x3f3f3f3fclass Solution &#123;private: int numA, numB; // numA、numB 分别表示两个集合的元素个数 vector&lt;vector&lt;int&gt;&gt; G; // 假设这里用邻接链表储存图 G，G[i] 表示和 ai 相邻的所有 B 集合的顶点编号 int match[numB]; // 记录 B 集合的元素的匹配点在 A 集合的编号 bool vis[numB]; // 记录 B 集合的元素是否被访问过 // ... bool isMatch(int index) &#123; // 判断 A 集合中编号为 index 的顶点是否能匹配成功 for (int i = 0; i &lt; G[index].size(); i++) &#123; if (!vis[G[i]]) &#123; vis[G[i]] = true; if (match[G[i]] == NOT_MATCH || isMatch(match[[G[i]]])) &#123; // 该顶点未被匹配或着原来匹配该点的顶点可以匹配其他顶点 match[G[i]] = index; return true; &#125; &#125; &#125; return false; &#125; public: int hungarian() &#123; int cnt = 0; for (int i = 0; i &lt; numA; i++) &#123; memset(vis, 0x3f, sizeof(vis)); if (isMatch(i)) &#123; cnt++; &#125; &#125; return cnt; &#125;&#125; 实际应用 Machine Schedule Problem Description As we all know, machine scheduling is a very classical problem in computer science and has been studied for a very long history. Scheduling problems differ widely in the nature of the constraints that must be satisfied and the type of schedule desired. Here we consider a 2-machine scheduling problem. There are two machines A and B. Machine A has n kinds of working modes, which is called \\(mode_0\\) , \\(mode_1\\) , …, \\(mode_{n-1}\\) , likewise machine B has m kinds of working modes, \\(mode_0\\), \\(mode_1\\) , … , \\(mode_{m-1}\\) . At the beginning they are both work at \\(mode_0\\). For k jobs given, each of them can be processed in either one of the two machines in particular mode. For example, job 0 can either be processed in machine A at \\(mode_3\\) or in machine B at \\(mode_4\\) , job 1 can either be processed in machine A at \\(mode_2\\) or in machine B at \\(mode_4\\) , and so on. Thus, for job i, the constraint can be represent as a triple (i, x, y), which means it can be processed either in machine A at \\(mode_x\\), or in machine B at \\(mode_y\\) . Obviously, to accomplish all the jobs, we need to change the machine’s working mode from time to time, but unfortunately, the machine’s working mode can only be changed by restarting it manually. By changing the sequence of the jobs and assigning each job to a suitable machine, please write a program to minimize the times of restarting machines. Input The input file for this program consists of several configurations. The first line of one configuration contains three positive integers: n, m (n, m &lt; 100) and k (k &lt; 1000). The following k lines give the constrains of the k jobs, each line is a triple: i, x, y. The input will be terminated by a line containing a single zero. Output The output should be one integer per line, which means the minimal times of restarting machine. 输入案例： 1234567891011125 5 100 1 11 1 22 1 33 1 44 2 15 2 26 2 37 2 48 3 39 4 30 输出案例： 13 对于此题，我们可以将 A、B 机器的所有模式看成二部图看成两个子集，若某个工作需要机器 A 的 x 模式和机器 B 的 y 模式来完成，就将 \\((a_x, b_y)\\) 连接起来。最后我们的问题就变成了：应该如何找到该二部图的最小点覆盖数？ 而根据我们之前提到的结论可知，最小点覆盖数在数值上等于最大匹配数。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;#define MAX_NUM 105#define NOT_FOUND 0x3f3f3f3fint G[MAX_NUM][MAX_NUM];bool vis[MAX_NUM];int match[MAX_NUM];int n, m, k;bool isMatch(int index) &#123; for (int i = 0; i &lt; m; i++) &#123; if (G[index][i] &amp;&amp; !vis[i]) &#123; vis[i] = true; if (match[i] == NOT_FOUND || isMatch(match[i])) &#123; match[i] = index; return true; &#125; &#125; &#125; return false;&#125;int main() &#123; ios::sync_with_stdio(false); while (cin &gt;&gt; n) &#123; if (n == 0) &#123; break; &#125; cin &gt;&gt; m &gt;&gt; k; memset(G, 0, sizeof(G)); memset(match, 0x3f, sizeof(match)); // 初始化 int t, ax, by; for (int i = 0; i &lt; k; i++) &#123; cin &gt;&gt; t &gt;&gt; ax &gt;&gt; by; if (ax != 0 &amp;&amp; by != 0) &#123; // 0 号模式下可以完成的任务不用添加 G[ax][by] = 1; &#125; &#125; int cnt = 0; for (int i = 0; i &lt; n; i++) &#123; memset(vis, 0, sizeof(vis)); if (isMatch(i)) &#123; cnt++; &#125; &#125; // 求出最小点覆盖数 cout &lt;&lt; cnt &lt;&lt; endl; &#125; return 0;&#125; 二分图博弈问题 二分图博弈是一类博弈模型，他可以抽象为：给出一张二分图和起点 \\(S\\) ，两人轮流进行操作，每次操作只能选择与上一个被选的点相邻的点，且不能选择已经选择过的点，无法选点的人输掉。问先手是否必胜。 结论：考虑二分图的所有最大匹配，如果在所有的最大匹配的方案中都包含了起点 \\(S\\) ，那么先手必胜，否则先手必败。 证明： 若所有最大匹配方案包括了 \\(S\\) ，则先手可以走到一个匹配点 \\(p_1\\) ，每一步后手都会走到一个新匹配点。假设后手走到了未匹配点 \\(p_n\\) ，考虑当前所走步：\\(S \\to p_1 \\to p_2 \\to ... \\to p_{n - 1} \\to p_{n}\\) ，则 \\((p_1, p_2), (p_3, p_4), ... (p_{n - 1}, p_{n})\\) 以及其他匹配对构成了不包含 \\(S\\) 的最大匹配，矛盾。因此后手一定会走到一个匹配点，综上所述，先手一定会选择完最后一个匹配点，后手将无路可走，先手必胜。 若存在一种最大匹配不包含 \\(S\\) ，则先手每一步只能走到新匹配点，假设先手在某一步走到了非匹配点 \\(p_n\\) ，则当前路径为 \\(S \\to p_1 \\to p_2 \\to ... \\to p_{n - 1} \\to p_{n}\\) ，此时 \\((S, p_1), (p_1, p_2), ... , (p_{n - 1}, p_n)\\) 加上其他匹配对构成了更大的匹配对数，这与假设矛盾。因此每一步先手后会走到新匹配点，后手走与该点匹配的点即可，最终后手一定会选择完最后一个匹配点，先手将无路可走，后手必胜。 如何确定某个点 \\(S\\) 在最大匹配中不可或缺呢？ 考虑先求该二分图的最大匹配，然后删除 \\(S\\) 点，再算一次最大匹配，若二者相等说明 \\(S\\) 不是最大匹配中不可或缺的点，反之这说明所有的最大匹配方案中都有 \\(S\\) 。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"DFS","slug":"DFS","permalink":"http://example.com/tags/DFS/"},{"name":"二分匹配","slug":"二分匹配","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E5%8C%B9%E9%85%8D/"},{"name":"匈牙利算法","slug":"匈牙利算法","permalink":"http://example.com/tags/%E5%8C%88%E7%89%99%E5%88%A9%E7%AE%97%E6%B3%95/"},{"name":"二分图博弈","slug":"二分图博弈","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8D%9A%E5%BC%88/"}]},{"title":"LLDB 快速入门","slug":"LLDB 快速入门","date":"2023-02-22T03:01:12.000Z","updated":"2023-07-10T08:05:54.880Z","comments":true,"path":"2023/02/22/LLDB 快速入门/","link":"","permalink":"http://example.com/2023/02/22/LLDB%20%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","excerpt":"","text":"如果调试是删除 bug 的过程，那么编程就是引入 bug 的过程。 —— Edsger W. Dijkstra LLDB 是什么？ LLDB（ Low level Debug ）是 MacOS 默认进行调试 C/C++ 程序的调试工具，能帮开发者进行更加丰富地流程控制和栈帧数据监测。 简言之，LLDB 是一个有着 REPL 的特性和 C++ 、Python 插件的开源调试器。 在此，我们以几个简单的程序为例子，对 LLDB 进行快速入门。 目录 启动 LLDB 断点操作 设置断点 查看断点 删除断点 分步调试 启动调试 进入，跳过和继续 跳出当前函数 查看变量 结束调试 启动 LLDB 1234567891011121314151617181920212223242526// demo.cpp#include &lt;iostream&gt;using namespace std;int fact(int n) &#123; if (n == 0) &#123; return 1; &#125; else &#123; return n * fact(n - 1); &#125;&#125;int main() &#123; int x = 2; int y = 3; int z = x + y; cout &lt;&lt; fact(z) &lt;&lt; endl; return 0;&#125; 编译 C/C++ 程序时使其可以被 LLDB 调试工具设置断点，需要添加 -g ，以 C++ 文件 demo.cpp 为例： 123clang++ -g demo.cpplldb a.out 断点操作 设置断点 12br s -f [文件名] -l [行号] # 在文件的某一行设置断点br s -n [函数名] # 给函数设置断点 查看断点 1br list # 显示所有断点和其序号 删除断点 12br del [断点序号]br del # 删除所有断点 示例： 1234567891011121314151617181920212223242526(lldb) br s -f demo.cpp -l 17Breakpoint 1: where = a.out`main + 28 at demo.cpp:17:9, address = 0x0000000100003d80(lldb) br s -f demo.cpp -l 21Breakpoint 2: where = a.out`main + 56 at demo.cpp:21:18, address = 0x0000000100003d9c(lldb) br s -n factBreakpoint 3: where = a.out`fact(int) + 16 at demo.cpp:6:9, address = 0x0000000100003d18(lldb) br listCurrent breakpoints:1: file = &#x27;demo.cpp&#x27;, line = 17, exact_match = 0, locations = 1 1.1: where = a.out`main + 28 at demo.cpp:17:9, address = a.out[0x0000000100003d80], unresolved, hit count = 0 2: file = &#x27;demo.cpp&#x27;, line = 21, exact_match = 0, locations = 1 2.1: where = a.out`main + 56 at demo.cpp:21:18, address = a.out[0x0000000100003d9c], unresolved, hit count = 0 3: name = &#x27;fact&#x27;, locations = 1 3.1: where = a.out`fact(int) + 16 at demo.cpp:6:9, address = a.out[0x0000000100003d18], unresolved, hit count = 0 (lldb) br del 31 breakpoints deleted; 0 breakpoint locations disabled.(lldb) br listCurrent breakpoints:1: file = &#x27;demo.cpp&#x27;, line = 17, exact_match = 0, locations = 1 1.1: where = a.out`main + 28 at demo.cpp:17:9, address = a.out[0x0000000100003d80], unresolved, hit count = 0 2: file = &#x27;demo.cpp&#x27;, line = 21, exact_match = 0, locations = 1 2.1: where = a.out`main + 56 at demo.cpp:21:18, address = a.out[0x0000000100003d9c], unresolved, hit count = 0 分步调试 启动调试 1r 输入 run 或者 r 后程序便会开始启动调试 进入，跳过和继续 12345678# 进入 单步执行，中间如果有函数调用会跳转到目标函数s# 跳过 单步执行，中间的函数执行过程会跳过n# 继续 跳转到下一个断点c 跳出当前函数 1finish 查看变量 123456789101112131415161718# 查看某个变量：p [变量名]# 查看当前栈帧所有变量fr v# 切换栈帧fr s [栈帧序号]# 打印当前线程的栈帧信息bt# 打印所有线程的栈帧信息bt all 综合案例：在 demo.cpp 的 17 行和 21 行设置断点，使用 r 开始调试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = breakpoint 1.1 frame #0: 0x0000000100003d80 a.out`main at demo.cpp:17:9 14 15 int main() &#123; 16 -&gt; 17 int x = 2; 18 int y = 3; 19 int z = x + y; 20 Target 0: (a.out) stopped.(lldb) sProcess 31435 stopped* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = step in frame #0: 0x0000000100003d88 a.out`main at demo.cpp:18:9 15 int main() &#123; 16 17 int x = 2;-&gt; 18 int y = 3; 19 int z = x + y; 20 21 cout &lt;&lt; fact(z) &lt;&lt; endl;Target 0: (a.out) stopped.(lldb) sProcess 31435 stopped* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = step in frame #0: 0x0000000100003d8c a.out`main at demo.cpp:19:13 16 17 int x = 2; 18 int y = 3;-&gt; 19 int z = x + y; 20 21 cout &lt;&lt; fact(z) &lt;&lt; endl; 22 Target 0: (a.out) stopped.(lldb) sProcess 31435 stopped* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = breakpoint 2.1 frame #0: 0x0000000100003d9c a.out`main at demo.cpp:21:18 18 int y = 3; 19 int z = x + y; 20 -&gt; 21 cout &lt;&lt; fact(z) &lt;&lt; endl; 22 23 return 0; 24 &#125;Target 0: (a.out) stopped.(lldb) fr v(int) x = 2(int) y = 3(int) z = 5(lldb) sProcess 31435 stopped* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = step in frame #0: 0x0000000100003d18 a.out`fact(n=5) at demo.cpp:6:9 3 using namespace std; 4 5 int fact(int n) &#123;-&gt; 6 if (n == 0) &#123; 7 return 1; 8 &#125; 9 else &#123;Target 0: (a.out) stopped.(lldb) finishProcess 31435 stopped* thread #1, queue = &#x27;com.apple.main-thread&#x27;, stop reason = step outReturn value: (int) $0 = 120 frame #0: 0x0000000100003da4 a.out`main at demo.cpp:21:13 18 int y = 3; 19 int z = x + y; 20 -&gt; 21 cout &lt;&lt; fact(z) &lt;&lt; endl; 22 23 return 0; 24 &#125;Target 0: (a.out) stopped.(lldb) cProcess 31435 resuming120Process 31435 exited with status = 0 (0x00000000) 结束调试 1q 输入 quit 或者 q 结束 LLDB 调试 以上就是对 LLDB 的一个简单介绍了，如果想了解更多 LLDB 指令，可以查看官网的 LLDB command map","categories":[{"name":"C/C++","slug":"C-C","permalink":"http://example.com/categories/C-C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"调试器","slug":"调试器","permalink":"http://example.com/tags/%E8%B0%83%E8%AF%95%E5%99%A8/"},{"name":"LLDB","slug":"LLDB","permalink":"http://example.com/tags/LLDB/"}]},{"title":"React 脚手架配置代理的方法","slug":"React 脚手架配置代理的方法","date":"2023-02-07T14:42:07.000Z","updated":"2023-07-10T08:03:12.050Z","comments":true,"path":"2023/02/07/React 脚手架配置代理的方法/","link":"","permalink":"http://example.com/2023/02/07/React%20%E8%84%9A%E6%89%8B%E6%9E%B6%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"方法一：直接在 package.json 中追加配置 例如，当前服务器端口为 3000，若要向端口 5000 的服务器发送请求，我们可以在 package.json 中添加如下配置： 1&quot;proxy&quot;: &quot;http://localhost:5000&quot; 此后，当请求了 3000 端口不存在的资源时，那么请求就会转发给 5000 端口。 示例： 例如一个 create-react-app 创建项目在 3001 端口运行，我们使用 json-server 模拟了一个 3000 端口的服务器，其中 JSON 数据如下： 1234567&#123; &quot;students&quot;: [ &#123;&quot;id&quot;: &quot;0001&quot;, &quot;name&quot;: &quot;Tom&quot;, &quot;age&quot;: 18&#125;, &#123;&quot;id&quot;: &quot;0002&quot;, &quot;name&quot;: &quot;Jack&quot;, &quot;age&quot;: 19&#125;, &#123;&quot;id&quot;: &quot;0003&quot;, &quot;name&quot;: &quot;Frank&quot;, &quot;age&quot;: 20&#125; ]&#125; students 数据的 URL 为 http://localhost:3000/students，若我们要向 3001 端口发送 GET 请求来获取 students 的 JSON 数据，则可以在 package.json 中添加配置： 1&quot;proxy&quot;: &quot;http://localhost:3000&quot; 获取 3001 端口有的资源： 12345678910111213141516171819202122export default class App extends Component &#123; getInfo = () =&gt; &#123; axios.get(&quot;http://localhost:3001/index.html&quot;).then( response =&gt; &#123; console.log(response.data); &#125;, err =&gt; &#123; console.log(err); &#125; ); &#125; render() &#123; return ( &lt;div&gt; &lt;button onClick=&#123;this.getInfo&#125;&gt;点击发送请求获取数据&lt;/button&gt; &lt;/div&gt; ) &#125;&#125; 此时控制台输出当前项目下的 index.html 文件： 获取 3001 端口没有而 3000 端口有的资源： 12345678910111213141516171819202122export default class App extends Component &#123; getInfo = () =&gt; &#123; axios.get(&quot;http://localhost:3001/students&quot;).then( response =&gt; &#123; console.log(response.data); &#125;, err =&gt; &#123; console.log(err); &#125; ); &#125; render() &#123; return ( &lt;div&gt; &lt;button onClick=&#123;this.getInfo&#125;&gt;点击发送请求获取数据&lt;/button&gt; &lt;/div&gt; ) &#125;&#125; 此时控制台输出 3000 端口下的 students 数据： 若获取的资源 3001 端口和 3000 端口都没有，则控制台会报错。 方法一优缺点： 优点：配置简单，前端请求资源时可以不加任何前缀 缺点：不能配置多个代理 方法二：创建 setupProxy.js 文件 首先在 src 目录下创建 setupProxy.js 文件 编写 setupProxy.js 配置具体代码规范： 12345678910111213141516171819202122232425262728// 配置端口 8000 和端口 5001 的服务器代理// setupProxy.jsconst &#123; createProxyMiddleware &#125; = require(&#x27;http-proxy-middleware&#x27;);// 引入内置模块: HTTP 代理中间件module.exports = function(app) &#123; // app 为服务对象 app.use( createProxyMiddleware(&#x27;/api1&#x27;, &#123; // 遇见 /api1 前缀的请求，就会触发该代理 target: &#x27;http://localhost:8000&#x27;, // 请求转发的端口地址 changeOrigin: true, // 控制服务器收到响应头中 Host 字段的值 pathRewrite: &#123; &#x27;^/api1&#x27;: &#x27;&#x27; // 去除请求前缀，保证交给后台服务器的是正常请求地址 &#125; &#125;) ); app.use( createProxyMiddleware(&#x27;/api2&#x27;, &#123; target: &#x27;http://localhost:5001&#x27;, changeOrigin: true, pathRewrite: &#123; &#x27;^/api2&#x27;: &#x27;&#x27; &#125; &#125;) );&#125; http-proxy-middleware 1.x 版本后配置代理使用： 1const &#123; createProxyMiddleware &#125; = require(&#x27;http-proxy-middleware&#x27;); 此前使用： 1const proxy = require(&#x27;http-proxy-middleware&#x27;); 向不同端口发送请求的方法： 如果要向 8000 端口发送请求，例如： 123axios.get(&#x27;http://localhost:3000/api1/teachers&#x27;).then( // ...); 如果要向 5001 端口发送请求，同理： 123axios.get(&#x27;http://localhost:3000/api2/students&#x27;).then( // ...); 方法二优缺点： 优点：可以配置多个代理，可以更加灵活地控制是否走代理请求 缺点：配置繁琐，前端发送代理请求时必须加前缀","categories":[{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"React","slug":"React","permalink":"http://example.com/tags/React/"}]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"},{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"ACM","slug":"ACM","permalink":"http://example.com/categories/ACM/"},{"name":"数学","slug":"数学","permalink":"http://example.com/categories/%E6%95%B0%E5%AD%A6/"},{"name":"日常","slug":"日常","permalink":"http://example.com/categories/%E6%97%A5%E5%B8%B8/"},{"name":"C/C++","slug":"C-C","permalink":"http://example.com/categories/C-C/"},{"name":"数据库","slug":"数据库","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"前端","slug":"前端","permalink":"http://example.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"SNN","slug":"SNN","permalink":"http://example.com/tags/SNN/"},{"name":"数据链路层","slug":"数据链路层","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"},{"name":"媒体访问控制","slug":"媒体访问控制","permalink":"http://example.com/tags/%E5%AA%92%E4%BD%93%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"name":"ALOHA","slug":"ALOHA","permalink":"http://example.com/tags/ALOHA/"},{"name":"CSMA","slug":"CSMA","permalink":"http://example.com/tags/CSMA/"},{"name":"以太网","slug":"以太网","permalink":"http://example.com/tags/%E4%BB%A5%E5%A4%AA%E7%BD%91/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"线程","slug":"线程","permalink":"http://example.com/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"死锁","slug":"死锁","permalink":"http://example.com/tags/%E6%AD%BB%E9%94%81/"},{"name":"NLP","slug":"NLP","permalink":"http://example.com/tags/NLP/"},{"name":"Transformer","slug":"Transformer","permalink":"http://example.com/tags/Transformer/"},{"name":"GPT","slug":"GPT","permalink":"http://example.com/tags/GPT/"},{"name":"LLM","slug":"LLM","permalink":"http://example.com/tags/LLM/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Scrapy","slug":"Scrapy","permalink":"http://example.com/tags/Scrapy/"},{"name":"CV","slug":"CV","permalink":"http://example.com/tags/CV/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"tqdm","slug":"tqdm","permalink":"http://example.com/tags/tqdm/"},{"name":"内存管理","slug":"内存管理","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"MMU","slug":"MMU","permalink":"http://example.com/tags/MMU/"},{"name":"页表","slug":"页表","permalink":"http://example.com/tags/%E9%A1%B5%E8%A1%A8/"},{"name":"N-gram","slug":"N-gram","permalink":"http://example.com/tags/N-gram/"},{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"时序神经网络","slug":"时序神经网络","permalink":"http://example.com/tags/%E6%97%B6%E5%BA%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"RNN","slug":"RNN","permalink":"http://example.com/tags/RNN/"},{"name":"流量控制","slug":"流量控制","permalink":"http://example.com/tags/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/"},{"name":"网络安全","slug":"网络安全","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"密码学","slug":"密码学","permalink":"http://example.com/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"RSA","slug":"RSA","permalink":"http://example.com/tags/RSA/"},{"name":"I/O","slug":"I-O","permalink":"http://example.com/tags/I-O/"},{"name":"概率论","slug":"概率论","permalink":"http://example.com/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"贝叶斯公式","slug":"贝叶斯公式","permalink":"http://example.com/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/"},{"name":"文件系统","slug":"文件系统","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"数据库系统","slug":"数据库系统","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"},{"name":"Servlet","slug":"Servlet","permalink":"http://example.com/tags/Servlet/"},{"name":"进程","slug":"进程","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"进程管理","slug":"进程管理","permalink":"http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"shell","slug":"shell","permalink":"http://example.com/tags/shell/"},{"name":"表达式树","slug":"表达式树","permalink":"http://example.com/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%91/"},{"name":"波兰记法","slug":"波兰记法","permalink":"http://example.com/tags/%E6%B3%A2%E5%85%B0%E8%AE%B0%E6%B3%95/"},{"name":"逆波兰记法","slug":"逆波兰记法","permalink":"http://example.com/tags/%E9%80%86%E6%B3%A2%E5%85%B0%E8%AE%B0%E6%B3%95/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://example.com/tags/PyTorch/"},{"name":"线性回归","slug":"线性回归","permalink":"http://example.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"name":"Pandas","slug":"Pandas","permalink":"http://example.com/tags/Pandas/"},{"name":"数据科学","slug":"数据科学","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"数论","slug":"数论","permalink":"http://example.com/tags/%E6%95%B0%E8%AE%BA/"},{"name":"杜教筛","slug":"杜教筛","permalink":"http://example.com/tags/%E6%9D%9C%E6%95%99%E7%AD%9B/"},{"name":"莫比乌斯反演","slug":"莫比乌斯反演","permalink":"http://example.com/tags/%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E5%8F%8D%E6%BC%94/"},{"name":"Vim","slug":"Vim","permalink":"http://example.com/tags/Vim/"},{"name":"杭电多校","slug":"杭电多校","permalink":"http://example.com/tags/%E6%9D%AD%E7%94%B5%E5%A4%9A%E6%A0%A1/"},{"name":"Nowcoder","slug":"Nowcoder","permalink":"http://example.com/tags/Nowcoder/"},{"name":"Manacher","slug":"Manacher","permalink":"http://example.com/tags/Manacher/"},{"name":"37% 法则","slug":"37-法则","permalink":"http://example.com/tags/37-%E6%B3%95%E5%88%99/"},{"name":"bitset","slug":"bitset","permalink":"http://example.com/tags/bitset/"},{"name":"NumPy","slug":"NumPy","permalink":"http://example.com/tags/NumPy/"},{"name":"Codeforces","slug":"Codeforces","permalink":"http://example.com/tags/Codeforces/"},{"name":"Div.2","slug":"Div-2","permalink":"http://example.com/tags/Div-2/"},{"name":"贪心算法","slug":"贪心算法","permalink":"http://example.com/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"前缀异或","slug":"前缀异或","permalink":"http://example.com/tags/%E5%89%8D%E7%BC%80%E5%BC%82%E6%88%96/"},{"name":"线段树","slug":"线段树","permalink":"http://example.com/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"},{"name":"哈尔滨","slug":"哈尔滨","permalink":"http://example.com/tags/%E5%93%88%E5%B0%94%E6%BB%A8/"},{"name":"分类讨论","slug":"分类讨论","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB%E8%AE%A8%E8%AE%BA/"},{"name":"Div.1","slug":"Div-1","permalink":"http://example.com/tags/Div-1/"},{"name":"DP","slug":"DP","permalink":"http://example.com/tags/DP/"},{"name":"Dijkstra","slug":"Dijkstra","permalink":"http://example.com/tags/Dijkstra/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"位运算","slug":"位运算","permalink":"http://example.com/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"集合","slug":"集合","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88/"},{"name":"数值运算","slug":"数值运算","permalink":"http://example.com/tags/%E6%95%B0%E5%80%BC%E8%BF%90%E7%AE%97/"},{"name":"CMake","slug":"CMake","permalink":"http://example.com/tags/CMake/"},{"name":"跨平台项目构建","slug":"跨平台项目构建","permalink":"http://example.com/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA/"},{"name":"字典树","slug":"字典树","permalink":"http://example.com/tags/%E5%AD%97%E5%85%B8%E6%A0%91/"},{"name":"字符串匹配","slug":"字符串匹配","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"name":"数据库规范化","slug":"数据库规范化","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%84%E8%8C%83%E5%8C%96/"},{"name":"计算几何","slug":"计算几何","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/"},{"name":"Simpson 公式","slug":"Simpson-公式","permalink":"http://example.com/tags/Simpson-%E5%85%AC%E5%BC%8F/"},{"name":"定积分","slug":"定积分","permalink":"http://example.com/tags/%E5%AE%9A%E7%A7%AF%E5%88%86/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"素数","slug":"素数","permalink":"http://example.com/tags/%E7%B4%A0%E6%95%B0/"},{"name":"素数筛","slug":"素数筛","permalink":"http://example.com/tags/%E7%B4%A0%E6%95%B0%E7%AD%9B/"},{"name":"埃氏筛","slug":"埃氏筛","permalink":"http://example.com/tags/%E5%9F%83%E6%B0%8F%E7%AD%9B/"},{"name":"欧式筛","slug":"欧式筛","permalink":"http://example.com/tags/%E6%AC%A7%E5%BC%8F%E7%AD%9B/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://example.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"匿名函数","slug":"匿名函数","permalink":"http://example.com/tags/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"},{"name":"树状数组","slug":"树状数组","permalink":"http://example.com/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"区间查询","slug":"区间查询","permalink":"http://example.com/tags/%E5%8C%BA%E9%97%B4%E6%9F%A5%E8%AF%A2/"},{"name":"STL","slug":"STL","permalink":"http://example.com/tags/STL/"},{"name":"图论","slug":"图论","permalink":"http://example.com/tags/%E5%9B%BE%E8%AE%BA/"},{"name":"链式前向星","slug":"链式前向星","permalink":"http://example.com/tags/%E9%93%BE%E5%BC%8F%E5%89%8D%E5%90%91%E6%98%9F/"},{"name":"SG 定理","slug":"SG-定理","permalink":"http://example.com/tags/SG-%E5%AE%9A%E7%90%86/"},{"name":"SG 函数","slug":"SG-函数","permalink":"http://example.com/tags/SG-%E5%87%BD%E6%95%B0/"},{"name":"组合博弈","slug":"组合博弈","permalink":"http://example.com/tags/%E7%BB%84%E5%90%88%E5%8D%9A%E5%BC%88/"},{"name":"组合数学","slug":"组合数学","permalink":"http://example.com/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"},{"name":"记忆化搜索","slug":"记忆化搜索","permalink":"http://example.com/tags/%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2/"},{"name":"DFS","slug":"DFS","permalink":"http://example.com/tags/DFS/"},{"name":"二分匹配","slug":"二分匹配","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E5%8C%B9%E9%85%8D/"},{"name":"匈牙利算法","slug":"匈牙利算法","permalink":"http://example.com/tags/%E5%8C%88%E7%89%99%E5%88%A9%E7%AE%97%E6%B3%95/"},{"name":"二分图博弈","slug":"二分图博弈","permalink":"http://example.com/tags/%E4%BA%8C%E5%88%86%E5%9B%BE%E5%8D%9A%E5%BC%88/"},{"name":"调试器","slug":"调试器","permalink":"http://example.com/tags/%E8%B0%83%E8%AF%95%E5%99%A8/"},{"name":"LLDB","slug":"LLDB","permalink":"http://example.com/tags/LLDB/"},{"name":"React","slug":"React","permalink":"http://example.com/tags/React/"}]}